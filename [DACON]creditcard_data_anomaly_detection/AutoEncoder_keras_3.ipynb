{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a0818b8",
   "metadata": {},
   "source": [
    "## 0. 텐서플로우 메모리 관리 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34c8968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 워닝 무시\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "371157a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-01 01:28:01.373481: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-01 01:28:01.402347: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-01 01:28:01.405319: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        # 프로그램 시작시에 메모리 증가가 설정되어야만 합니다\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c068ec",
   "metadata": {},
   "source": [
    "## 1. 패키지 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a740e9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity, cosine_distances, distance\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import (confusion_matrix, precision_recall_curve, auc,\n",
    "                             roc_curve, recall_score, classification_report, f1_score,\n",
    "                             precision_recall_fscore_support, recall_score)\n",
    "from tqdm.notebook import tqdm "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee812904",
   "metadata": {},
   "source": [
    "## 2. 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1c558d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train.csv') # 학습용 데이터\n",
    "test_df = pd.read_csv('./data/test.csv') # 테스트용 데이터\n",
    "val_df = pd.read_csv('./data/val.csv') # 검증용 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70ff7ea",
   "metadata": {},
   "source": [
    "## 3. EDA를 통한 피처 선정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "4de052f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_feature = ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V9', 'V10', 'V11', 'V12', 'V14', 'V16', 'V17', 'V18', 'V30']\n",
    "select_feature_val = ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V9', 'V10', 'V11', 'V12', 'V14', 'V16', 'V17', 'V18', 'V30', 'Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4013f32a",
   "metadata": {},
   "source": [
    "## 4. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "ff407196",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_df[select_feature].values\n",
    "test_X = test_df[select_feature].values\n",
    "val_X = val_df[select_feature]\n",
    "val_Y = val_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5136a4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_df[train_df.columns[1:]].values # id를 제외하여 train_X 생성\n",
    "test_X = test_df[test_df.columns[1:]].values # id를 제외하여 test_X 생성\n",
    "val_X = val_df[val_df.columns[1:-1]].values # id와 Class를 제외하여 val_X 생성\n",
    "val_Y = val_df['Class'] # Class 값으로 val_Y 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "0b20f086",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = train_X.shape[1] # 입력층의 dim 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a3a3f5",
   "metadata": {},
   "source": [
    "## 5. AutoEncoder 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "cda7d349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 Layer 쌓기 \n",
    "input_layer = layers.Input(shape=(input_dim,))\n",
    "encoder = Dense(12, activation='relu',\n",
    "               activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
    "batch_normal = BatchNormalization()(encoder)\n",
    "encoder = Dense(8, activation='relu')(batch_normal)\n",
    "batch_normal = BatchNormalization()(encoder)\n",
    "encoder = Dense(4, activation='relu')(batch_normal)\n",
    "batch_normal = BatchNormalization()(encoder)\n",
    "decoder = Dense(4, activation='relu')(batch_normal)\n",
    "batch_normal = BatchNormalization()(decoder)\n",
    "decoder = Dense(8, activation='relu')(batch_normal)\n",
    "batch_normal = BatchNormalization()(decoder)\n",
    "decoder = Dense(12, activation='relu')(batch_normal)\n",
    "decoder = Dense(input_dim, activation='linear')(encoder)\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "e7280c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 Params 설정\n",
    "EPOCHS = 2000\n",
    "batch_size = 8192 * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "957ff0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 callback 함수 설정\n",
    "checkpointer = ModelCheckpoint(filepath='./model/keras_best.h5', verbos=1, save_best_only=True, monitor='val_accuracy', mode='max')\n",
    "earlystopping = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "f1981fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb6e9d0",
   "metadata": {},
   "source": [
    "## 6. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "d895bcca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "6/6 [==============================] - 1s 50ms/step - loss: 1.6230 - accuracy: 0.1131 - val_loss: 1.4773 - val_accuracy: 0.0560\n",
      "Epoch 2/2000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.5760 - accuracy: 0.1179 - val_loss: 1.4593 - val_accuracy: 0.0600\n",
      "Epoch 3/2000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 1.5371 - accuracy: 0.1282 - val_loss: 1.4434 - val_accuracy: 0.0708\n",
      "Epoch 4/2000\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 1.5052 - accuracy: 0.1375 - val_loss: 1.4296 - val_accuracy: 0.0935\n",
      "Epoch 5/2000\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 1.4793 - accuracy: 0.1487 - val_loss: 1.4170 - val_accuracy: 0.1268\n",
      "Epoch 6/2000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 1.4574 - accuracy: 0.1591 - val_loss: 1.4050 - val_accuracy: 0.1634\n",
      "Epoch 7/2000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 1.4389 - accuracy: 0.1691 - val_loss: 1.3930 - val_accuracy: 0.2011\n",
      "Epoch 8/2000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.4225 - accuracy: 0.1786 - val_loss: 1.3806 - val_accuracy: 0.2373\n",
      "Epoch 9/2000\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 1.4077 - accuracy: 0.1881 - val_loss: 1.3679 - val_accuracy: 0.2714\n",
      "Epoch 10/2000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 1.3940 - accuracy: 0.1976 - val_loss: 1.3548 - val_accuracy: 0.2971\n",
      "Epoch 11/2000\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 1.3812 - accuracy: 0.2055 - val_loss: 1.3413 - val_accuracy: 0.3157\n",
      "Epoch 12/2000\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 1.3690 - accuracy: 0.2147 - val_loss: 1.3274 - val_accuracy: 0.3319\n",
      "Epoch 13/2000\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 1.3573 - accuracy: 0.2220 - val_loss: 1.3133 - val_accuracy: 0.3461\n",
      "Epoch 14/2000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.3461 - accuracy: 0.2282 - val_loss: 1.2991 - val_accuracy: 0.3557\n",
      "Epoch 15/2000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 1.3354 - accuracy: 0.2340 - val_loss: 1.2849 - val_accuracy: 0.3623\n",
      "Epoch 16/2000\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 1.3252 - accuracy: 0.2396 - val_loss: 1.2709 - val_accuracy: 0.3723\n",
      "Epoch 17/2000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 1.3155 - accuracy: 0.2450 - val_loss: 1.2572 - val_accuracy: 0.3818\n",
      "Epoch 18/2000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.3062 - accuracy: 0.2516 - val_loss: 1.2440 - val_accuracy: 0.3955\n",
      "Epoch 19/2000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.2973 - accuracy: 0.2586 - val_loss: 1.2315 - val_accuracy: 0.4064\n",
      "Epoch 20/2000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.2888 - accuracy: 0.2651 - val_loss: 1.2196 - val_accuracy: 0.4159\n",
      "Epoch 21/2000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 1.2808 - accuracy: 0.2712 - val_loss: 1.2083 - val_accuracy: 0.4259\n",
      "Epoch 22/2000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 1.2728 - accuracy: 0.2791 - val_loss: 1.1976 - val_accuracy: 0.4369\n",
      "Epoch 23/2000\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 1.2653 - accuracy: 0.2858 - val_loss: 1.1875 - val_accuracy: 0.4453\n",
      "Epoch 24/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1.2579 - accuracy: 0.2928 - val_loss: 1.1781 - val_accuracy: 0.4531\n",
      "Epoch 25/2000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 1.2508 - accuracy: 0.3442 - val_loss: 1.1693 - val_accuracy: 0.4861\n",
      "Epoch 26/2000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.2441 - accuracy: 0.3735 - val_loss: 1.1610 - val_accuracy: 0.4933\n",
      "Epoch 27/2000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 1.2372 - accuracy: 0.3768 - val_loss: 1.1531 - val_accuracy: 0.4973\n",
      "Epoch 28/2000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.2306 - accuracy: 0.3802 - val_loss: 1.1455 - val_accuracy: 0.5037\n",
      "Epoch 29/2000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.2240 - accuracy: 0.3833 - val_loss: 1.1382 - val_accuracy: 0.5103\n",
      "Epoch 30/2000\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 1.2174 - accuracy: 0.3865 - val_loss: 1.1310 - val_accuracy: 0.5162\n",
      "Epoch 31/2000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 1.2108 - accuracy: 0.3898 - val_loss: 1.1240 - val_accuracy: 0.5211\n",
      "Epoch 32/2000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 1.2043 - accuracy: 0.3925 - val_loss: 1.1172 - val_accuracy: 0.5255\n",
      "Epoch 33/2000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 1.1979 - accuracy: 0.3957 - val_loss: 1.1103 - val_accuracy: 0.5299\n",
      "Epoch 34/2000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.1916 - accuracy: 0.4012 - val_loss: 1.1039 - val_accuracy: 0.5337\n",
      "Epoch 35/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1.1854 - accuracy: 0.4063 - val_loss: 1.0976 - val_accuracy: 0.5371\n",
      "Epoch 36/2000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.1794 - accuracy: 0.4093 - val_loss: 1.0913 - val_accuracy: 0.5407\n",
      "Epoch 37/2000\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 1.1734 - accuracy: 0.4125 - val_loss: 1.0852 - val_accuracy: 0.5434\n",
      "Epoch 38/2000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 1.1678 - accuracy: 0.4151 - val_loss: 1.0792 - val_accuracy: 0.5463\n",
      "Epoch 39/2000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.1622 - accuracy: 0.4182 - val_loss: 1.0734 - val_accuracy: 0.5481\n",
      "Epoch 40/2000\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 1.1565 - accuracy: 0.4204 - val_loss: 1.0678 - val_accuracy: 0.5500\n",
      "Epoch 41/2000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 1.1508 - accuracy: 0.4232 - val_loss: 1.0622 - val_accuracy: 0.5501\n",
      "Epoch 42/2000\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 1.1451 - accuracy: 0.4252 - val_loss: 1.0569 - val_accuracy: 0.5517\n",
      "Epoch 43/2000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 1.1393 - accuracy: 0.4284 - val_loss: 1.0518 - val_accuracy: 0.5538\n",
      "Epoch 44/2000\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 1.1336 - accuracy: 0.4306 - val_loss: 1.0467 - val_accuracy: 0.5558\n",
      "Epoch 45/2000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 1.1278 - accuracy: 0.4328 - val_loss: 1.0414 - val_accuracy: 0.5580\n",
      "Epoch 46/2000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 1.1224 - accuracy: 0.4350 - val_loss: 1.0361 - val_accuracy: 0.5597\n",
      "Epoch 47/2000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.1168 - accuracy: 0.4360 - val_loss: 1.0309 - val_accuracy: 0.5613\n",
      "Epoch 48/2000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 1.1115 - accuracy: 0.4377 - val_loss: 1.0257 - val_accuracy: 0.5623\n",
      "Epoch 49/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.1063 - accuracy: 0.4399 - val_loss: 1.0207 - val_accuracy: 0.5643\n",
      "Epoch 50/2000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.1012 - accuracy: 0.4419 - val_loss: 1.0159 - val_accuracy: 0.5663\n",
      "Epoch 51/2000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.0961 - accuracy: 0.4440 - val_loss: 1.0113 - val_accuracy: 0.5675\n",
      "Epoch 52/2000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.0913 - accuracy: 0.4454 - val_loss: 1.0065 - val_accuracy: 0.5686\n",
      "Epoch 53/2000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.0863 - accuracy: 0.4469 - val_loss: 1.0022 - val_accuracy: 0.5699\n",
      "Epoch 54/2000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.0815 - accuracy: 0.4490 - val_loss: 0.9979 - val_accuracy: 0.5707\n",
      "Epoch 55/2000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.0769 - accuracy: 0.4506 - val_loss: 0.9937 - val_accuracy: 0.5718\n",
      "Epoch 56/2000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.0721 - accuracy: 0.4520 - val_loss: 0.9897 - val_accuracy: 0.5731\n",
      "Epoch 57/2000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.0676 - accuracy: 0.4534 - val_loss: 0.9858 - val_accuracy: 0.5738\n",
      "Epoch 58/2000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.0630 - accuracy: 0.4545 - val_loss: 0.9820 - val_accuracy: 0.5747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.0588 - accuracy: 0.4551 - val_loss: 0.9781 - val_accuracy: 0.5750\n",
      "Epoch 60/2000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.0544 - accuracy: 0.4570 - val_loss: 0.9745 - val_accuracy: 0.5754\n",
      "Epoch 61/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.0501 - accuracy: 0.4591 - val_loss: 0.9708 - val_accuracy: 0.5757\n",
      "Epoch 62/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.0460 - accuracy: 0.4607 - val_loss: 0.9673 - val_accuracy: 0.5760\n",
      "Epoch 63/2000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.0421 - accuracy: 0.4624 - val_loss: 0.9639 - val_accuracy: 0.5765\n",
      "Epoch 64/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0377 - accuracy: 0.4639 - val_loss: 0.9604 - val_accuracy: 0.5765\n",
      "Epoch 65/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.0340 - accuracy: 0.4665 - val_loss: 0.9573 - val_accuracy: 0.5769\n",
      "Epoch 66/2000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.0300 - accuracy: 0.4704 - val_loss: 0.9541 - val_accuracy: 0.5777\n",
      "Epoch 67/2000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.0264 - accuracy: 0.4725 - val_loss: 0.9511 - val_accuracy: 0.5780\n",
      "Epoch 68/2000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.0228 - accuracy: 0.4736 - val_loss: 0.9480 - val_accuracy: 0.5781\n",
      "Epoch 69/2000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.0191 - accuracy: 0.4757 - val_loss: 0.9451 - val_accuracy: 0.5784\n",
      "Epoch 70/2000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.0157 - accuracy: 0.4772 - val_loss: 0.9422 - val_accuracy: 0.5786\n",
      "Epoch 71/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.0124 - accuracy: 0.4791 - val_loss: 0.9395 - val_accuracy: 0.5780\n",
      "Epoch 72/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0090 - accuracy: 0.4800 - val_loss: 0.9364 - val_accuracy: 0.5776\n",
      "Epoch 73/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0056 - accuracy: 0.4804 - val_loss: 0.9337 - val_accuracy: 0.5772\n",
      "Epoch 74/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0021 - accuracy: 0.4815 - val_loss: 0.9309 - val_accuracy: 0.5771\n",
      "Epoch 75/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9988 - accuracy: 0.4820 - val_loss: 0.9282 - val_accuracy: 0.5772\n",
      "Epoch 76/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9957 - accuracy: 0.4823 - val_loss: 0.9255 - val_accuracy: 0.5769\n",
      "Epoch 77/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9926 - accuracy: 0.4831 - val_loss: 0.9229 - val_accuracy: 0.5771\n",
      "Epoch 78/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9891 - accuracy: 0.4830 - val_loss: 0.9203 - val_accuracy: 0.5776\n",
      "Epoch 79/2000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.9860 - accuracy: 0.4832 - val_loss: 0.9179 - val_accuracy: 0.5775\n",
      "Epoch 80/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9826 - accuracy: 0.4833 - val_loss: 0.9151 - val_accuracy: 0.5777\n",
      "Epoch 81/2000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.9794 - accuracy: 0.4831 - val_loss: 0.9121 - val_accuracy: 0.5772\n",
      "Epoch 82/2000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.9763 - accuracy: 0.4833 - val_loss: 0.9095 - val_accuracy: 0.5758\n",
      "Epoch 83/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9733 - accuracy: 0.4832 - val_loss: 0.9072 - val_accuracy: 0.5742\n",
      "Epoch 84/2000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.9700 - accuracy: 0.4829 - val_loss: 0.9047 - val_accuracy: 0.5733\n",
      "Epoch 85/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9664 - accuracy: 0.4825 - val_loss: 0.9024 - val_accuracy: 0.5720\n",
      "Epoch 86/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9631 - accuracy: 0.4823 - val_loss: 0.9007 - val_accuracy: 0.5711\n",
      "Epoch 87/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9594 - accuracy: 0.4814 - val_loss: 0.8985 - val_accuracy: 0.5699\n",
      "Epoch 88/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9562 - accuracy: 0.4808 - val_loss: 0.8964 - val_accuracy: 0.5697\n",
      "Epoch 89/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9525 - accuracy: 0.4801 - val_loss: 0.8941 - val_accuracy: 0.5698\n",
      "Epoch 90/2000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.9492 - accuracy: 0.4794 - val_loss: 0.8920 - val_accuracy: 0.5690\n",
      "Epoch 91/2000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.9458 - accuracy: 0.4782 - val_loss: 0.8899 - val_accuracy: 0.5691\n",
      "Epoch 92/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9420 - accuracy: 0.4777 - val_loss: 0.8879 - val_accuracy: 0.5694\n",
      "Epoch 93/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9382 - accuracy: 0.4767 - val_loss: 0.8861 - val_accuracy: 0.5686\n",
      "Epoch 94/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9347 - accuracy: 0.4759 - val_loss: 0.8839 - val_accuracy: 0.5681\n",
      "Epoch 95/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9314 - accuracy: 0.4520 - val_loss: 0.8819 - val_accuracy: 0.5598\n",
      "Epoch 96/2000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.9280 - accuracy: 0.4252 - val_loss: 0.8795 - val_accuracy: 0.5600\n",
      "Epoch 97/2000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.9247 - accuracy: 0.4246 - val_loss: 0.8774 - val_accuracy: 0.5598\n",
      "Epoch 98/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9217 - accuracy: 0.4242 - val_loss: 0.8755 - val_accuracy: 0.5595\n",
      "Epoch 99/2000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.9180 - accuracy: 0.4233 - val_loss: 0.8730 - val_accuracy: 0.5581\n",
      "Epoch 100/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9152 - accuracy: 0.4222 - val_loss: 0.8709 - val_accuracy: 0.5583\n",
      "Epoch 101/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9118 - accuracy: 0.4219 - val_loss: 0.8689 - val_accuracy: 0.5584\n",
      "Epoch 102/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9091 - accuracy: 0.4214 - val_loss: 0.8666 - val_accuracy: 0.5586\n",
      "Epoch 103/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9058 - accuracy: 0.4216 - val_loss: 0.8643 - val_accuracy: 0.5593\n",
      "Epoch 104/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9033 - accuracy: 0.4215 - val_loss: 0.8627 - val_accuracy: 0.5578\n",
      "Epoch 105/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9007 - accuracy: 0.4211 - val_loss: 0.8606 - val_accuracy: 0.5597\n",
      "Epoch 106/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8976 - accuracy: 0.4215 - val_loss: 0.8590 - val_accuracy: 0.5576\n",
      "Epoch 107/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8951 - accuracy: 0.4214 - val_loss: 0.8576 - val_accuracy: 0.5572\n",
      "Epoch 108/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.8922 - accuracy: 0.4217 - val_loss: 0.8555 - val_accuracy: 0.5568\n",
      "Epoch 109/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8901 - accuracy: 0.4216 - val_loss: 0.8541 - val_accuracy: 0.5562\n",
      "Epoch 110/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8883 - accuracy: 0.4225 - val_loss: 0.8529 - val_accuracy: 0.5556\n",
      "Epoch 111/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8855 - accuracy: 0.4226 - val_loss: 0.8508 - val_accuracy: 0.5540\n",
      "Epoch 112/2000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.8831 - accuracy: 0.4237 - val_loss: 0.8493 - val_accuracy: 0.5517\n",
      "Epoch 113/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8811 - accuracy: 0.4225 - val_loss: 0.8483 - val_accuracy: 0.5520\n",
      "Epoch 114/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8792 - accuracy: 0.4222 - val_loss: 0.8471 - val_accuracy: 0.5522\n",
      "Epoch 115/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.8774 - accuracy: 0.4218 - val_loss: 0.8458 - val_accuracy: 0.5553\n",
      "Epoch 116/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8760 - accuracy: 0.4230 - val_loss: 0.8438 - val_accuracy: 0.5546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/2000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.8742 - accuracy: 0.4233 - val_loss: 0.8427 - val_accuracy: 0.5544\n",
      "Epoch 118/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8724 - accuracy: 0.4231 - val_loss: 0.8410 - val_accuracy: 0.5559\n",
      "Epoch 119/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8705 - accuracy: 0.4230 - val_loss: 0.8401 - val_accuracy: 0.5557\n",
      "Epoch 120/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8686 - accuracy: 0.4224 - val_loss: 0.8394 - val_accuracy: 0.5590\n",
      "Epoch 121/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8683 - accuracy: 0.4237 - val_loss: 0.8378 - val_accuracy: 0.5583\n",
      "Epoch 122/2000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.8658 - accuracy: 0.4246 - val_loss: 0.8355 - val_accuracy: 0.5605\n",
      "Epoch 123/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8645 - accuracy: 0.4241 - val_loss: 0.8353 - val_accuracy: 0.5576\n",
      "Epoch 124/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8642 - accuracy: 0.4250 - val_loss: 0.8349 - val_accuracy: 0.5585\n",
      "Epoch 125/2000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.8618 - accuracy: 0.4252 - val_loss: 0.8338 - val_accuracy: 0.5576\n",
      "Epoch 126/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8613 - accuracy: 0.4265 - val_loss: 0.8319 - val_accuracy: 0.5620\n",
      "Epoch 127/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8598 - accuracy: 0.4286 - val_loss: 0.8314 - val_accuracy: 0.5609\n",
      "Epoch 128/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8584 - accuracy: 0.4274 - val_loss: 0.8302 - val_accuracy: 0.5613\n",
      "Epoch 129/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.8569 - accuracy: 0.4281 - val_loss: 0.8290 - val_accuracy: 0.5634\n",
      "Epoch 130/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8569 - accuracy: 0.4281 - val_loss: 0.8286 - val_accuracy: 0.5609\n",
      "Epoch 131/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8558 - accuracy: 0.4280 - val_loss: 0.8274 - val_accuracy: 0.5620\n",
      "Epoch 132/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8541 - accuracy: 0.4285 - val_loss: 0.8263 - val_accuracy: 0.5623\n",
      "Epoch 133/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8531 - accuracy: 0.4272 - val_loss: 0.8254 - val_accuracy: 0.5624\n",
      "Epoch 134/2000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.8528 - accuracy: 0.4261 - val_loss: 0.8254 - val_accuracy: 0.5600\n",
      "Epoch 135/2000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.8507 - accuracy: 0.4244 - val_loss: 0.8246 - val_accuracy: 0.5590\n",
      "Epoch 136/2000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.8503 - accuracy: 0.4253 - val_loss: 0.8239 - val_accuracy: 0.5637\n",
      "Epoch 137/2000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.8494 - accuracy: 0.4289 - val_loss: 0.8227 - val_accuracy: 0.5672\n",
      "Epoch 138/2000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.8483 - accuracy: 0.4305 - val_loss: 0.8219 - val_accuracy: 0.5673\n",
      "Epoch 139/2000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.8486 - accuracy: 0.4295 - val_loss: 0.8211 - val_accuracy: 0.5641\n",
      "Epoch 140/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8467 - accuracy: 0.4266 - val_loss: 0.8206 - val_accuracy: 0.5635\n",
      "Epoch 141/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8465 - accuracy: 0.4281 - val_loss: 0.8199 - val_accuracy: 0.5654\n",
      "Epoch 142/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8461 - accuracy: 0.4295 - val_loss: 0.8192 - val_accuracy: 0.5655\n",
      "Epoch 143/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8446 - accuracy: 0.4284 - val_loss: 0.8191 - val_accuracy: 0.5634\n",
      "Epoch 144/2000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.8444 - accuracy: 0.4261 - val_loss: 0.8188 - val_accuracy: 0.5633\n",
      "Epoch 145/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8431 - accuracy: 0.4252 - val_loss: 0.8175 - val_accuracy: 0.5657\n",
      "Epoch 146/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8427 - accuracy: 0.4262 - val_loss: 0.8167 - val_accuracy: 0.5670\n",
      "Epoch 147/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8419 - accuracy: 0.4297 - val_loss: 0.8158 - val_accuracy: 0.5689\n",
      "Epoch 148/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8411 - accuracy: 0.4295 - val_loss: 0.8154 - val_accuracy: 0.5673\n",
      "Epoch 149/2000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.8408 - accuracy: 0.4292 - val_loss: 0.8153 - val_accuracy: 0.5674\n",
      "Epoch 150/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.8398 - accuracy: 0.4293 - val_loss: 0.8140 - val_accuracy: 0.5696\n",
      "Epoch 151/2000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.8400 - accuracy: 0.4301 - val_loss: 0.8132 - val_accuracy: 0.5700\n",
      "Epoch 152/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8401 - accuracy: 0.4308 - val_loss: 0.8133 - val_accuracy: 0.5711\n",
      "Epoch 153/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8390 - accuracy: 0.4310 - val_loss: 0.8128 - val_accuracy: 0.5695\n",
      "Epoch 154/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8387 - accuracy: 0.4325 - val_loss: 0.8124 - val_accuracy: 0.5726\n",
      "Epoch 155/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8383 - accuracy: 0.4343 - val_loss: 0.8116 - val_accuracy: 0.5754\n",
      "Epoch 156/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8378 - accuracy: 0.4343 - val_loss: 0.8105 - val_accuracy: 0.5767\n",
      "Epoch 157/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8371 - accuracy: 0.4329 - val_loss: 0.8092 - val_accuracy: 0.5767\n",
      "Epoch 158/2000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8361 - accuracy: 0.4355 - val_loss: 0.8096 - val_accuracy: 0.5754\n",
      "Epoch 159/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8372 - accuracy: 0.4370 - val_loss: 0.8102 - val_accuracy: 0.5759\n",
      "Epoch 160/2000\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.8355 - accuracy: 0.4375 - val_loss: 0.8094 - val_accuracy: 0.5796\n",
      "Epoch 161/2000\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.8346 - accuracy: 0.4383 - val_loss: 0.8076 - val_accuracy: 0.5809\n",
      "Epoch 162/2000\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.8346 - accuracy: 0.4385 - val_loss: 0.8067 - val_accuracy: 0.5818\n",
      "Epoch 163/2000\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.8336 - accuracy: 0.4401 - val_loss: 0.8069 - val_accuracy: 0.5823\n",
      "Epoch 164/2000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.8335 - accuracy: 0.4402 - val_loss: 0.8068 - val_accuracy: 0.5821\n",
      "Epoch 165/2000\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.8331 - accuracy: 0.4400 - val_loss: 0.8057 - val_accuracy: 0.5836\n",
      "Epoch 166/2000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.8340 - accuracy: 0.4421 - val_loss: 0.8056 - val_accuracy: 0.5847\n",
      "Epoch 167/2000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8318 - accuracy: 0.4434 - val_loss: 0.8054 - val_accuracy: 0.5854\n",
      "Epoch 168/2000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8323 - accuracy: 0.4422 - val_loss: 0.8043 - val_accuracy: 0.5858\n",
      "Epoch 169/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.8318 - accuracy: 0.4439 - val_loss: 0.8035 - val_accuracy: 0.5861\n",
      "Epoch 170/2000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.8304 - accuracy: 0.4442 - val_loss: 0.8030 - val_accuracy: 0.5868\n",
      "Epoch 171/2000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.8303 - accuracy: 0.4453 - val_loss: 0.8033 - val_accuracy: 0.5874\n",
      "Epoch 172/2000\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.8300 - accuracy: 0.4466 - val_loss: 0.8025 - val_accuracy: 0.5883\n",
      "Epoch 173/2000\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.8304 - accuracy: 0.4474 - val_loss: 0.8023 - val_accuracy: 0.5884\n",
      "Epoch 174/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 23ms/step - loss: 0.8299 - accuracy: 0.4473 - val_loss: 0.8020 - val_accuracy: 0.5890\n",
      "Epoch 175/2000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.8290 - accuracy: 0.4487 - val_loss: 0.8008 - val_accuracy: 0.5891\n",
      "Epoch 176/2000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.8286 - accuracy: 0.4482 - val_loss: 0.8003 - val_accuracy: 0.5893\n",
      "Epoch 177/2000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.8284 - accuracy: 0.4499 - val_loss: 0.8007 - val_accuracy: 0.5913\n",
      "Epoch 178/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8281 - accuracy: 0.4516 - val_loss: 0.8004 - val_accuracy: 0.5897\n",
      "Epoch 179/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8291 - accuracy: 0.4495 - val_loss: 0.7995 - val_accuracy: 0.5901\n",
      "Epoch 180/2000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8286 - accuracy: 0.4514 - val_loss: 0.7979 - val_accuracy: 0.5905\n",
      "Epoch 181/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8277 - accuracy: 0.4512 - val_loss: 0.7998 - val_accuracy: 0.5907\n",
      "Epoch 182/2000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.8279 - accuracy: 0.4525 - val_loss: 0.7982 - val_accuracy: 0.5935\n",
      "Epoch 183/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8266 - accuracy: 0.4539 - val_loss: 0.7973 - val_accuracy: 0.5918\n",
      "Epoch 184/2000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.8261 - accuracy: 0.4535 - val_loss: 0.7978 - val_accuracy: 0.5931\n",
      "Epoch 185/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8261 - accuracy: 0.4554 - val_loss: 0.7976 - val_accuracy: 0.5939\n",
      "Epoch 186/2000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.8262 - accuracy: 0.4556 - val_loss: 0.7974 - val_accuracy: 0.5935\n",
      "Epoch 187/2000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.8271 - accuracy: 0.4560 - val_loss: 0.7965 - val_accuracy: 0.5950\n",
      "Epoch 188/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8257 - accuracy: 0.4564 - val_loss: 0.7969 - val_accuracy: 0.5935\n",
      "Epoch 189/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8255 - accuracy: 0.4565 - val_loss: 0.7961 - val_accuracy: 0.5944\n",
      "Epoch 190/2000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.8249 - accuracy: 0.4584 - val_loss: 0.7951 - val_accuracy: 0.5959\n",
      "Epoch 191/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8250 - accuracy: 0.4573 - val_loss: 0.7953 - val_accuracy: 0.5945\n",
      "Epoch 192/2000\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.8239 - accuracy: 0.4595 - val_loss: 0.7952 - val_accuracy: 0.5963\n",
      "Epoch 193/2000\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.8241 - accuracy: 0.4601 - val_loss: 0.7944 - val_accuracy: 0.5967\n",
      "Epoch 194/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8235 - accuracy: 0.4599 - val_loss: 0.7949 - val_accuracy: 0.5945\n",
      "Epoch 195/2000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.8234 - accuracy: 0.4596 - val_loss: 0.7939 - val_accuracy: 0.5952\n",
      "Epoch 196/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8246 - accuracy: 0.4596 - val_loss: 0.7939 - val_accuracy: 0.5965\n",
      "Epoch 197/2000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.8229 - accuracy: 0.4621 - val_loss: 0.7928 - val_accuracy: 0.5978\n",
      "Epoch 198/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8235 - accuracy: 0.4621 - val_loss: 0.7928 - val_accuracy: 0.5969\n",
      "Epoch 199/2000\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.8228 - accuracy: 0.4626 - val_loss: 0.7933 - val_accuracy: 0.5993\n",
      "Epoch 200/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8233 - accuracy: 0.4636 - val_loss: 0.7926 - val_accuracy: 0.5981\n",
      "Epoch 201/2000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8229 - accuracy: 0.4632 - val_loss: 0.7922 - val_accuracy: 0.5947\n",
      "Epoch 202/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.8230 - accuracy: 0.4619 - val_loss: 0.7914 - val_accuracy: 0.5971\n",
      "Epoch 203/2000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.8224 - accuracy: 0.4642 - val_loss: 0.7915 - val_accuracy: 0.5977\n",
      "Epoch 204/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8220 - accuracy: 0.4645 - val_loss: 0.7915 - val_accuracy: 0.5983\n",
      "Epoch 205/2000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.8226 - accuracy: 0.4656 - val_loss: 0.7908 - val_accuracy: 0.5999\n",
      "Epoch 206/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8216 - accuracy: 0.4673 - val_loss: 0.7902 - val_accuracy: 0.5966\n",
      "Epoch 207/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8214 - accuracy: 0.4649 - val_loss: 0.7898 - val_accuracy: 0.5972\n",
      "Epoch 208/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8215 - accuracy: 0.4674 - val_loss: 0.7907 - val_accuracy: 0.5988\n",
      "Epoch 209/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8211 - accuracy: 0.4670 - val_loss: 0.7905 - val_accuracy: 0.5990\n",
      "Epoch 210/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8209 - accuracy: 0.4672 - val_loss: 0.7888 - val_accuracy: 0.5980\n",
      "Epoch 211/2000\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.8200 - accuracy: 0.4683 - val_loss: 0.7898 - val_accuracy: 0.6001\n",
      "Epoch 212/2000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.8216 - accuracy: 0.4695 - val_loss: 0.7889 - val_accuracy: 0.6006\n",
      "Epoch 213/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8204 - accuracy: 0.4693 - val_loss: 0.7891 - val_accuracy: 0.5988\n",
      "Epoch 214/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8213 - accuracy: 0.4682 - val_loss: 0.7884 - val_accuracy: 0.5986\n",
      "Epoch 215/2000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.8198 - accuracy: 0.4691 - val_loss: 0.7882 - val_accuracy: 0.6008\n",
      "Epoch 216/2000\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.8196 - accuracy: 0.4714 - val_loss: 0.7882 - val_accuracy: 0.6022\n",
      "Epoch 217/2000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.8198 - accuracy: 0.4710 - val_loss: 0.7882 - val_accuracy: 0.5986\n",
      "Epoch 218/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8191 - accuracy: 0.4692 - val_loss: 0.7866 - val_accuracy: 0.5994\n",
      "Epoch 219/2000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.8197 - accuracy: 0.4706 - val_loss: 0.7871 - val_accuracy: 0.6009\n",
      "Epoch 220/2000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.8193 - accuracy: 0.4719 - val_loss: 0.7867 - val_accuracy: 0.6001\n",
      "Epoch 221/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8201 - accuracy: 0.4719 - val_loss: 0.7867 - val_accuracy: 0.6014\n",
      "Epoch 222/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8182 - accuracy: 0.4737 - val_loss: 0.7861 - val_accuracy: 0.5999\n",
      "Epoch 223/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8201 - accuracy: 0.4713 - val_loss: 0.7858 - val_accuracy: 0.5999\n",
      "Epoch 224/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8187 - accuracy: 0.4743 - val_loss: 0.7864 - val_accuracy: 0.6024\n",
      "Epoch 225/2000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.8183 - accuracy: 0.4744 - val_loss: 0.7855 - val_accuracy: 0.5997\n",
      "Epoch 226/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8177 - accuracy: 0.4731 - val_loss: 0.7855 - val_accuracy: 0.6014\n",
      "Epoch 227/2000\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.8177 - accuracy: 0.4755 - val_loss: 0.7850 - val_accuracy: 0.6025\n",
      "Epoch 228/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8174 - accuracy: 0.4758 - val_loss: 0.7852 - val_accuracy: 0.6006\n",
      "Epoch 229/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8180 - accuracy: 0.4755 - val_loss: 0.7846 - val_accuracy: 0.6023\n",
      "Epoch 230/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8171 - accuracy: 0.4770 - val_loss: 0.7848 - val_accuracy: 0.6023\n",
      "Epoch 231/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8177 - accuracy: 0.4765 - val_loss: 0.7845 - val_accuracy: 0.6013\n",
      "Epoch 232/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8175 - accuracy: 0.4763 - val_loss: 0.7841 - val_accuracy: 0.6018\n",
      "Epoch 233/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8178 - accuracy: 0.4773 - val_loss: 0.7836 - val_accuracy: 0.6023\n",
      "Epoch 234/2000\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.8166 - accuracy: 0.4785 - val_loss: 0.7837 - val_accuracy: 0.6029\n",
      "Epoch 235/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8162 - accuracy: 0.4788 - val_loss: 0.7842 - val_accuracy: 0.6025\n",
      "Epoch 236/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8167 - accuracy: 0.4787 - val_loss: 0.7832 - val_accuracy: 0.6019\n",
      "Epoch 237/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8168 - accuracy: 0.4789 - val_loss: 0.7833 - val_accuracy: 0.6028\n",
      "Epoch 238/2000\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.8166 - accuracy: 0.4805 - val_loss: 0.7830 - val_accuracy: 0.6049\n",
      "Epoch 239/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8167 - accuracy: 0.4806 - val_loss: 0.7824 - val_accuracy: 0.6010\n",
      "Epoch 240/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8170 - accuracy: 0.4786 - val_loss: 0.7823 - val_accuracy: 0.5998\n",
      "Epoch 241/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.8160 - accuracy: 0.4800 - val_loss: 0.7826 - val_accuracy: 0.6034\n",
      "Epoch 242/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8170 - accuracy: 0.4815 - val_loss: 0.7822 - val_accuracy: 0.6029\n",
      "Epoch 243/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8161 - accuracy: 0.4813 - val_loss: 0.7820 - val_accuracy: 0.6033\n",
      "Epoch 244/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8164 - accuracy: 0.4821 - val_loss: 0.7817 - val_accuracy: 0.6025\n",
      "Epoch 245/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8153 - accuracy: 0.4826 - val_loss: 0.7820 - val_accuracy: 0.6033\n",
      "Epoch 246/2000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.8170 - accuracy: 0.4831 - val_loss: 0.7815 - val_accuracy: 0.6056\n",
      "Epoch 247/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8157 - accuracy: 0.4830 - val_loss: 0.7808 - val_accuracy: 0.6027\n",
      "Epoch 248/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8155 - accuracy: 0.4824 - val_loss: 0.7810 - val_accuracy: 0.6027\n",
      "Epoch 249/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8156 - accuracy: 0.4835 - val_loss: 0.7807 - val_accuracy: 0.6048\n",
      "Epoch 250/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8156 - accuracy: 0.4847 - val_loss: 0.7802 - val_accuracy: 0.6046\n",
      "Epoch 251/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8161 - accuracy: 0.4852 - val_loss: 0.7809 - val_accuracy: 0.6049\n",
      "Epoch 252/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8154 - accuracy: 0.4855 - val_loss: 0.7795 - val_accuracy: 0.6041\n",
      "Epoch 253/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8150 - accuracy: 0.4848 - val_loss: 0.7796 - val_accuracy: 0.6042\n",
      "Epoch 254/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8157 - accuracy: 0.4854 - val_loss: 0.7804 - val_accuracy: 0.6056\n",
      "Epoch 255/2000\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.8146 - accuracy: 0.4864 - val_loss: 0.7790 - val_accuracy: 0.6066\n",
      "Epoch 256/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8147 - accuracy: 0.4876 - val_loss: 0.7796 - val_accuracy: 0.6038\n",
      "Epoch 257/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8150 - accuracy: 0.4859 - val_loss: 0.7790 - val_accuracy: 0.6056\n",
      "Epoch 258/2000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8140 - accuracy: 0.4882 - val_loss: 0.7790 - val_accuracy: 0.6058\n",
      "Epoch 259/2000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.8143 - accuracy: 0.4873 - val_loss: 0.7795 - val_accuracy: 0.6039\n",
      "Epoch 260/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8144 - accuracy: 0.4879 - val_loss: 0.7789 - val_accuracy: 0.6060\n",
      "Epoch 261/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8143 - accuracy: 0.4883 - val_loss: 0.7784 - val_accuracy: 0.6056\n",
      "Epoch 262/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8151 - accuracy: 0.4891 - val_loss: 0.7784 - val_accuracy: 0.6060\n",
      "Epoch 263/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8142 - accuracy: 0.4886 - val_loss: 0.7781 - val_accuracy: 0.6035\n",
      "Epoch 264/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8149 - accuracy: 0.4879 - val_loss: 0.7780 - val_accuracy: 0.6065\n",
      "Epoch 265/2000\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.8139 - accuracy: 0.4906 - val_loss: 0.7777 - val_accuracy: 0.6077\n",
      "Epoch 266/2000\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.8140 - accuracy: 0.4911 - val_loss: 0.7780 - val_accuracy: 0.6092\n",
      "Epoch 267/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8142 - accuracy: 0.4919 - val_loss: 0.7780 - val_accuracy: 0.6072\n",
      "Epoch 268/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8139 - accuracy: 0.4905 - val_loss: 0.7772 - val_accuracy: 0.6055\n",
      "Epoch 269/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8133 - accuracy: 0.4903 - val_loss: 0.7776 - val_accuracy: 0.6065\n",
      "Epoch 270/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8135 - accuracy: 0.4913 - val_loss: 0.7773 - val_accuracy: 0.6070\n",
      "Epoch 271/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8138 - accuracy: 0.4916 - val_loss: 0.7767 - val_accuracy: 0.6080\n",
      "Epoch 272/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8137 - accuracy: 0.4922 - val_loss: 0.7769 - val_accuracy: 0.6085\n",
      "Epoch 273/2000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.8133 - accuracy: 0.4922 - val_loss: 0.7774 - val_accuracy: 0.6076\n",
      "Epoch 274/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8138 - accuracy: 0.4925 - val_loss: 0.7768 - val_accuracy: 0.6083\n",
      "Epoch 275/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8139 - accuracy: 0.4924 - val_loss: 0.7768 - val_accuracy: 0.6087\n",
      "Epoch 276/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.8142 - accuracy: 0.4936 - val_loss: 0.7761 - val_accuracy: 0.6090\n",
      "Epoch 277/2000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8126 - accuracy: 0.4934 - val_loss: 0.7760 - val_accuracy: 0.6088\n",
      "Epoch 278/2000\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.8127 - accuracy: 0.4946 - val_loss: 0.7763 - val_accuracy: 0.6102\n",
      "Epoch 279/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8131 - accuracy: 0.4948 - val_loss: 0.7758 - val_accuracy: 0.6088\n",
      "Epoch 280/2000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8132 - accuracy: 0.4945 - val_loss: 0.7758 - val_accuracy: 0.6091\n",
      "Epoch 281/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8128 - accuracy: 0.4946 - val_loss: 0.7758 - val_accuracy: 0.6089\n",
      "Epoch 282/2000\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.8132 - accuracy: 0.4951 - val_loss: 0.7751 - val_accuracy: 0.6113\n",
      "Epoch 283/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8132 - accuracy: 0.4966 - val_loss: 0.7762 - val_accuracy: 0.6095\n",
      "Epoch 284/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8137 - accuracy: 0.4947 - val_loss: 0.7751 - val_accuracy: 0.6087\n",
      "Epoch 285/2000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.8124 - accuracy: 0.4962 - val_loss: 0.7748 - val_accuracy: 0.6126\n",
      "Epoch 286/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8135 - accuracy: 0.4980 - val_loss: 0.7753 - val_accuracy: 0.6106\n",
      "Epoch 287/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8125 - accuracy: 0.4962 - val_loss: 0.7745 - val_accuracy: 0.6108\n",
      "Epoch 288/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8120 - accuracy: 0.4972 - val_loss: 0.7750 - val_accuracy: 0.6116\n",
      "Epoch 289/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8126 - accuracy: 0.4980 - val_loss: 0.7747 - val_accuracy: 0.6110\n",
      "Epoch 290/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8129 - accuracy: 0.4975 - val_loss: 0.7744 - val_accuracy: 0.6125\n",
      "Epoch 291/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8128 - accuracy: 0.4988 - val_loss: 0.7744 - val_accuracy: 0.6121\n",
      "Epoch 292/2000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.8130 - accuracy: 0.4975 - val_loss: 0.7744 - val_accuracy: 0.6114\n",
      "Epoch 293/2000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.8125 - accuracy: 0.4988 - val_loss: 0.7737 - val_accuracy: 0.6137\n",
      "Epoch 294/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8122 - accuracy: 0.4999 - val_loss: 0.7746 - val_accuracy: 0.6131\n",
      "Epoch 295/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8135 - accuracy: 0.4997 - val_loss: 0.7736 - val_accuracy: 0.6131\n",
      "Epoch 296/2000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.8119 - accuracy: 0.4999 - val_loss: 0.7740 - val_accuracy: 0.6123\n",
      "Epoch 297/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8118 - accuracy: 0.4994 - val_loss: 0.7733 - val_accuracy: 0.6126\n",
      "Epoch 298/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8128 - accuracy: 0.4996 - val_loss: 0.7738 - val_accuracy: 0.6132\n",
      "Epoch 299/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8132 - accuracy: 0.5001 - val_loss: 0.7737 - val_accuracy: 0.6122\n",
      "Epoch 300/2000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.8123 - accuracy: 0.5004 - val_loss: 0.7738 - val_accuracy: 0.6142\n",
      "Epoch 301/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8113 - accuracy: 0.5022 - val_loss: 0.7734 - val_accuracy: 0.6137\n",
      "Epoch 302/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8122 - accuracy: 0.5010 - val_loss: 0.7732 - val_accuracy: 0.6138\n",
      "Epoch 303/2000\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.8126 - accuracy: 0.5009 - val_loss: 0.7729 - val_accuracy: 0.6147\n",
      "Epoch 304/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8132 - accuracy: 0.5018 - val_loss: 0.7730 - val_accuracy: 0.6143\n",
      "Epoch 305/2000\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.8119 - accuracy: 0.5026 - val_loss: 0.7735 - val_accuracy: 0.6153\n",
      "Epoch 306/2000\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.8118 - accuracy: 0.5041 - val_loss: 0.7727 - val_accuracy: 0.6155\n",
      "Epoch 307/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8111 - accuracy: 0.5034 - val_loss: 0.7726 - val_accuracy: 0.6137\n",
      "Epoch 308/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8112 - accuracy: 0.5023 - val_loss: 0.7728 - val_accuracy: 0.6138\n",
      "Epoch 309/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8114 - accuracy: 0.5031 - val_loss: 0.7723 - val_accuracy: 0.6148\n",
      "Epoch 310/2000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8113 - accuracy: 0.5035 - val_loss: 0.7727 - val_accuracy: 0.6155\n",
      "Epoch 311/2000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.8117 - accuracy: 0.5043 - val_loss: 0.7724 - val_accuracy: 0.6157\n",
      "Epoch 312/2000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.8109 - accuracy: 0.5046 - val_loss: 0.7717 - val_accuracy: 0.6148\n",
      "Epoch 313/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8112 - accuracy: 0.5048 - val_loss: 0.7723 - val_accuracy: 0.6147\n",
      "Epoch 314/2000\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.8114 - accuracy: 0.5052 - val_loss: 0.7719 - val_accuracy: 0.6159\n",
      "Epoch 315/2000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.8106 - accuracy: 0.5059 - val_loss: 0.7729 - val_accuracy: 0.6166\n",
      "Epoch 316/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8117 - accuracy: 0.5060 - val_loss: 0.7715 - val_accuracy: 0.6161\n",
      "Epoch 317/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8117 - accuracy: 0.5053 - val_loss: 0.7725 - val_accuracy: 0.6150\n",
      "Epoch 318/2000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.8113 - accuracy: 0.5055 - val_loss: 0.7714 - val_accuracy: 0.6167\n",
      "Epoch 319/2000\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.8114 - accuracy: 0.5073 - val_loss: 0.7718 - val_accuracy: 0.6170\n",
      "Epoch 320/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8107 - accuracy: 0.5074 - val_loss: 0.7716 - val_accuracy: 0.6160\n",
      "Epoch 321/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8119 - accuracy: 0.5068 - val_loss: 0.7718 - val_accuracy: 0.6169\n",
      "Epoch 322/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8109 - accuracy: 0.5076 - val_loss: 0.7713 - val_accuracy: 0.6170\n",
      "Epoch 323/2000\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.8104 - accuracy: 0.5086 - val_loss: 0.7718 - val_accuracy: 0.6171\n",
      "Epoch 324/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8107 - accuracy: 0.5083 - val_loss: 0.7721 - val_accuracy: 0.6160\n",
      "Epoch 325/2000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.8104 - accuracy: 0.5075 - val_loss: 0.7711 - val_accuracy: 0.6160\n",
      "Epoch 326/2000\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.8106 - accuracy: 0.5084 - val_loss: 0.7714 - val_accuracy: 0.6177\n",
      "Epoch 327/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8104 - accuracy: 0.5105 - val_loss: 0.7716 - val_accuracy: 0.6171\n",
      "Epoch 328/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8116 - accuracy: 0.5082 - val_loss: 0.7709 - val_accuracy: 0.6156\n",
      "Epoch 329/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8109 - accuracy: 0.5082 - val_loss: 0.7711 - val_accuracy: 0.6164\n",
      "Epoch 330/2000\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.8103 - accuracy: 0.5095 - val_loss: 0.7709 - val_accuracy: 0.6177\n",
      "Epoch 331/2000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.8104 - accuracy: 0.5098 - val_loss: 0.7712 - val_accuracy: 0.6181\n",
      "Epoch 332/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8104 - accuracy: 0.5106 - val_loss: 0.7707 - val_accuracy: 0.6175\n",
      "Epoch 333/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8107 - accuracy: 0.5101 - val_loss: 0.7709 - val_accuracy: 0.6161\n",
      "Epoch 334/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8101 - accuracy: 0.5103 - val_loss: 0.7708 - val_accuracy: 0.6175\n",
      "Epoch 335/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8107 - accuracy: 0.5108 - val_loss: 0.7710 - val_accuracy: 0.6172\n",
      "Epoch 336/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8107 - accuracy: 0.5109 - val_loss: 0.7704 - val_accuracy: 0.6176\n",
      "Epoch 337/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8106 - accuracy: 0.5105 - val_loss: 0.7704 - val_accuracy: 0.6179\n",
      "Epoch 338/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8104 - accuracy: 0.5118 - val_loss: 0.7704 - val_accuracy: 0.6168\n",
      "Epoch 339/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8103 - accuracy: 0.5113 - val_loss: 0.7701 - val_accuracy: 0.6180\n",
      "Epoch 340/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8100 - accuracy: 0.5121 - val_loss: 0.7701 - val_accuracy: 0.6179\n",
      "Epoch 341/2000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.8106 - accuracy: 0.5129 - val_loss: 0.7702 - val_accuracy: 0.6195\n",
      "Epoch 342/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8099 - accuracy: 0.5124 - val_loss: 0.7700 - val_accuracy: 0.6174\n",
      "Epoch 343/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8100 - accuracy: 0.5125 - val_loss: 0.7694 - val_accuracy: 0.6190\n",
      "Epoch 344/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8102 - accuracy: 0.5136 - val_loss: 0.7699 - val_accuracy: 0.6186\n",
      "Epoch 345/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8097 - accuracy: 0.5127 - val_loss: 0.7696 - val_accuracy: 0.6173\n",
      "Epoch 346/2000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8097 - accuracy: 0.5137 - val_loss: 0.7693 - val_accuracy: 0.6217\n",
      "Epoch 347/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8096 - accuracy: 0.5150 - val_loss: 0.7696 - val_accuracy: 0.6190\n",
      "Epoch 348/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8103 - accuracy: 0.5133 - val_loss: 0.7695 - val_accuracy: 0.6177\n",
      "Epoch 349/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8107 - accuracy: 0.5127 - val_loss: 0.7691 - val_accuracy: 0.6197\n",
      "Epoch 350/2000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.8097 - accuracy: 0.5157 - val_loss: 0.7691 - val_accuracy: 0.6219\n",
      "Epoch 351/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8104 - accuracy: 0.5161 - val_loss: 0.7689 - val_accuracy: 0.6212\n",
      "Epoch 352/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8099 - accuracy: 0.5146 - val_loss: 0.7694 - val_accuracy: 0.6180\n",
      "Epoch 353/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8109 - accuracy: 0.5121 - val_loss: 0.7692 - val_accuracy: 0.6180\n",
      "Epoch 354/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8106 - accuracy: 0.5147 - val_loss: 0.7692 - val_accuracy: 0.6215\n",
      "Epoch 355/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8098 - accuracy: 0.5162 - val_loss: 0.7688 - val_accuracy: 0.6198\n",
      "Epoch 356/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8101 - accuracy: 0.5151 - val_loss: 0.7692 - val_accuracy: 0.6208\n",
      "Epoch 357/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8099 - accuracy: 0.5164 - val_loss: 0.7689 - val_accuracy: 0.6214\n",
      "Epoch 358/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8106 - accuracy: 0.5159 - val_loss: 0.7688 - val_accuracy: 0.6198\n",
      "Epoch 359/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8097 - accuracy: 0.5162 - val_loss: 0.7684 - val_accuracy: 0.6210\n",
      "Epoch 360/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8098 - accuracy: 0.5164 - val_loss: 0.7690 - val_accuracy: 0.6206\n",
      "Epoch 361/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8103 - accuracy: 0.5159 - val_loss: 0.7687 - val_accuracy: 0.6215\n",
      "Epoch 362/2000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.8095 - accuracy: 0.5183 - val_loss: 0.7686 - val_accuracy: 0.6234\n",
      "Epoch 363/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8100 - accuracy: 0.5191 - val_loss: 0.7688 - val_accuracy: 0.6234\n",
      "Epoch 364/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.8094 - accuracy: 0.5172 - val_loss: 0.7683 - val_accuracy: 0.6208\n",
      "Epoch 365/2000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.8093 - accuracy: 0.5172 - val_loss: 0.7686 - val_accuracy: 0.6216\n",
      "Epoch 366/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8103 - accuracy: 0.5164 - val_loss: 0.7689 - val_accuracy: 0.6198\n",
      "Epoch 367/2000\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.8092 - accuracy: 0.5175 - val_loss: 0.7683 - val_accuracy: 0.6237\n",
      "Epoch 368/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8097 - accuracy: 0.5199 - val_loss: 0.7678 - val_accuracy: 0.6236\n",
      "Epoch 369/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8095 - accuracy: 0.5192 - val_loss: 0.7684 - val_accuracy: 0.6220\n",
      "Epoch 370/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8099 - accuracy: 0.5184 - val_loss: 0.7685 - val_accuracy: 0.6225\n",
      "Epoch 371/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8093 - accuracy: 0.5187 - val_loss: 0.7679 - val_accuracy: 0.6220\n",
      "Epoch 372/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8092 - accuracy: 0.5185 - val_loss: 0.7679 - val_accuracy: 0.6233\n",
      "Epoch 373/2000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.8097 - accuracy: 0.5199 - val_loss: 0.7682 - val_accuracy: 0.6244\n",
      "Epoch 374/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8094 - accuracy: 0.5200 - val_loss: 0.7684 - val_accuracy: 0.6225\n",
      "Epoch 375/2000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8097 - accuracy: 0.5194 - val_loss: 0.7677 - val_accuracy: 0.6222\n",
      "Epoch 376/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8087 - accuracy: 0.5194 - val_loss: 0.7683 - val_accuracy: 0.6229\n",
      "Epoch 377/2000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.8088 - accuracy: 0.5199 - val_loss: 0.7677 - val_accuracy: 0.6238\n",
      "Epoch 378/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8094 - accuracy: 0.5206 - val_loss: 0.7683 - val_accuracy: 0.6237\n",
      "Epoch 379/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8089 - accuracy: 0.5214 - val_loss: 0.7671 - val_accuracy: 0.6240\n",
      "Epoch 380/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8087 - accuracy: 0.5212 - val_loss: 0.7674 - val_accuracy: 0.6241\n",
      "Epoch 381/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8088 - accuracy: 0.5210 - val_loss: 0.7679 - val_accuracy: 0.6232\n",
      "Epoch 382/2000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.8095 - accuracy: 0.5217 - val_loss: 0.7677 - val_accuracy: 0.6248\n",
      "Epoch 383/2000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.8087 - accuracy: 0.5214 - val_loss: 0.7671 - val_accuracy: 0.6235\n",
      "Epoch 384/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8085 - accuracy: 0.5214 - val_loss: 0.7677 - val_accuracy: 0.6227\n",
      "Epoch 385/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8100 - accuracy: 0.5210 - val_loss: 0.7672 - val_accuracy: 0.6242\n",
      "Epoch 386/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8091 - accuracy: 0.5217 - val_loss: 0.7674 - val_accuracy: 0.6244\n",
      "Epoch 387/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8095 - accuracy: 0.5223 - val_loss: 0.7674 - val_accuracy: 0.6234\n",
      "Epoch 388/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8094 - accuracy: 0.5221 - val_loss: 0.7675 - val_accuracy: 0.6237\n",
      "Epoch 389/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8087 - accuracy: 0.5214 - val_loss: 0.7671 - val_accuracy: 0.6231\n",
      "Epoch 390/2000\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.8100 - accuracy: 0.5229 - val_loss: 0.7678 - val_accuracy: 0.6251\n",
      "Epoch 391/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8084 - accuracy: 0.5225 - val_loss: 0.7664 - val_accuracy: 0.6226\n",
      "Epoch 392/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8094 - accuracy: 0.5219 - val_loss: 0.7672 - val_accuracy: 0.6236\n",
      "Epoch 393/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8087 - accuracy: 0.5233 - val_loss: 0.7675 - val_accuracy: 0.6240\n",
      "Epoch 394/2000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.8088 - accuracy: 0.5227 - val_loss: 0.7668 - val_accuracy: 0.6254\n",
      "Epoch 395/2000\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.8086 - accuracy: 0.5245 - val_loss: 0.7677 - val_accuracy: 0.6261\n",
      "Epoch 396/2000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.8086 - accuracy: 0.5246 - val_loss: 0.7672 - val_accuracy: 0.6245\n",
      "Epoch 397/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8085 - accuracy: 0.5233 - val_loss: 0.7668 - val_accuracy: 0.6224\n",
      "Epoch 398/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8083 - accuracy: 0.5230 - val_loss: 0.7670 - val_accuracy: 0.6240\n",
      "Epoch 399/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.8085 - accuracy: 0.5239 - val_loss: 0.7670 - val_accuracy: 0.6251\n",
      "Epoch 400/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8085 - accuracy: 0.5247 - val_loss: 0.7667 - val_accuracy: 0.6233\n",
      "Epoch 401/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8082 - accuracy: 0.5246 - val_loss: 0.7668 - val_accuracy: 0.6251\n",
      "Epoch 402/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8096 - accuracy: 0.5236 - val_loss: 0.7665 - val_accuracy: 0.6235\n",
      "Epoch 403/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8088 - accuracy: 0.5249 - val_loss: 0.7666 - val_accuracy: 0.6248\n",
      "Epoch 404/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8083 - accuracy: 0.5257 - val_loss: 0.7666 - val_accuracy: 0.6248\n",
      "Epoch 405/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8080 - accuracy: 0.5244 - val_loss: 0.7665 - val_accuracy: 0.6226\n",
      "Epoch 406/2000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8083 - accuracy: 0.5243 - val_loss: 0.7671 - val_accuracy: 0.6249\n",
      "Epoch 407/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8084 - accuracy: 0.5247 - val_loss: 0.7662 - val_accuracy: 0.6244\n",
      "Epoch 408/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8083 - accuracy: 0.5253 - val_loss: 0.7662 - val_accuracy: 0.6251\n",
      "Epoch 409/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8081 - accuracy: 0.5260 - val_loss: 0.7660 - val_accuracy: 0.6255\n",
      "Epoch 410/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8079 - accuracy: 0.5260 - val_loss: 0.7670 - val_accuracy: 0.6241\n",
      "Epoch 411/2000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.8088 - accuracy: 0.5260 - val_loss: 0.7659 - val_accuracy: 0.6249\n",
      "Epoch 412/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8079 - accuracy: 0.5266 - val_loss: 0.7664 - val_accuracy: 0.6250\n",
      "Epoch 413/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8083 - accuracy: 0.5261 - val_loss: 0.7666 - val_accuracy: 0.6254\n",
      "Epoch 414/2000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8085 - accuracy: 0.5270 - val_loss: 0.7659 - val_accuracy: 0.6259\n",
      "Epoch 415/2000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.8078 - accuracy: 0.5275 - val_loss: 0.7658 - val_accuracy: 0.6256\n",
      "Epoch 416/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8077 - accuracy: 0.5273 - val_loss: 0.7664 - val_accuracy: 0.6254\n",
      "Epoch 417/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8086 - accuracy: 0.5268 - val_loss: 0.7657 - val_accuracy: 0.6237\n",
      "Epoch 418/2000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.8079 - accuracy: 0.5251 - val_loss: 0.7664 - val_accuracy: 0.6233\n",
      "Epoch 419/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8100 - accuracy: 0.5263 - val_loss: 0.7658 - val_accuracy: 0.6261\n",
      "Epoch 420/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8084 - accuracy: 0.5273 - val_loss: 0.7657 - val_accuracy: 0.6249\n",
      "Epoch 421/2000\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.8095 - accuracy: 0.5263 - val_loss: 0.7656 - val_accuracy: 0.6264\n",
      "Epoch 422/2000\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.8084 - accuracy: 0.5285 - val_loss: 0.7666 - val_accuracy: 0.6270\n",
      "Epoch 423/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8081 - accuracy: 0.5286 - val_loss: 0.7657 - val_accuracy: 0.6252\n",
      "Epoch 424/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8091 - accuracy: 0.5267 - val_loss: 0.7661 - val_accuracy: 0.6244\n",
      "Epoch 425/2000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.8079 - accuracy: 0.5267 - val_loss: 0.7649 - val_accuracy: 0.6258\n",
      "Epoch 426/2000\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.8079 - accuracy: 0.5279 - val_loss: 0.7654 - val_accuracy: 0.6273\n",
      "Epoch 427/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8084 - accuracy: 0.5292 - val_loss: 0.7663 - val_accuracy: 0.6267\n",
      "Epoch 428/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8083 - accuracy: 0.5289 - val_loss: 0.7651 - val_accuracy: 0.6260\n",
      "Epoch 429/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8080 - accuracy: 0.5285 - val_loss: 0.7654 - val_accuracy: 0.6266\n",
      "Epoch 430/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8086 - accuracy: 0.5290 - val_loss: 0.7654 - val_accuracy: 0.6259\n",
      "Epoch 431/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8083 - accuracy: 0.5287 - val_loss: 0.7649 - val_accuracy: 0.6271\n",
      "Epoch 432/2000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8075 - accuracy: 0.5292 - val_loss: 0.7658 - val_accuracy: 0.6266\n",
      "Epoch 433/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8076 - accuracy: 0.5286 - val_loss: 0.7654 - val_accuracy: 0.6269\n",
      "Epoch 434/2000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.8078 - accuracy: 0.5305 - val_loss: 0.7647 - val_accuracy: 0.6284\n",
      "Epoch 435/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8092 - accuracy: 0.5296 - val_loss: 0.7658 - val_accuracy: 0.6269\n",
      "Epoch 436/2000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8081 - accuracy: 0.5304 - val_loss: 0.7654 - val_accuracy: 0.6280\n",
      "Epoch 437/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8084 - accuracy: 0.5307 - val_loss: 0.7655 - val_accuracy: 0.6278\n",
      "Epoch 438/2000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8076 - accuracy: 0.5298 - val_loss: 0.7650 - val_accuracy: 0.6266\n",
      "Epoch 439/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8076 - accuracy: 0.5303 - val_loss: 0.7647 - val_accuracy: 0.6284\n",
      "Epoch 440/2000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8078 - accuracy: 0.5310 - val_loss: 0.7653 - val_accuracy: 0.6277\n",
      "Epoch 441/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8077 - accuracy: 0.5302 - val_loss: 0.7654 - val_accuracy: 0.6272\n",
      "Epoch 442/2000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8079 - accuracy: 0.5297 - val_loss: 0.7654 - val_accuracy: 0.6266\n",
      "Epoch 443/2000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8087 - accuracy: 0.5295 - val_loss: 0.7650 - val_accuracy: 0.6279\n",
      "Epoch 444/2000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8081 - accuracy: 0.5308 - val_loss: 0.7649 - val_accuracy: 0.6283\n",
      "Epoch 445/2000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.8077 - accuracy: 0.5323 - val_loss: 0.7651 - val_accuracy: 0.6282\n",
      "Epoch 446/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8077 - accuracy: 0.5317 - val_loss: 0.7652 - val_accuracy: 0.6279\n",
      "Epoch 447/2000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8079 - accuracy: 0.5301 - val_loss: 0.7652 - val_accuracy: 0.6266\n",
      "Epoch 448/2000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.8078 - accuracy: 0.5303 - val_loss: 0.7642 - val_accuracy: 0.6275\n",
      "Epoch 449/2000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.8076 - accuracy: 0.5315 - val_loss: 0.7646 - val_accuracy: 0.6287\n",
      "Epoch 450/2000\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.8074 - accuracy: 0.5328 - val_loss: 0.7652 - val_accuracy: 0.6289\n",
      "Epoch 451/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8079 - accuracy: 0.5319 - val_loss: 0.7647 - val_accuracy: 0.6273\n",
      "Epoch 452/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8080 - accuracy: 0.5313 - val_loss: 0.7651 - val_accuracy: 0.6278\n",
      "Epoch 453/2000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8078 - accuracy: 0.5311 - val_loss: 0.7644 - val_accuracy: 0.6280\n",
      "Epoch 454/2000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.8070 - accuracy: 0.5318 - val_loss: 0.7645 - val_accuracy: 0.6280\n",
      "Epoch 455/2000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8075 - accuracy: 0.5319 - val_loss: 0.7653 - val_accuracy: 0.6281\n",
      "Epoch 456/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8078 - accuracy: 0.5324 - val_loss: 0.7643 - val_accuracy: 0.6286\n",
      "Epoch 457/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8069 - accuracy: 0.5335 - val_loss: 0.7647 - val_accuracy: 0.6287\n",
      "Epoch 458/2000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8073 - accuracy: 0.5329 - val_loss: 0.7643 - val_accuracy: 0.6285\n",
      "Epoch 459/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 22ms/step - loss: 0.8078 - accuracy: 0.5319 - val_loss: 0.7646 - val_accuracy: 0.6291\n",
      "Epoch 460/2000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8077 - accuracy: 0.5336 - val_loss: 0.7649 - val_accuracy: 0.6281\n",
      "Epoch 461/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8072 - accuracy: 0.5335 - val_loss: 0.7647 - val_accuracy: 0.6278\n",
      "Epoch 462/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8084 - accuracy: 0.5331 - val_loss: 0.7640 - val_accuracy: 0.6286\n",
      "Epoch 463/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8075 - accuracy: 0.5332 - val_loss: 0.7646 - val_accuracy: 0.6277\n",
      "Epoch 464/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8077 - accuracy: 0.5320 - val_loss: 0.7646 - val_accuracy: 0.6274\n",
      "Epoch 465/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8076 - accuracy: 0.5321 - val_loss: 0.7642 - val_accuracy: 0.6288\n",
      "Epoch 466/2000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.8070 - accuracy: 0.5339 - val_loss: 0.7649 - val_accuracy: 0.6294\n",
      "Epoch 467/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8069 - accuracy: 0.5354 - val_loss: 0.7639 - val_accuracy: 0.6294\n",
      "Epoch 468/2000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8081 - accuracy: 0.5334 - val_loss: 0.7642 - val_accuracy: 0.6284\n",
      "Epoch 469/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8083 - accuracy: 0.5338 - val_loss: 0.7637 - val_accuracy: 0.6293\n",
      "Epoch 470/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8072 - accuracy: 0.5342 - val_loss: 0.7640 - val_accuracy: 0.6291\n",
      "Epoch 471/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8079 - accuracy: 0.5339 - val_loss: 0.7642 - val_accuracy: 0.6276\n",
      "Epoch 472/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8076 - accuracy: 0.5337 - val_loss: 0.7632 - val_accuracy: 0.6288\n",
      "Epoch 473/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.8069 - accuracy: 0.5344 - val_loss: 0.7644 - val_accuracy: 0.6281\n",
      "Epoch 474/2000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.8076 - accuracy: 0.5344 - val_loss: 0.7631 - val_accuracy: 0.6295\n",
      "Epoch 475/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8071 - accuracy: 0.5359 - val_loss: 0.7643 - val_accuracy: 0.6287\n",
      "Epoch 476/2000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.8073 - accuracy: 0.5349 - val_loss: 0.7636 - val_accuracy: 0.6281\n",
      "Epoch 477/2000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.8069 - accuracy: 0.5345 - val_loss: 0.7635 - val_accuracy: 0.6300\n",
      "Epoch 478/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8069 - accuracy: 0.5354 - val_loss: 0.7641 - val_accuracy: 0.6298\n",
      "Epoch 479/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8071 - accuracy: 0.5359 - val_loss: 0.7640 - val_accuracy: 0.6281\n",
      "Epoch 480/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8075 - accuracy: 0.5347 - val_loss: 0.7634 - val_accuracy: 0.6277\n",
      "Epoch 481/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8071 - accuracy: 0.5350 - val_loss: 0.7634 - val_accuracy: 0.6291\n",
      "Epoch 482/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8067 - accuracy: 0.5355 - val_loss: 0.7642 - val_accuracy: 0.6286\n",
      "Epoch 483/2000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.8070 - accuracy: 0.5360 - val_loss: 0.7634 - val_accuracy: 0.6294\n",
      "Epoch 484/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8073 - accuracy: 0.5360 - val_loss: 0.7633 - val_accuracy: 0.6298\n",
      "Epoch 485/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8074 - accuracy: 0.5364 - val_loss: 0.7643 - val_accuracy: 0.6285\n",
      "Epoch 486/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8071 - accuracy: 0.5357 - val_loss: 0.7634 - val_accuracy: 0.6286\n",
      "Epoch 487/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8069 - accuracy: 0.5359 - val_loss: 0.7636 - val_accuracy: 0.6287\n",
      "Epoch 488/2000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.8067 - accuracy: 0.5362 - val_loss: 0.7633 - val_accuracy: 0.6293\n",
      "Epoch 489/2000\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.8069 - accuracy: 0.5369 - val_loss: 0.7634 - val_accuracy: 0.6302\n",
      "Epoch 490/2000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8076 - accuracy: 0.5363 - val_loss: 0.7636 - val_accuracy: 0.6283\n",
      "Epoch 491/2000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8063 - accuracy: 0.5369 - val_loss: 0.7633 - val_accuracy: 0.6301\n",
      "Epoch 492/2000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.8069 - accuracy: 0.5381 - val_loss: 0.7644 - val_accuracy: 0.6279\n",
      "Epoch 493/2000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8069 - accuracy: 0.5372 - val_loss: 0.7630 - val_accuracy: 0.6282\n",
      "Epoch 494/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8068 - accuracy: 0.5356 - val_loss: 0.7633 - val_accuracy: 0.6290\n",
      "Epoch 495/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8067 - accuracy: 0.5369 - val_loss: 0.7640 - val_accuracy: 0.6279\n",
      "Epoch 496/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8078 - accuracy: 0.5366 - val_loss: 0.7634 - val_accuracy: 0.6291\n",
      "Epoch 497/2000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.8068 - accuracy: 0.5380 - val_loss: 0.7633 - val_accuracy: 0.6307\n",
      "Epoch 498/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8071 - accuracy: 0.5386 - val_loss: 0.7637 - val_accuracy: 0.6282\n",
      "Epoch 499/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8074 - accuracy: 0.5367 - val_loss: 0.7634 - val_accuracy: 0.6270\n",
      "Epoch 500/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8070 - accuracy: 0.5365 - val_loss: 0.7629 - val_accuracy: 0.6302\n",
      "Epoch 501/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8067 - accuracy: 0.5376 - val_loss: 0.7634 - val_accuracy: 0.6296\n",
      "Epoch 502/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8065 - accuracy: 0.5379 - val_loss: 0.7638 - val_accuracy: 0.6278\n",
      "Epoch 503/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8073 - accuracy: 0.5366 - val_loss: 0.7626 - val_accuracy: 0.6298\n",
      "Epoch 504/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8069 - accuracy: 0.5378 - val_loss: 0.7635 - val_accuracy: 0.6292\n",
      "Epoch 505/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8072 - accuracy: 0.5385 - val_loss: 0.7632 - val_accuracy: 0.6295\n",
      "Epoch 506/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8063 - accuracy: 0.5373 - val_loss: 0.7631 - val_accuracy: 0.6270\n",
      "Epoch 507/2000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.8079 - accuracy: 0.5367 - val_loss: 0.7625 - val_accuracy: 0.6281\n",
      "Epoch 508/2000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.8072 - accuracy: 0.5391 - val_loss: 0.7638 - val_accuracy: 0.6309\n",
      "Epoch 509/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8071 - accuracy: 0.5397 - val_loss: 0.7623 - val_accuracy: 0.6299\n",
      "Epoch 510/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8064 - accuracy: 0.5385 - val_loss: 0.7643 - val_accuracy: 0.6275\n",
      "Epoch 511/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8066 - accuracy: 0.5381 - val_loss: 0.7626 - val_accuracy: 0.6282\n",
      "Epoch 512/2000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.8069 - accuracy: 0.5369 - val_loss: 0.7637 - val_accuracy: 0.6285\n",
      "Epoch 513/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8066 - accuracy: 0.5381 - val_loss: 0.7631 - val_accuracy: 0.6288\n",
      "Epoch 514/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8071 - accuracy: 0.5391 - val_loss: 0.7632 - val_accuracy: 0.6282\n",
      "Epoch 515/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8062 - accuracy: 0.5388 - val_loss: 0.7628 - val_accuracy: 0.6295\n",
      "Epoch 516/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8065 - accuracy: 0.5394 - val_loss: 0.7628 - val_accuracy: 0.6291\n",
      "Epoch 517/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8071 - accuracy: 0.5372 - val_loss: 0.7624 - val_accuracy: 0.6280\n",
      "Epoch 518/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8067 - accuracy: 0.5389 - val_loss: 0.7642 - val_accuracy: 0.6282\n",
      "Epoch 519/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8084 - accuracy: 0.5391 - val_loss: 0.7618 - val_accuracy: 0.6278\n",
      "Epoch 520/2000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8069 - accuracy: 0.5375 - val_loss: 0.7641 - val_accuracy: 0.6280\n",
      "Epoch 521/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8063 - accuracy: 0.5394 - val_loss: 0.7619 - val_accuracy: 0.6293\n",
      "Epoch 522/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8069 - accuracy: 0.5398 - val_loss: 0.7636 - val_accuracy: 0.6300\n",
      "Epoch 523/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8064 - accuracy: 0.5400 - val_loss: 0.7617 - val_accuracy: 0.6280\n",
      "Epoch 524/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8060 - accuracy: 0.5401 - val_loss: 0.7637 - val_accuracy: 0.6292\n",
      "Epoch 525/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8072 - accuracy: 0.5391 - val_loss: 0.7626 - val_accuracy: 0.6275\n",
      "Epoch 526/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8064 - accuracy: 0.5391 - val_loss: 0.7624 - val_accuracy: 0.6297\n",
      "Epoch 527/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8066 - accuracy: 0.5406 - val_loss: 0.7626 - val_accuracy: 0.6285\n",
      "Epoch 528/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8062 - accuracy: 0.5396 - val_loss: 0.7627 - val_accuracy: 0.6277\n",
      "Epoch 529/2000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.8061 - accuracy: 0.5389 - val_loss: 0.7627 - val_accuracy: 0.6280\n",
      "Epoch 530/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8062 - accuracy: 0.5401 - val_loss: 0.7620 - val_accuracy: 0.6292\n",
      "Epoch 531/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8058 - accuracy: 0.5409 - val_loss: 0.7629 - val_accuracy: 0.6284\n",
      "Epoch 532/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8062 - accuracy: 0.5403 - val_loss: 0.7622 - val_accuracy: 0.6276\n",
      "Epoch 533/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8061 - accuracy: 0.5396 - val_loss: 0.7619 - val_accuracy: 0.6288\n",
      "Epoch 534/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8059 - accuracy: 0.5408 - val_loss: 0.7627 - val_accuracy: 0.6288\n",
      "Epoch 535/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8062 - accuracy: 0.5412 - val_loss: 0.7617 - val_accuracy: 0.6283\n",
      "Epoch 536/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8061 - accuracy: 0.5404 - val_loss: 0.7626 - val_accuracy: 0.6287\n",
      "Epoch 537/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8065 - accuracy: 0.5405 - val_loss: 0.7621 - val_accuracy: 0.6282\n",
      "Epoch 538/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8062 - accuracy: 0.5412 - val_loss: 0.7629 - val_accuracy: 0.6278\n",
      "Epoch 539/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8063 - accuracy: 0.5405 - val_loss: 0.7626 - val_accuracy: 0.6278\n",
      "Epoch 540/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8074 - accuracy: 0.5386 - val_loss: 0.7620 - val_accuracy: 0.6273\n",
      "Epoch 541/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8065 - accuracy: 0.5411 - val_loss: 0.7625 - val_accuracy: 0.6277\n",
      "Epoch 542/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8064 - accuracy: 0.5408 - val_loss: 0.7626 - val_accuracy: 0.6278\n",
      "Epoch 543/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8059 - accuracy: 0.5405 - val_loss: 0.7617 - val_accuracy: 0.6276\n",
      "Epoch 544/2000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.8061 - accuracy: 0.5404 - val_loss: 0.7625 - val_accuracy: 0.6275\n",
      "Epoch 545/2000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8064 - accuracy: 0.5409 - val_loss: 0.7617 - val_accuracy: 0.6277\n",
      "Epoch 546/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.8063 - accuracy: 0.5420 - val_loss: 0.7628 - val_accuracy: 0.6284\n",
      "Epoch 547/2000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.8073 - accuracy: 0.5409 - val_loss: 0.7621 - val_accuracy: 0.6272\n",
      "Epoch 548/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8062 - accuracy: 0.5405 - val_loss: 0.7625 - val_accuracy: 0.6279\n",
      "Epoch 549/2000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.8058 - accuracy: 0.5415 - val_loss: 0.7617 - val_accuracy: 0.6280\n",
      "Epoch 550/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8064 - accuracy: 0.5419 - val_loss: 0.7624 - val_accuracy: 0.6273\n",
      "Epoch 551/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8058 - accuracy: 0.5409 - val_loss: 0.7618 - val_accuracy: 0.6277\n",
      "Epoch 552/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8060 - accuracy: 0.5415 - val_loss: 0.7619 - val_accuracy: 0.6280\n",
      "Epoch 553/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8068 - accuracy: 0.5419 - val_loss: 0.7617 - val_accuracy: 0.6286\n",
      "Epoch 554/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8065 - accuracy: 0.5416 - val_loss: 0.7630 - val_accuracy: 0.6271\n",
      "Epoch 555/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8070 - accuracy: 0.5402 - val_loss: 0.7615 - val_accuracy: 0.6277\n",
      "Epoch 556/2000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8062 - accuracy: 0.5415 - val_loss: 0.7624 - val_accuracy: 0.6282\n",
      "Epoch 557/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8058 - accuracy: 0.5425 - val_loss: 0.7614 - val_accuracy: 0.6277\n",
      "Epoch 558/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8060 - accuracy: 0.5416 - val_loss: 0.7621 - val_accuracy: 0.6273\n",
      "Epoch 559/2000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8063 - accuracy: 0.5411 - val_loss: 0.7622 - val_accuracy: 0.6268\n",
      "Epoch 560/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8060 - accuracy: 0.5422 - val_loss: 0.7615 - val_accuracy: 0.6282\n",
      "Epoch 561/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8058 - accuracy: 0.5429 - val_loss: 0.7618 - val_accuracy: 0.6282\n",
      "Epoch 562/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8065 - accuracy: 0.5413 - val_loss: 0.7623 - val_accuracy: 0.6272\n",
      "Epoch 563/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8061 - accuracy: 0.5422 - val_loss: 0.7613 - val_accuracy: 0.6269\n",
      "Epoch 564/2000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8069 - accuracy: 0.5402 - val_loss: 0.7623 - val_accuracy: 0.6279\n",
      "Epoch 565/2000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.8060 - accuracy: 0.5423 - val_loss: 0.7621 - val_accuracy: 0.6276\n",
      "Epoch 566/2000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.8063 - accuracy: 0.5417 - val_loss: 0.7613 - val_accuracy: 0.6272\n",
      "Epoch 567/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8059 - accuracy: 0.5416 - val_loss: 0.7621 - val_accuracy: 0.6282\n",
      "Epoch 568/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8059 - accuracy: 0.5434 - val_loss: 0.7612 - val_accuracy: 0.6278\n",
      "Epoch 569/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8056 - accuracy: 0.5429 - val_loss: 0.7620 - val_accuracy: 0.6276\n",
      "Epoch 570/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8057 - accuracy: 0.5426 - val_loss: 0.7616 - val_accuracy: 0.6268\n",
      "Epoch 571/2000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8060 - accuracy: 0.5419 - val_loss: 0.7619 - val_accuracy: 0.6273\n",
      "Epoch 572/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8060 - accuracy: 0.5434 - val_loss: 0.7613 - val_accuracy: 0.6268\n",
      "Epoch 573/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8061 - accuracy: 0.5420 - val_loss: 0.7614 - val_accuracy: 0.6275\n",
      "Epoch 574/2000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.8056 - accuracy: 0.5429 - val_loss: 0.7619 - val_accuracy: 0.6273\n",
      "Epoch 575/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8055 - accuracy: 0.5432 - val_loss: 0.7619 - val_accuracy: 0.6261\n",
      "Epoch 576/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8057 - accuracy: 0.5418 - val_loss: 0.7614 - val_accuracy: 0.6261\n",
      "Epoch 577/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8063 - accuracy: 0.5417 - val_loss: 0.7613 - val_accuracy: 0.6276\n",
      "Epoch 578/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8053 - accuracy: 0.5436 - val_loss: 0.7624 - val_accuracy: 0.6265\n",
      "Epoch 579/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8057 - accuracy: 0.5428 - val_loss: 0.7609 - val_accuracy: 0.6270\n",
      "Epoch 580/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8067 - accuracy: 0.5430 - val_loss: 0.7612 - val_accuracy: 0.6271\n",
      "Epoch 581/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8055 - accuracy: 0.5429 - val_loss: 0.7623 - val_accuracy: 0.6263\n",
      "Epoch 582/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8055 - accuracy: 0.5429 - val_loss: 0.7608 - val_accuracy: 0.6269\n",
      "Epoch 583/2000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.8058 - accuracy: 0.5434 - val_loss: 0.7614 - val_accuracy: 0.6269\n",
      "Epoch 584/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8064 - accuracy: 0.5429 - val_loss: 0.7616 - val_accuracy: 0.6260\n",
      "Epoch 585/2000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.8063 - accuracy: 0.5420 - val_loss: 0.7620 - val_accuracy: 0.6269\n",
      "Epoch 586/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8057 - accuracy: 0.5430 - val_loss: 0.7608 - val_accuracy: 0.6268\n",
      "Epoch 587/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8062 - accuracy: 0.5431 - val_loss: 0.7621 - val_accuracy: 0.6262\n",
      "Epoch 588/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8056 - accuracy: 0.5431 - val_loss: 0.7608 - val_accuracy: 0.6271\n",
      "Epoch 589/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8052 - accuracy: 0.5442 - val_loss: 0.7617 - val_accuracy: 0.6269\n",
      "Epoch 590/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8054 - accuracy: 0.5442 - val_loss: 0.7616 - val_accuracy: 0.6266\n",
      "Epoch 591/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8061 - accuracy: 0.5423 - val_loss: 0.7609 - val_accuracy: 0.6263\n",
      "Epoch 592/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8056 - accuracy: 0.5434 - val_loss: 0.7618 - val_accuracy: 0.6266\n",
      "Epoch 593/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8060 - accuracy: 0.5437 - val_loss: 0.7607 - val_accuracy: 0.6269\n",
      "Epoch 594/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8053 - accuracy: 0.5443 - val_loss: 0.7614 - val_accuracy: 0.6275\n",
      "Epoch 595/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8060 - accuracy: 0.5440 - val_loss: 0.7610 - val_accuracy: 0.6270\n",
      "Epoch 596/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8054 - accuracy: 0.5435 - val_loss: 0.7610 - val_accuracy: 0.6268\n",
      "Epoch 597/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8059 - accuracy: 0.5432 - val_loss: 0.7614 - val_accuracy: 0.6254\n",
      "Epoch 598/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8058 - accuracy: 0.5437 - val_loss: 0.7604 - val_accuracy: 0.6279\n",
      "Epoch 599/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8055 - accuracy: 0.5447 - val_loss: 0.7620 - val_accuracy: 0.6262\n",
      "Epoch 600/2000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.8060 - accuracy: 0.5432 - val_loss: 0.7605 - val_accuracy: 0.6263\n",
      "Epoch 601/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8058 - accuracy: 0.5437 - val_loss: 0.7609 - val_accuracy: 0.6262\n",
      "Epoch 602/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.8059 - accuracy: 0.5436 - val_loss: 0.7609 - val_accuracy: 0.6268\n",
      "Epoch 603/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8055 - accuracy: 0.5444 - val_loss: 0.7607 - val_accuracy: 0.6281\n",
      "Epoch 604/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8055 - accuracy: 0.5450 - val_loss: 0.7608 - val_accuracy: 0.6262\n",
      "Epoch 605/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8054 - accuracy: 0.5438 - val_loss: 0.7618 - val_accuracy: 0.6257\n",
      "Epoch 606/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8062 - accuracy: 0.5437 - val_loss: 0.7600 - val_accuracy: 0.6271\n",
      "Epoch 607/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8056 - accuracy: 0.5448 - val_loss: 0.7614 - val_accuracy: 0.6266\n",
      "Epoch 608/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8059 - accuracy: 0.5447 - val_loss: 0.7607 - val_accuracy: 0.6263\n",
      "Epoch 609/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8061 - accuracy: 0.5432 - val_loss: 0.7616 - val_accuracy: 0.6251\n",
      "Epoch 610/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8062 - accuracy: 0.5443 - val_loss: 0.7603 - val_accuracy: 0.6270\n",
      "Epoch 611/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8054 - accuracy: 0.5451 - val_loss: 0.7611 - val_accuracy: 0.6272\n",
      "Epoch 612/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8066 - accuracy: 0.5434 - val_loss: 0.7602 - val_accuracy: 0.6262\n",
      "Epoch 613/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8051 - accuracy: 0.5448 - val_loss: 0.7611 - val_accuracy: 0.6260\n",
      "Epoch 614/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8050 - accuracy: 0.5440 - val_loss: 0.7606 - val_accuracy: 0.6267\n",
      "Epoch 615/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8052 - accuracy: 0.5449 - val_loss: 0.7607 - val_accuracy: 0.6267\n",
      "Epoch 616/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8054 - accuracy: 0.5455 - val_loss: 0.7611 - val_accuracy: 0.6265\n",
      "Epoch 617/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8052 - accuracy: 0.5445 - val_loss: 0.7606 - val_accuracy: 0.6266\n",
      "Epoch 618/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8049 - accuracy: 0.5443 - val_loss: 0.7612 - val_accuracy: 0.6255\n",
      "Epoch 619/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8056 - accuracy: 0.5446 - val_loss: 0.7604 - val_accuracy: 0.6258\n",
      "Epoch 620/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8054 - accuracy: 0.5446 - val_loss: 0.7607 - val_accuracy: 0.6264\n",
      "Epoch 621/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.8062 - accuracy: 0.5437 - val_loss: 0.7607 - val_accuracy: 0.6262\n",
      "Epoch 622/2000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.8051 - accuracy: 0.5449 - val_loss: 0.7608 - val_accuracy: 0.6257\n",
      "Epoch 623/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8055 - accuracy: 0.5445 - val_loss: 0.7603 - val_accuracy: 0.6266\n",
      "Epoch 624/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8056 - accuracy: 0.5448 - val_loss: 0.7609 - val_accuracy: 0.6266\n",
      "Epoch 625/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8052 - accuracy: 0.5452 - val_loss: 0.7599 - val_accuracy: 0.6265\n",
      "Epoch 626/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8060 - accuracy: 0.5451 - val_loss: 0.7611 - val_accuracy: 0.6266\n",
      "Epoch 627/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8056 - accuracy: 0.5447 - val_loss: 0.7601 - val_accuracy: 0.6263\n",
      "Epoch 628/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8055 - accuracy: 0.5454 - val_loss: 0.7619 - val_accuracy: 0.6247\n",
      "Epoch 629/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8057 - accuracy: 0.5446 - val_loss: 0.7600 - val_accuracy: 0.6266\n",
      "Epoch 630/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8061 - accuracy: 0.5446 - val_loss: 0.7609 - val_accuracy: 0.6257\n",
      "Epoch 631/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8051 - accuracy: 0.5454 - val_loss: 0.7603 - val_accuracy: 0.6257\n",
      "Epoch 632/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8051 - accuracy: 0.5449 - val_loss: 0.7608 - val_accuracy: 0.6262\n",
      "Epoch 633/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8054 - accuracy: 0.5447 - val_loss: 0.7605 - val_accuracy: 0.6259\n",
      "Epoch 634/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8061 - accuracy: 0.5454 - val_loss: 0.7602 - val_accuracy: 0.6271\n",
      "Epoch 635/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8052 - accuracy: 0.5457 - val_loss: 0.7603 - val_accuracy: 0.6265\n",
      "Epoch 636/2000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.8048 - accuracy: 0.5456 - val_loss: 0.7605 - val_accuracy: 0.6263\n",
      "Epoch 637/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8050 - accuracy: 0.5454 - val_loss: 0.7606 - val_accuracy: 0.6256\n",
      "Epoch 638/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8055 - accuracy: 0.5457 - val_loss: 0.7604 - val_accuracy: 0.6268\n",
      "Epoch 639/2000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8054 - accuracy: 0.5455 - val_loss: 0.7594 - val_accuracy: 0.6260\n",
      "Epoch 640/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8053 - accuracy: 0.5451 - val_loss: 0.7604 - val_accuracy: 0.6259\n",
      "Epoch 641/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8052 - accuracy: 0.5453 - val_loss: 0.7603 - val_accuracy: 0.6251\n",
      "Epoch 642/2000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8051 - accuracy: 0.5456 - val_loss: 0.7600 - val_accuracy: 0.6259\n",
      "Epoch 643/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8055 - accuracy: 0.5450 - val_loss: 0.7606 - val_accuracy: 0.6254\n",
      "Epoch 644/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8049 - accuracy: 0.5449 - val_loss: 0.7606 - val_accuracy: 0.6243\n",
      "Epoch 645/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8053 - accuracy: 0.5446 - val_loss: 0.7598 - val_accuracy: 0.6258\n",
      "Epoch 646/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8050 - accuracy: 0.5460 - val_loss: 0.7606 - val_accuracy: 0.6269\n",
      "Epoch 647/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8057 - accuracy: 0.5458 - val_loss: 0.7608 - val_accuracy: 0.6249\n",
      "Epoch 648/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8053 - accuracy: 0.5447 - val_loss: 0.7597 - val_accuracy: 0.6240\n",
      "Epoch 649/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8048 - accuracy: 0.5458 - val_loss: 0.7598 - val_accuracy: 0.6269\n",
      "Epoch 650/2000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.8047 - accuracy: 0.5466 - val_loss: 0.7600 - val_accuracy: 0.6263\n",
      "Epoch 651/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8055 - accuracy: 0.5460 - val_loss: 0.7603 - val_accuracy: 0.6259\n",
      "Epoch 652/2000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.8050 - accuracy: 0.5458 - val_loss: 0.7604 - val_accuracy: 0.6248\n",
      "Epoch 653/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8050 - accuracy: 0.5453 - val_loss: 0.7597 - val_accuracy: 0.6250\n",
      "Epoch 654/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8059 - accuracy: 0.5455 - val_loss: 0.7602 - val_accuracy: 0.6261\n",
      "Epoch 655/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8050 - accuracy: 0.5456 - val_loss: 0.7604 - val_accuracy: 0.6263\n",
      "Epoch 656/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8051 - accuracy: 0.5459 - val_loss: 0.7608 - val_accuracy: 0.6244\n",
      "Epoch 657/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8050 - accuracy: 0.5455 - val_loss: 0.7603 - val_accuracy: 0.6241\n",
      "Epoch 658/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.8057 - accuracy: 0.5447 - val_loss: 0.7606 - val_accuracy: 0.6256\n",
      "Epoch 659/2000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.8048 - accuracy: 0.5469 - val_loss: 0.7599 - val_accuracy: 0.6264\n",
      "Epoch 660/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8056 - accuracy: 0.5458 - val_loss: 0.7606 - val_accuracy: 0.6247\n",
      "Epoch 661/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8056 - accuracy: 0.5451 - val_loss: 0.7599 - val_accuracy: 0.6253\n",
      "Epoch 662/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8051 - accuracy: 0.5466 - val_loss: 0.7601 - val_accuracy: 0.6259\n",
      "Epoch 663/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8047 - accuracy: 0.5461 - val_loss: 0.7595 - val_accuracy: 0.6261\n",
      "Epoch 664/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8057 - accuracy: 0.5459 - val_loss: 0.7601 - val_accuracy: 0.6249\n",
      "Epoch 665/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8048 - accuracy: 0.5460 - val_loss: 0.7599 - val_accuracy: 0.6259\n",
      "Epoch 666/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8048 - accuracy: 0.5458 - val_loss: 0.7600 - val_accuracy: 0.6251\n",
      "Epoch 667/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8049 - accuracy: 0.5460 - val_loss: 0.7605 - val_accuracy: 0.6251\n",
      "Epoch 668/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8048 - accuracy: 0.5455 - val_loss: 0.7592 - val_accuracy: 0.6259\n",
      "Epoch 669/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8047 - accuracy: 0.5459 - val_loss: 0.7599 - val_accuracy: 0.6264\n",
      "Epoch 670/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8049 - accuracy: 0.5468 - val_loss: 0.7601 - val_accuracy: 0.6254\n",
      "Epoch 671/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8050 - accuracy: 0.5460 - val_loss: 0.7603 - val_accuracy: 0.6245\n",
      "Epoch 672/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8047 - accuracy: 0.5459 - val_loss: 0.7589 - val_accuracy: 0.6253\n",
      "Epoch 673/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8054 - accuracy: 0.5464 - val_loss: 0.7602 - val_accuracy: 0.6259\n",
      "Epoch 674/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8054 - accuracy: 0.5465 - val_loss: 0.7597 - val_accuracy: 0.6257\n",
      "Epoch 675/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8048 - accuracy: 0.5466 - val_loss: 0.7603 - val_accuracy: 0.6248\n",
      "Epoch 676/2000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.8050 - accuracy: 0.5463 - val_loss: 0.7592 - val_accuracy: 0.6250\n",
      "Epoch 677/2000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.8057 - accuracy: 0.5459 - val_loss: 0.7596 - val_accuracy: 0.6246\n",
      "Epoch 678/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8056 - accuracy: 0.5460 - val_loss: 0.7604 - val_accuracy: 0.6244\n",
      "Epoch 679/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8045 - accuracy: 0.5462 - val_loss: 0.7599 - val_accuracy: 0.6242\n",
      "Epoch 680/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8045 - accuracy: 0.5462 - val_loss: 0.7605 - val_accuracy: 0.6249\n",
      "Epoch 681/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8054 - accuracy: 0.5462 - val_loss: 0.7594 - val_accuracy: 0.6248\n",
      "Epoch 682/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8056 - accuracy: 0.5463 - val_loss: 0.7604 - val_accuracy: 0.6246\n",
      "Epoch 683/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8048 - accuracy: 0.5464 - val_loss: 0.7597 - val_accuracy: 0.6249\n",
      "Epoch 684/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8053 - accuracy: 0.5463 - val_loss: 0.7599 - val_accuracy: 0.6250\n",
      "Epoch 685/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8047 - accuracy: 0.5471 - val_loss: 0.7598 - val_accuracy: 0.6250\n",
      "Epoch 686/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8054 - accuracy: 0.5459 - val_loss: 0.7598 - val_accuracy: 0.6244\n",
      "Epoch 687/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8048 - accuracy: 0.5464 - val_loss: 0.7596 - val_accuracy: 0.6247\n",
      "Epoch 688/2000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.8045 - accuracy: 0.5465 - val_loss: 0.7594 - val_accuracy: 0.6248\n",
      "Epoch 689/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8049 - accuracy: 0.5466 - val_loss: 0.7601 - val_accuracy: 0.6257\n",
      "Epoch 690/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8046 - accuracy: 0.5468 - val_loss: 0.7598 - val_accuracy: 0.6246\n",
      "Epoch 691/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8049 - accuracy: 0.5461 - val_loss: 0.7598 - val_accuracy: 0.6245\n",
      "Epoch 692/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8047 - accuracy: 0.5464 - val_loss: 0.7595 - val_accuracy: 0.6247\n",
      "Epoch 693/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8050 - accuracy: 0.5471 - val_loss: 0.7599 - val_accuracy: 0.6250\n",
      "Epoch 694/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8046 - accuracy: 0.5466 - val_loss: 0.7589 - val_accuracy: 0.6247\n",
      "Epoch 695/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.8059 - accuracy: 0.5462 - val_loss: 0.7606 - val_accuracy: 0.6248\n",
      "Epoch 696/2000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.8046 - accuracy: 0.5466 - val_loss: 0.7593 - val_accuracy: 0.6252\n",
      "Epoch 697/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8047 - accuracy: 0.5468 - val_loss: 0.7598 - val_accuracy: 0.6251\n",
      "Epoch 698/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8045 - accuracy: 0.5468 - val_loss: 0.7598 - val_accuracy: 0.6244\n",
      "Epoch 699/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8056 - accuracy: 0.5464 - val_loss: 0.7593 - val_accuracy: 0.6250\n",
      "Epoch 700/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8050 - accuracy: 0.5464 - val_loss: 0.7599 - val_accuracy: 0.6245\n",
      "Epoch 701/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8043 - accuracy: 0.5467 - val_loss: 0.7597 - val_accuracy: 0.6250\n",
      "Epoch 702/2000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8049 - accuracy: 0.5470 - val_loss: 0.7597 - val_accuracy: 0.6255\n",
      "Epoch 703/2000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.8050 - accuracy: 0.5472 - val_loss: 0.7595 - val_accuracy: 0.6246\n",
      "Epoch 704/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8043 - accuracy: 0.5469 - val_loss: 0.7599 - val_accuracy: 0.6248\n",
      "Epoch 705/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8049 - accuracy: 0.5467 - val_loss: 0.7594 - val_accuracy: 0.6251\n",
      "Epoch 706/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8046 - accuracy: 0.5470 - val_loss: 0.7591 - val_accuracy: 0.6250\n",
      "Epoch 707/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8048 - accuracy: 0.5469 - val_loss: 0.7595 - val_accuracy: 0.6258\n",
      "Epoch 708/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8043 - accuracy: 0.5477 - val_loss: 0.7598 - val_accuracy: 0.6250\n",
      "Epoch 00708: early stopping\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "history = autoencoder.fit(train_X, train_X, epochs=EPOCHS, batch_size=batch_size, shuffle=True, verbose=1, \n",
    "                          callbacks=[checkpointer, earlystopping], validation_split=0.2, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47e8ccd",
   "metadata": {},
   "source": [
    "## 7. 오류 분포 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "6906b686",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val = autoencoder.predict(val_X)\n",
    "mse = np.mean(np.power(val_X - pred_val, 2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "5a636b56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reconstruction_error</th>\n",
       "      <th>true_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28462.000000</td>\n",
       "      <td>28462.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.784269</td>\n",
       "      <td>0.001054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.478186</td>\n",
       "      <td>0.032449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.030074</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.299744</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.507025</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.836842</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>146.137464</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reconstruction_error    true_class\n",
       "count          28462.000000  28462.000000\n",
       "mean               0.784269      0.001054\n",
       "std                2.478186      0.032449\n",
       "min                0.030074      0.000000\n",
       "25%                0.299744      0.000000\n",
       "50%                0.507025      0.000000\n",
       "75%                0.836842      0.000000\n",
       "max              146.137464      1.000000"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_df = pd.DataFrame({'reconstruction_error' : mse, 'true_class' : val_Y})\n",
    "error_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c77c3e6",
   "metadata": {},
   "source": [
    "### 1) 정상 데이터의 재구성 오류 분포 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "83f13bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "normal_error_df = error_df[(error_df['true_class'] == 0)]\n",
    "_ = ax.hist(normal_error_df.reconstruction_error.values, bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2543496",
   "metadata": {},
   "source": [
    "### 2) 이상 데이터의 재구성 오류 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "1a5547fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "fraud_error_df = error_df[error_df['true_class'] == 1]\n",
    "_ = ax.hist(fraud_error_df.reconstruction_error.values, bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71ab88f",
   "metadata": {},
   "source": [
    "### 3) 정밀도 vs 재현율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "6b84c6eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision, recall, th = precision_recall_curve(error_df.true_class, error_df.reconstruction_error)\n",
    "plt.plot(recall, precision, 'b', label='Precision-Recall curve')\n",
    "plt.title('Recall vs Precision')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56e932d",
   "metadata": {},
   "source": [
    "### 4) 임계값에 따른 정밀도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "3abd51c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(th, precision[1:], 'b', label='Threshold-Precision curve')\n",
    "plt.title('Precision for different threshold values')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Precision')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab98f347",
   "metadata": {},
   "source": [
    "### 5) 임계값에 따른 재현율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "77ddaa84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(th, recall[1:], 'b', label='Threshold-Recall curve')\n",
    "plt.title('Recall for different threshold values')\n",
    "plt.xlabel('Reconstruction error')\n",
    "plt.ylabel('Recall')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae15b8e",
   "metadata": {},
   "source": [
    "## 8. 학습 데이터에서 이상치 판명 데이터 제거\n",
    "- recall_score를 기준"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "363a3787",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36a24e452c924e2c892377154ced752c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28451 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [167]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(th):\n\u001b[1;32m      6\u001b[0m     pred_class \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(mse \u001b[38;5;241m>\u001b[39m i, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[43mrecall_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_Y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_class\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (score \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m (max_th \u001b[38;5;241m<\u001b[39m i):\n\u001b[1;32m      9\u001b[0m         max_th \u001b[38;5;241m=\u001b[39m i\n",
      "File \u001b[0;32m/home/ubuntu/anaconda3/envs/world_4/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1913\u001b[0m, in \u001b[0;36mrecall_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecall_score\u001b[39m(\n\u001b[1;32m   1783\u001b[0m     y_true,\n\u001b[1;32m   1784\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1790\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1791\u001b[0m ):\n\u001b[1;32m   1792\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute the recall.\u001b[39;00m\n\u001b[1;32m   1793\u001b[0m \n\u001b[1;32m   1794\u001b[0m \u001b[38;5;124;03m    The recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1911\u001b[0m \u001b[38;5;124;03m    array([1. , 1. , 0.5])\u001b[39;00m\n\u001b[1;32m   1912\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1913\u001b[0m     _, r, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1914\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1915\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1917\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrecall\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1922\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1923\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m/home/ubuntu/anaconda3/envs/world_4/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1560\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1560\u001b[0m MCM \u001b[38;5;241m=\u001b[39m \u001b[43mmultilabel_confusion_matrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1561\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1562\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1563\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1565\u001b[0m \u001b[43m    \u001b[49m\u001b[43msamplewise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msamplewise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1566\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1567\u001b[0m tp_sum \u001b[38;5;241m=\u001b[39m MCM[:, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1568\u001b[0m pred_sum \u001b[38;5;241m=\u001b[39m tp_sum \u001b[38;5;241m+\u001b[39m MCM[:, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/home/ubuntu/anaconda3/envs/world_4/lib/python3.8/site-packages/sklearn/metrics/_classification.py:507\u001b[0m, in \u001b[0;36mmultilabel_confusion_matrix\u001b[0;34m(y_true, y_pred, sample_weight, labels, samplewise)\u001b[0m\n\u001b[1;32m    505\u001b[0m le\u001b[38;5;241m.\u001b[39mfit(labels)\n\u001b[1;32m    506\u001b[0m y_true \u001b[38;5;241m=\u001b[39m le\u001b[38;5;241m.\u001b[39mtransform(y_true)\n\u001b[0;32m--> 507\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m sorted_labels \u001b[38;5;241m=\u001b[39m le\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[1;32m    510\u001b[0m \u001b[38;5;66;03m# labels are now from 0 to len(labels) - 1 -> use bincount\u001b[39;00m\n",
      "File \u001b[0;32m/home/ubuntu/anaconda3/envs/world_4/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:138\u001b[0m, in \u001b[0;36mLabelEncoder.transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([])\n\u001b[0;32m--> 138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniques\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/ubuntu/anaconda3/envs/world_4/lib/python3.8/site-packages/sklearn/utils/_encode.py:232\u001b[0m, in \u001b[0;36m_encode\u001b[0;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m diff:\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my contains previously unseen labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(diff)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearchsorted\u001b[49m\u001b[43m(\u001b[49m\u001b[43muniques\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msearchsorted\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/home/ubuntu/anaconda3/envs/world_4/lib/python3.8/site-packages/numpy/core/fromnumeric.py:1387\u001b[0m, in \u001b[0;36msearchsorted\u001b[0;34m(a, v, side, sorter)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_searchsorted_dispatcher)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearchsorted\u001b[39m(a, v, side\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, sorter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;124;03m    Find indices where elements should be inserted to maintain order.\u001b[39;00m\n\u001b[1;32m   1323\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1385\u001b[0m \n\u001b[1;32m   1386\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msearchsorted\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mside\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mside\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msorter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msorter\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/ubuntu/anaconda3/envs/world_4/lib/python3.8/site-packages/numpy/core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# racall score가 1인 최대 임계값 구하기\n",
    "recall_score_list = []\n",
    "max_th = 0\n",
    "\n",
    "for i in tqdm(th):\n",
    "    pred_class = np.where(mse > i, 1, 0)\n",
    "    score = recall_score(val_Y, pred_class)\n",
    "    if (score == 1) & (max_th < i):\n",
    "        max_th = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "309a11f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구한 임계값으로 train 예측\n",
    "pred_X = autoencoder.predict(train_X)\n",
    "mse = np.mean(np.power(train_X - pred_X, 2), axis=1)\n",
    "train_pred_class = np.where(mse > max_th, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2376f7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 데이터 생성\n",
    "new_train_df = train_df.copy()\n",
    "new_train_df['Class'] = train_pred_class\n",
    "new_train_df = new_train_df[new_train_df['Class'] == 0]\n",
    "new_train_X = new_train_df[new_train_df.columns[1:-1]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "87e14701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32645"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_train_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1481e192",
   "metadata": {},
   "source": [
    "## 9. 정상 값만 존재하는 데이터로 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0986b331",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.losses import MeanSquaredLogarithmicError\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f287ef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "x_train_scaled = min_max_scaler.fit_transform(new_train_X)\n",
    "x_test_scaled = min_max_scaler.transform(test_X)\n",
    "x_val_scaled = min_max_scaler.transform(val_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baadd0a3",
   "metadata": {},
   "source": [
    "### 1) 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "02dbd52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(Model):\n",
    "    def __init__(self, output_units, code_size=2):\n",
    "        super().__init__()\n",
    "        self.encoder = Sequential([\n",
    "            Dense(16, activation='relu'),\n",
    "            Dropout(0.1),\n",
    "            Dense(8, activation='relu'),\n",
    "            Dropout(0.1),\n",
    "            Dense(4, activation='relu'),\n",
    "            Dropout(0.1),\n",
    "            Dense(code_size, activation='relu')\n",
    "        ])\n",
    "        self.decoder = Sequential([\n",
    "              Dense(4, activation='relu'),\n",
    "              Dropout(0.1),\n",
    "              Dense(8, activation='relu'),\n",
    "              Dropout(0.1),\n",
    "              Dense(16, activation='relu'),\n",
    "              Dropout(0.1),\n",
    "              Dense(output_units, activation='sigmoid')\n",
    "        ])\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        encoded = self.encoder(inputs)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "700d7410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "model = AutoEncoder(output_units=x_train_scaled.shape[1])\n",
    "model.compile(loss='msle', metrics=['mse'], optimizer='adam')\n",
    "checkpointer = ModelCheckpoint(filepath='./model/keras_best.h5', verbos=1, save_best_only=True, save_weights_only=True, monitor='val_mse', mode='min')\n",
    "earlystopping = EarlyStopping(monitor='val_mse', mode='min', verbose=1, patience=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f89ba8",
   "metadata": {},
   "source": [
    "### 2) 정상 데이터로 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8d1567db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "2/2 [==============================] - 1s 226ms/step - loss: 0.0161 - mse: 0.0331 - val_loss: 0.0181 - val_mse: 0.0388\n",
      "Epoch 2/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0160 - mse: 0.0330 - val_loss: 0.0180 - val_mse: 0.0387\n",
      "Epoch 3/2000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0160 - mse: 0.0329 - val_loss: 0.0180 - val_mse: 0.0387\n",
      "Epoch 4/2000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0159 - mse: 0.0328 - val_loss: 0.0180 - val_mse: 0.0386\n",
      "Epoch 5/2000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0159 - mse: 0.0327 - val_loss: 0.0180 - val_mse: 0.0386\n",
      "Epoch 6/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0158 - mse: 0.0325 - val_loss: 0.0179 - val_mse: 0.0385\n",
      "Epoch 7/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0157 - mse: 0.0324 - val_loss: 0.0179 - val_mse: 0.0385\n",
      "Epoch 8/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0157 - mse: 0.0323 - val_loss: 0.0179 - val_mse: 0.0385\n",
      "Epoch 9/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0156 - mse: 0.0321 - val_loss: 0.0179 - val_mse: 0.0384\n",
      "Epoch 10/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0155 - mse: 0.0319 - val_loss: 0.0179 - val_mse: 0.0384\n",
      "Epoch 11/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0154 - mse: 0.0317 - val_loss: 0.0178 - val_mse: 0.0384\n",
      "Epoch 12/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0154 - mse: 0.0316 - val_loss: 0.0178 - val_mse: 0.0384\n",
      "Epoch 13/2000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0153 - mse: 0.0314 - val_loss: 0.0178 - val_mse: 0.0384\n",
      "Epoch 14/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0152 - mse: 0.0312 - val_loss: 0.0178 - val_mse: 0.0383\n",
      "Epoch 15/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0151 - mse: 0.0309 - val_loss: 0.0178 - val_mse: 0.0383\n",
      "Epoch 16/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0150 - mse: 0.0307 - val_loss: 0.0178 - val_mse: 0.0383\n",
      "Epoch 17/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0148 - mse: 0.0305 - val_loss: 0.0177 - val_mse: 0.0382\n",
      "Epoch 18/2000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0147 - mse: 0.0302 - val_loss: 0.0177 - val_mse: 0.0382\n",
      "Epoch 19/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0146 - mse: 0.0300 - val_loss: 0.0176 - val_mse: 0.0381\n",
      "Epoch 20/2000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0145 - mse: 0.0298 - val_loss: 0.0176 - val_mse: 0.0380\n",
      "Epoch 21/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0144 - mse: 0.0295 - val_loss: 0.0175 - val_mse: 0.0380\n",
      "Epoch 22/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0142 - mse: 0.0292 - val_loss: 0.0175 - val_mse: 0.0378\n",
      "Epoch 23/2000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0141 - mse: 0.0290 - val_loss: 0.0174 - val_mse: 0.0377\n",
      "Epoch 24/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0140 - mse: 0.0287 - val_loss: 0.0174 - val_mse: 0.0376\n",
      "Epoch 25/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0139 - mse: 0.0284 - val_loss: 0.0173 - val_mse: 0.0375\n",
      "Epoch 26/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0137 - mse: 0.0282 - val_loss: 0.0172 - val_mse: 0.0373\n",
      "Epoch 27/2000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0136 - mse: 0.0279 - val_loss: 0.0171 - val_mse: 0.0372\n",
      "Epoch 28/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0134 - mse: 0.0276 - val_loss: 0.0170 - val_mse: 0.0370\n",
      "Epoch 29/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0133 - mse: 0.0273 - val_loss: 0.0169 - val_mse: 0.0368\n",
      "Epoch 30/2000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0131 - mse: 0.0270 - val_loss: 0.0168 - val_mse: 0.0366\n",
      "Epoch 31/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0130 - mse: 0.0267 - val_loss: 0.0167 - val_mse: 0.0364\n",
      "Epoch 32/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0129 - mse: 0.0264 - val_loss: 0.0166 - val_mse: 0.0362\n",
      "Epoch 33/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0127 - mse: 0.0262 - val_loss: 0.0165 - val_mse: 0.0359\n",
      "Epoch 34/2000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0126 - mse: 0.0259 - val_loss: 0.0163 - val_mse: 0.0356\n",
      "Epoch 35/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0125 - mse: 0.0256 - val_loss: 0.0162 - val_mse: 0.0354\n",
      "Epoch 36/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0123 - mse: 0.0254 - val_loss: 0.0161 - val_mse: 0.0351\n",
      "Epoch 37/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0122 - mse: 0.0251 - val_loss: 0.0159 - val_mse: 0.0348\n",
      "Epoch 38/2000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0121 - mse: 0.0248 - val_loss: 0.0158 - val_mse: 0.0345\n",
      "Epoch 39/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0119 - mse: 0.0246 - val_loss: 0.0156 - val_mse: 0.0342\n",
      "Epoch 40/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0118 - mse: 0.0244 - val_loss: 0.0154 - val_mse: 0.0338\n",
      "Epoch 41/2000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0117 - mse: 0.0241 - val_loss: 0.0153 - val_mse: 0.0335\n",
      "Epoch 42/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0116 - mse: 0.0239 - val_loss: 0.0151 - val_mse: 0.0332\n",
      "Epoch 43/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0114 - mse: 0.0237 - val_loss: 0.0150 - val_mse: 0.0328\n",
      "Epoch 44/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0113 - mse: 0.0235 - val_loss: 0.0148 - val_mse: 0.0325\n",
      "Epoch 45/2000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0112 - mse: 0.0232 - val_loss: 0.0146 - val_mse: 0.0322\n",
      "Epoch 46/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0111 - mse: 0.0230 - val_loss: 0.0145 - val_mse: 0.0318\n",
      "Epoch 47/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0110 - mse: 0.0229 - val_loss: 0.0143 - val_mse: 0.0315\n",
      "Epoch 48/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0109 - mse: 0.0227 - val_loss: 0.0141 - val_mse: 0.0312\n",
      "Epoch 49/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0108 - mse: 0.0225 - val_loss: 0.0140 - val_mse: 0.0308\n",
      "Epoch 50/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0107 - mse: 0.0224 - val_loss: 0.0138 - val_mse: 0.0305\n",
      "Epoch 51/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0106 - mse: 0.0222 - val_loss: 0.0137 - val_mse: 0.0303\n",
      "Epoch 52/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0105 - mse: 0.0221 - val_loss: 0.0136 - val_mse: 0.0300\n",
      "Epoch 53/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0104 - mse: 0.0219 - val_loss: 0.0134 - val_mse: 0.0297\n",
      "Epoch 54/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0104 - mse: 0.0218 - val_loss: 0.0133 - val_mse: 0.0295\n",
      "Epoch 55/2000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0103 - mse: 0.0217 - val_loss: 0.0132 - val_mse: 0.0293\n",
      "Epoch 56/2000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0103 - mse: 0.0216 - val_loss: 0.0131 - val_mse: 0.0291\n",
      "Epoch 57/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0102 - mse: 0.0214 - val_loss: 0.0130 - val_mse: 0.0290\n",
      "Epoch 58/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0101 - mse: 0.0213 - val_loss: 0.0130 - val_mse: 0.0288\n",
      "Epoch 59/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0101 - mse: 0.0212 - val_loss: 0.0129 - val_mse: 0.0287\n",
      "Epoch 60/2000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0100 - mse: 0.0211 - val_loss: 0.0128 - val_mse: 0.0286\n",
      "Epoch 61/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0100 - mse: 0.0211 - val_loss: 0.0128 - val_mse: 0.0285\n",
      "Epoch 62/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0099 - mse: 0.0210 - val_loss: 0.0127 - val_mse: 0.0284\n",
      "Epoch 63/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0098 - mse: 0.0209 - val_loss: 0.0127 - val_mse: 0.0284\n",
      "Epoch 64/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0098 - mse: 0.0208 - val_loss: 0.0127 - val_mse: 0.0283\n",
      "Epoch 65/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0097 - mse: 0.0207 - val_loss: 0.0126 - val_mse: 0.0283\n",
      "Epoch 66/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0097 - mse: 0.0206 - val_loss: 0.0126 - val_mse: 0.0282\n",
      "Epoch 67/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0096 - mse: 0.0205 - val_loss: 0.0126 - val_mse: 0.0282\n",
      "Epoch 68/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0096 - mse: 0.0205 - val_loss: 0.0125 - val_mse: 0.0281\n",
      "Epoch 69/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0096 - mse: 0.0204 - val_loss: 0.0125 - val_mse: 0.0281\n",
      "Epoch 70/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0095 - mse: 0.0204 - val_loss: 0.0125 - val_mse: 0.0280\n",
      "Epoch 71/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0095 - mse: 0.0203 - val_loss: 0.0124 - val_mse: 0.0280\n",
      "Epoch 72/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0095 - mse: 0.0203 - val_loss: 0.0124 - val_mse: 0.0280\n",
      "Epoch 73/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0094 - mse: 0.0202 - val_loss: 0.0124 - val_mse: 0.0279\n",
      "Epoch 74/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0094 - mse: 0.0202 - val_loss: 0.0123 - val_mse: 0.0279\n",
      "Epoch 75/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0093 - mse: 0.0201 - val_loss: 0.0123 - val_mse: 0.0278\n",
      "Epoch 76/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0093 - mse: 0.0201 - val_loss: 0.0123 - val_mse: 0.0278\n",
      "Epoch 77/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0093 - mse: 0.0200 - val_loss: 0.0123 - val_mse: 0.0277\n",
      "Epoch 78/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0092 - mse: 0.0199 - val_loss: 0.0122 - val_mse: 0.0277\n",
      "Epoch 79/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0092 - mse: 0.0199 - val_loss: 0.0122 - val_mse: 0.0277\n",
      "Epoch 80/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0092 - mse: 0.0199 - val_loss: 0.0122 - val_mse: 0.0276\n",
      "Epoch 81/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0091 - mse: 0.0198 - val_loss: 0.0121 - val_mse: 0.0276\n",
      "Epoch 82/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0091 - mse: 0.0197 - val_loss: 0.0121 - val_mse: 0.0276\n",
      "Epoch 83/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0091 - mse: 0.0197 - val_loss: 0.0121 - val_mse: 0.0275\n",
      "Epoch 84/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0091 - mse: 0.0196 - val_loss: 0.0121 - val_mse: 0.0275\n",
      "Epoch 85/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0090 - mse: 0.0196 - val_loss: 0.0121 - val_mse: 0.0275\n",
      "Epoch 86/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0090 - mse: 0.0195 - val_loss: 0.0120 - val_mse: 0.0274\n",
      "Epoch 87/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0090 - mse: 0.0195 - val_loss: 0.0120 - val_mse: 0.0274\n",
      "Epoch 88/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0090 - mse: 0.0194 - val_loss: 0.0120 - val_mse: 0.0274\n",
      "Epoch 89/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0089 - mse: 0.0194 - val_loss: 0.0120 - val_mse: 0.0273\n",
      "Epoch 90/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0089 - mse: 0.0194 - val_loss: 0.0119 - val_mse: 0.0273\n",
      "Epoch 91/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0089 - mse: 0.0193 - val_loss: 0.0119 - val_mse: 0.0273\n",
      "Epoch 92/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0089 - mse: 0.0193 - val_loss: 0.0119 - val_mse: 0.0272\n",
      "Epoch 93/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0089 - mse: 0.0192 - val_loss: 0.0119 - val_mse: 0.0272\n",
      "Epoch 94/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0088 - mse: 0.0192 - val_loss: 0.0119 - val_mse: 0.0272\n",
      "Epoch 95/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0088 - mse: 0.0192 - val_loss: 0.0119 - val_mse: 0.0272\n",
      "Epoch 96/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0088 - mse: 0.0191 - val_loss: 0.0118 - val_mse: 0.0271\n",
      "Epoch 97/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0088 - mse: 0.0191 - val_loss: 0.0118 - val_mse: 0.0271\n",
      "Epoch 98/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0087 - mse: 0.0190 - val_loss: 0.0118 - val_mse: 0.0271\n",
      "Epoch 99/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0087 - mse: 0.0190 - val_loss: 0.0118 - val_mse: 0.0270\n",
      "Epoch 100/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0087 - mse: 0.0190 - val_loss: 0.0118 - val_mse: 0.0270\n",
      "Epoch 101/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0087 - mse: 0.0189 - val_loss: 0.0117 - val_mse: 0.0270\n",
      "Epoch 102/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0086 - mse: 0.0189 - val_loss: 0.0117 - val_mse: 0.0269\n",
      "Epoch 103/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0086 - mse: 0.0189 - val_loss: 0.0117 - val_mse: 0.0269\n",
      "Epoch 104/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0086 - mse: 0.0188 - val_loss: 0.0117 - val_mse: 0.0269\n",
      "Epoch 105/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0086 - mse: 0.0188 - val_loss: 0.0117 - val_mse: 0.0269\n",
      "Epoch 106/2000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0086 - mse: 0.0187 - val_loss: 0.0117 - val_mse: 0.0269\n",
      "Epoch 107/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0086 - mse: 0.0187 - val_loss: 0.0117 - val_mse: 0.0269\n",
      "Epoch 108/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0085 - mse: 0.0187 - val_loss: 0.0117 - val_mse: 0.0269\n",
      "Epoch 109/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0085 - mse: 0.0187 - val_loss: 0.0117 - val_mse: 0.0269\n",
      "Epoch 110/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0085 - mse: 0.0186 - val_loss: 0.0116 - val_mse: 0.0268\n",
      "Epoch 111/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0085 - mse: 0.0186 - val_loss: 0.0116 - val_mse: 0.0268\n",
      "Epoch 112/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0085 - mse: 0.0186 - val_loss: 0.0116 - val_mse: 0.0268\n",
      "Epoch 113/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0085 - mse: 0.0186 - val_loss: 0.0116 - val_mse: 0.0267\n",
      "Epoch 114/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0085 - mse: 0.0185 - val_loss: 0.0116 - val_mse: 0.0267\n",
      "Epoch 115/2000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0084 - mse: 0.0185 - val_loss: 0.0116 - val_mse: 0.0267\n",
      "Epoch 116/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0084 - mse: 0.0185 - val_loss: 0.0115 - val_mse: 0.0267\n",
      "Epoch 117/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0084 - mse: 0.0185 - val_loss: 0.0115 - val_mse: 0.0266\n",
      "Epoch 118/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0084 - mse: 0.0185 - val_loss: 0.0115 - val_mse: 0.0266\n",
      "Epoch 119/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0084 - mse: 0.0185 - val_loss: 0.0115 - val_mse: 0.0266\n",
      "Epoch 120/2000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0084 - mse: 0.0184 - val_loss: 0.0115 - val_mse: 0.0265\n",
      "Epoch 121/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0084 - mse: 0.0184 - val_loss: 0.0115 - val_mse: 0.0265\n",
      "Epoch 122/2000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0083 - mse: 0.0184 - val_loss: 0.0114 - val_mse: 0.0265\n",
      "Epoch 123/2000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0083 - mse: 0.0183 - val_loss: 0.0114 - val_mse: 0.0264\n",
      "Epoch 124/2000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0083 - mse: 0.0183 - val_loss: 0.0114 - val_mse: 0.0264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0083 - mse: 0.0183 - val_loss: 0.0114 - val_mse: 0.0264\n",
      "Epoch 126/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0083 - mse: 0.0183 - val_loss: 0.0114 - val_mse: 0.0264\n",
      "Epoch 127/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0083 - mse: 0.0183 - val_loss: 0.0114 - val_mse: 0.0264\n",
      "Epoch 128/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0083 - mse: 0.0183 - val_loss: 0.0114 - val_mse: 0.0264\n",
      "Epoch 129/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0083 - mse: 0.0183 - val_loss: 0.0114 - val_mse: 0.0264\n",
      "Epoch 130/2000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0083 - mse: 0.0182 - val_loss: 0.0114 - val_mse: 0.0264\n",
      "Epoch 131/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0083 - mse: 0.0182 - val_loss: 0.0114 - val_mse: 0.0264\n",
      "Epoch 132/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0083 - mse: 0.0182 - val_loss: 0.0114 - val_mse: 0.0263\n",
      "Epoch 133/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0083 - mse: 0.0182 - val_loss: 0.0113 - val_mse: 0.0263\n",
      "Epoch 134/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0082 - mse: 0.0182 - val_loss: 0.0113 - val_mse: 0.0263\n",
      "Epoch 135/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0082 - mse: 0.0182 - val_loss: 0.0113 - val_mse: 0.0263\n",
      "Epoch 136/2000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0082 - mse: 0.0182 - val_loss: 0.0113 - val_mse: 0.0263\n",
      "Epoch 137/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0082 - mse: 0.0181 - val_loss: 0.0113 - val_mse: 0.0262\n",
      "Epoch 138/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0082 - mse: 0.0181 - val_loss: 0.0113 - val_mse: 0.0262\n",
      "Epoch 139/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0082 - mse: 0.0181 - val_loss: 0.0113 - val_mse: 0.0262\n",
      "Epoch 140/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0082 - mse: 0.0181 - val_loss: 0.0113 - val_mse: 0.0262\n",
      "Epoch 141/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0082 - mse: 0.0181 - val_loss: 0.0113 - val_mse: 0.0262\n",
      "Epoch 142/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0082 - mse: 0.0181 - val_loss: 0.0113 - val_mse: 0.0262\n",
      "Epoch 143/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0082 - mse: 0.0180 - val_loss: 0.0113 - val_mse: 0.0262\n",
      "Epoch 144/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0082 - mse: 0.0181 - val_loss: 0.0112 - val_mse: 0.0262\n",
      "Epoch 145/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0082 - mse: 0.0180 - val_loss: 0.0112 - val_mse: 0.0261\n",
      "Epoch 146/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0081 - mse: 0.0180 - val_loss: 0.0112 - val_mse: 0.0261\n",
      "Epoch 147/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0081 - mse: 0.0180 - val_loss: 0.0112 - val_mse: 0.0261\n",
      "Epoch 148/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0081 - mse: 0.0180 - val_loss: 0.0112 - val_mse: 0.0261\n",
      "Epoch 149/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0081 - mse: 0.0180 - val_loss: 0.0112 - val_mse: 0.0261\n",
      "Epoch 150/2000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0081 - mse: 0.0180 - val_loss: 0.0112 - val_mse: 0.0261\n",
      "Epoch 151/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0081 - mse: 0.0180 - val_loss: 0.0112 - val_mse: 0.0261\n",
      "Epoch 152/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0081 - mse: 0.0180 - val_loss: 0.0112 - val_mse: 0.0261\n",
      "Epoch 153/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0081 - mse: 0.0179 - val_loss: 0.0112 - val_mse: 0.0260\n",
      "Epoch 154/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0081 - mse: 0.0179 - val_loss: 0.0112 - val_mse: 0.0260\n",
      "Epoch 155/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0081 - mse: 0.0179 - val_loss: 0.0112 - val_mse: 0.0260\n",
      "Epoch 156/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0081 - mse: 0.0179 - val_loss: 0.0112 - val_mse: 0.0260\n",
      "Epoch 157/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0081 - mse: 0.0179 - val_loss: 0.0112 - val_mse: 0.0260\n",
      "Epoch 158/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0081 - mse: 0.0179 - val_loss: 0.0111 - val_mse: 0.0260\n",
      "Epoch 159/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0081 - mse: 0.0179 - val_loss: 0.0111 - val_mse: 0.0260\n",
      "Epoch 160/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0081 - mse: 0.0179 - val_loss: 0.0111 - val_mse: 0.0260\n",
      "Epoch 161/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0081 - mse: 0.0179 - val_loss: 0.0111 - val_mse: 0.0260\n",
      "Epoch 162/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0081 - mse: 0.0179 - val_loss: 0.0111 - val_mse: 0.0259\n",
      "Epoch 163/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0081 - mse: 0.0179 - val_loss: 0.0111 - val_mse: 0.0259\n",
      "Epoch 164/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0081 - mse: 0.0178 - val_loss: 0.0111 - val_mse: 0.0259\n",
      "Epoch 165/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0080 - mse: 0.0178 - val_loss: 0.0111 - val_mse: 0.0259\n",
      "Epoch 166/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0080 - mse: 0.0178 - val_loss: 0.0111 - val_mse: 0.0259\n",
      "Epoch 167/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0080 - mse: 0.0178 - val_loss: 0.0111 - val_mse: 0.0259\n",
      "Epoch 168/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0080 - mse: 0.0178 - val_loss: 0.0111 - val_mse: 0.0259\n",
      "Epoch 169/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0080 - mse: 0.0178 - val_loss: 0.0111 - val_mse: 0.0258\n",
      "Epoch 170/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0080 - mse: 0.0178 - val_loss: 0.0111 - val_mse: 0.0258\n",
      "Epoch 171/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0080 - mse: 0.0178 - val_loss: 0.0111 - val_mse: 0.0258\n",
      "Epoch 172/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0080 - mse: 0.0178 - val_loss: 0.0111 - val_mse: 0.0258\n",
      "Epoch 173/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0080 - mse: 0.0178 - val_loss: 0.0110 - val_mse: 0.0258\n",
      "Epoch 174/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0080 - mse: 0.0177 - val_loss: 0.0110 - val_mse: 0.0258\n",
      "Epoch 175/2000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.0080 - mse: 0.0177 - val_loss: 0.0110 - val_mse: 0.0258\n",
      "Epoch 176/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0080 - mse: 0.0177 - val_loss: 0.0110 - val_mse: 0.0258\n",
      "Epoch 177/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0080 - mse: 0.0177 - val_loss: 0.0110 - val_mse: 0.0258\n",
      "Epoch 178/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0080 - mse: 0.0177 - val_loss: 0.0110 - val_mse: 0.0258\n",
      "Epoch 179/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0080 - mse: 0.0177 - val_loss: 0.0110 - val_mse: 0.0257\n",
      "Epoch 180/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0080 - mse: 0.0177 - val_loss: 0.0110 - val_mse: 0.0257\n",
      "Epoch 181/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0080 - mse: 0.0177 - val_loss: 0.0110 - val_mse: 0.0257\n",
      "Epoch 182/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0080 - mse: 0.0177 - val_loss: 0.0110 - val_mse: 0.0257\n",
      "Epoch 183/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0080 - mse: 0.0177 - val_loss: 0.0110 - val_mse: 0.0257\n",
      "Epoch 184/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0080 - mse: 0.0177 - val_loss: 0.0110 - val_mse: 0.0257\n",
      "Epoch 185/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0080 - mse: 0.0177 - val_loss: 0.0110 - val_mse: 0.0257\n",
      "Epoch 186/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0080 - mse: 0.0177 - val_loss: 0.0110 - val_mse: 0.0257\n",
      "Epoch 187/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0080 - mse: 0.0177 - val_loss: 0.0110 - val_mse: 0.0256\n",
      "Epoch 188/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0079 - mse: 0.0176 - val_loss: 0.0109 - val_mse: 0.0256\n",
      "Epoch 189/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0079 - mse: 0.0176 - val_loss: 0.0109 - val_mse: 0.0256\n",
      "Epoch 190/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0079 - mse: 0.0176 - val_loss: 0.0109 - val_mse: 0.0256\n",
      "Epoch 191/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0079 - mse: 0.0176 - val_loss: 0.0109 - val_mse: 0.0256\n",
      "Epoch 192/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0079 - mse: 0.0176 - val_loss: 0.0109 - val_mse: 0.0255\n",
      "Epoch 193/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0079 - mse: 0.0176 - val_loss: 0.0109 - val_mse: 0.0255\n",
      "Epoch 194/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0079 - mse: 0.0176 - val_loss: 0.0109 - val_mse: 0.0255\n",
      "Epoch 195/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0079 - mse: 0.0176 - val_loss: 0.0109 - val_mse: 0.0255\n",
      "Epoch 196/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0079 - mse: 0.0176 - val_loss: 0.0109 - val_mse: 0.0255\n",
      "Epoch 197/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0079 - mse: 0.0176 - val_loss: 0.0109 - val_mse: 0.0255\n",
      "Epoch 198/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0079 - mse: 0.0176 - val_loss: 0.0109 - val_mse: 0.0255\n",
      "Epoch 199/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0079 - mse: 0.0176 - val_loss: 0.0109 - val_mse: 0.0255\n",
      "Epoch 200/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0079 - mse: 0.0176 - val_loss: 0.0109 - val_mse: 0.0255\n",
      "Epoch 201/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0079 - mse: 0.0176 - val_loss: 0.0109 - val_mse: 0.0255\n",
      "Epoch 202/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0079 - mse: 0.0176 - val_loss: 0.0109 - val_mse: 0.0255\n",
      "Epoch 203/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0079 - mse: 0.0175 - val_loss: 0.0109 - val_mse: 0.0254\n",
      "Epoch 204/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0079 - mse: 0.0175 - val_loss: 0.0108 - val_mse: 0.0254\n",
      "Epoch 205/2000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.0079 - mse: 0.0175 - val_loss: 0.0108 - val_mse: 0.0254\n",
      "Epoch 206/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0079 - mse: 0.0175 - val_loss: 0.0108 - val_mse: 0.0254\n",
      "Epoch 207/2000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0079 - mse: 0.0175 - val_loss: 0.0108 - val_mse: 0.0254\n",
      "Epoch 208/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0079 - mse: 0.0175 - val_loss: 0.0108 - val_mse: 0.0254\n",
      "Epoch 209/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0079 - mse: 0.0175 - val_loss: 0.0108 - val_mse: 0.0253\n",
      "Epoch 210/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0079 - mse: 0.0175 - val_loss: 0.0108 - val_mse: 0.0253\n",
      "Epoch 211/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0079 - mse: 0.0175 - val_loss: 0.0108 - val_mse: 0.0253\n",
      "Epoch 212/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0079 - mse: 0.0175 - val_loss: 0.0108 - val_mse: 0.0253\n",
      "Epoch 213/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0079 - mse: 0.0175 - val_loss: 0.0108 - val_mse: 0.0253\n",
      "Epoch 214/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0079 - mse: 0.0175 - val_loss: 0.0108 - val_mse: 0.0253\n",
      "Epoch 215/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0079 - mse: 0.0175 - val_loss: 0.0108 - val_mse: 0.0253\n",
      "Epoch 216/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0079 - mse: 0.0175 - val_loss: 0.0108 - val_mse: 0.0253\n",
      "Epoch 217/2000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0079 - mse: 0.0175 - val_loss: 0.0108 - val_mse: 0.0253\n",
      "Epoch 218/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0079 - mse: 0.0175 - val_loss: 0.0108 - val_mse: 0.0252\n",
      "Epoch 219/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0079 - mse: 0.0174 - val_loss: 0.0108 - val_mse: 0.0252\n",
      "Epoch 220/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0078 - mse: 0.0174 - val_loss: 0.0107 - val_mse: 0.0252\n",
      "Epoch 221/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0078 - mse: 0.0174 - val_loss: 0.0107 - val_mse: 0.0252\n",
      "Epoch 222/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0078 - mse: 0.0174 - val_loss: 0.0107 - val_mse: 0.0252\n",
      "Epoch 223/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0078 - mse: 0.0174 - val_loss: 0.0107 - val_mse: 0.0252\n",
      "Epoch 224/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0078 - mse: 0.0174 - val_loss: 0.0107 - val_mse: 0.0252\n",
      "Epoch 225/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0078 - mse: 0.0174 - val_loss: 0.0107 - val_mse: 0.0251\n",
      "Epoch 226/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0078 - mse: 0.0174 - val_loss: 0.0107 - val_mse: 0.0251\n",
      "Epoch 227/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0078 - mse: 0.0174 - val_loss: 0.0107 - val_mse: 0.0251\n",
      "Epoch 228/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0078 - mse: 0.0174 - val_loss: 0.0107 - val_mse: 0.0251\n",
      "Epoch 229/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0078 - mse: 0.0174 - val_loss: 0.0107 - val_mse: 0.0251\n",
      "Epoch 230/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0078 - mse: 0.0174 - val_loss: 0.0107 - val_mse: 0.0251\n",
      "Epoch 231/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0078 - mse: 0.0174 - val_loss: 0.0107 - val_mse: 0.0251\n",
      "Epoch 232/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0078 - mse: 0.0174 - val_loss: 0.0107 - val_mse: 0.0251\n",
      "Epoch 233/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0078 - mse: 0.0174 - val_loss: 0.0107 - val_mse: 0.0250\n",
      "Epoch 234/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0078 - mse: 0.0174 - val_loss: 0.0107 - val_mse: 0.0250\n",
      "Epoch 235/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0078 - mse: 0.0174 - val_loss: 0.0107 - val_mse: 0.0250\n",
      "Epoch 236/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0078 - mse: 0.0174 - val_loss: 0.0107 - val_mse: 0.0250\n",
      "Epoch 237/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0078 - mse: 0.0173 - val_loss: 0.0106 - val_mse: 0.0250\n",
      "Epoch 238/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0078 - mse: 0.0173 - val_loss: 0.0106 - val_mse: 0.0250\n",
      "Epoch 239/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0078 - mse: 0.0173 - val_loss: 0.0106 - val_mse: 0.0250\n",
      "Epoch 240/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0078 - mse: 0.0173 - val_loss: 0.0106 - val_mse: 0.0249\n",
      "Epoch 241/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0078 - mse: 0.0173 - val_loss: 0.0106 - val_mse: 0.0249\n",
      "Epoch 242/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0078 - mse: 0.0173 - val_loss: 0.0106 - val_mse: 0.0249\n",
      "Epoch 243/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0078 - mse: 0.0173 - val_loss: 0.0106 - val_mse: 0.0249\n",
      "Epoch 244/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0078 - mse: 0.0173 - val_loss: 0.0106 - val_mse: 0.0249\n",
      "Epoch 245/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0078 - mse: 0.0173 - val_loss: 0.0106 - val_mse: 0.0249\n",
      "Epoch 246/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0078 - mse: 0.0173 - val_loss: 0.0106 - val_mse: 0.0249\n",
      "Epoch 247/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0078 - mse: 0.0173 - val_loss: 0.0106 - val_mse: 0.0249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 248/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0078 - mse: 0.0173 - val_loss: 0.0106 - val_mse: 0.0248\n",
      "Epoch 249/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0078 - mse: 0.0173 - val_loss: 0.0106 - val_mse: 0.0248\n",
      "Epoch 250/2000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0078 - mse: 0.0173 - val_loss: 0.0106 - val_mse: 0.0248\n",
      "Epoch 251/2000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0078 - mse: 0.0173 - val_loss: 0.0106 - val_mse: 0.0248\n",
      "Epoch 252/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0078 - mse: 0.0173 - val_loss: 0.0105 - val_mse: 0.0248\n",
      "Epoch 253/2000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0078 - mse: 0.0173 - val_loss: 0.0105 - val_mse: 0.0248\n",
      "Epoch 254/2000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0078 - mse: 0.0173 - val_loss: 0.0105 - val_mse: 0.0248\n",
      "Epoch 255/2000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0078 - mse: 0.0173 - val_loss: 0.0105 - val_mse: 0.0248\n",
      "Epoch 256/2000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0078 - mse: 0.0172 - val_loss: 0.0105 - val_mse: 0.0248\n",
      "Epoch 257/2000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0077 - mse: 0.0172 - val_loss: 0.0105 - val_mse: 0.0247\n",
      "Epoch 258/2000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0078 - mse: 0.0172 - val_loss: 0.0105 - val_mse: 0.0247\n",
      "Epoch 259/2000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0077 - mse: 0.0172 - val_loss: 0.0105 - val_mse: 0.0247\n",
      "Epoch 260/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0077 - mse: 0.0172 - val_loss: 0.0105 - val_mse: 0.0247\n",
      "Epoch 261/2000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.0077 - mse: 0.0172 - val_loss: 0.0105 - val_mse: 0.0247\n",
      "Epoch 262/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0077 - mse: 0.0172 - val_loss: 0.0105 - val_mse: 0.0247\n",
      "Epoch 263/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0077 - mse: 0.0172 - val_loss: 0.0105 - val_mse: 0.0247\n",
      "Epoch 264/2000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0077 - mse: 0.0172 - val_loss: 0.0105 - val_mse: 0.0247\n",
      "Epoch 265/2000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0077 - mse: 0.0172 - val_loss: 0.0105 - val_mse: 0.0246\n",
      "Epoch 266/2000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0077 - mse: 0.0172 - val_loss: 0.0105 - val_mse: 0.0246\n",
      "Epoch 267/2000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0077 - mse: 0.0172 - val_loss: 0.0105 - val_mse: 0.0246\n",
      "Epoch 268/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0077 - mse: 0.0172 - val_loss: 0.0105 - val_mse: 0.0246\n",
      "Epoch 269/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0077 - mse: 0.0172 - val_loss: 0.0105 - val_mse: 0.0246\n",
      "Epoch 270/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0077 - mse: 0.0172 - val_loss: 0.0105 - val_mse: 0.0246\n",
      "Epoch 271/2000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0077 - mse: 0.0172 - val_loss: 0.0104 - val_mse: 0.0246\n",
      "Epoch 272/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0077 - mse: 0.0172 - val_loss: 0.0104 - val_mse: 0.0245\n",
      "Epoch 273/2000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.0077 - mse: 0.0171 - val_loss: 0.0104 - val_mse: 0.0245\n",
      "Epoch 274/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0077 - mse: 0.0171 - val_loss: 0.0104 - val_mse: 0.0245\n",
      "Epoch 275/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0077 - mse: 0.0171 - val_loss: 0.0104 - val_mse: 0.0245\n",
      "Epoch 276/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0077 - mse: 0.0171 - val_loss: 0.0104 - val_mse: 0.0245\n",
      "Epoch 277/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0077 - mse: 0.0171 - val_loss: 0.0104 - val_mse: 0.0245\n",
      "Epoch 278/2000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0077 - mse: 0.0171 - val_loss: 0.0104 - val_mse: 0.0245\n",
      "Epoch 279/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0077 - mse: 0.0171 - val_loss: 0.0104 - val_mse: 0.0245\n",
      "Epoch 280/2000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.0077 - mse: 0.0171 - val_loss: 0.0104 - val_mse: 0.0245\n",
      "Epoch 281/2000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0077 - mse: 0.0171 - val_loss: 0.0104 - val_mse: 0.0245\n",
      "Epoch 282/2000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0077 - mse: 0.0171 - val_loss: 0.0104 - val_mse: 0.0244\n",
      "Epoch 283/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0077 - mse: 0.0171 - val_loss: 0.0104 - val_mse: 0.0244\n",
      "Epoch 284/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0077 - mse: 0.0171 - val_loss: 0.0104 - val_mse: 0.0244\n",
      "Epoch 285/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0077 - mse: 0.0171 - val_loss: 0.0104 - val_mse: 0.0244\n",
      "Epoch 286/2000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0077 - mse: 0.0171 - val_loss: 0.0104 - val_mse: 0.0244\n",
      "Epoch 287/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0077 - mse: 0.0171 - val_loss: 0.0104 - val_mse: 0.0244\n",
      "Epoch 288/2000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0077 - mse: 0.0171 - val_loss: 0.0104 - val_mse: 0.0244\n",
      "Epoch 289/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0077 - mse: 0.0171 - val_loss: 0.0103 - val_mse: 0.0243\n",
      "Epoch 290/2000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0077 - mse: 0.0171 - val_loss: 0.0103 - val_mse: 0.0243\n",
      "Epoch 291/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0077 - mse: 0.0171 - val_loss: 0.0103 - val_mse: 0.0243\n",
      "Epoch 292/2000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0077 - mse: 0.0170 - val_loss: 0.0103 - val_mse: 0.0243\n",
      "Epoch 293/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0077 - mse: 0.0171 - val_loss: 0.0103 - val_mse: 0.0243\n",
      "Epoch 294/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0077 - mse: 0.0171 - val_loss: 0.0103 - val_mse: 0.0243\n",
      "Epoch 295/2000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0077 - mse: 0.0170 - val_loss: 0.0103 - val_mse: 0.0243\n",
      "Epoch 296/2000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0077 - mse: 0.0170 - val_loss: 0.0103 - val_mse: 0.0243\n",
      "Epoch 297/2000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0077 - mse: 0.0170 - val_loss: 0.0103 - val_mse: 0.0243\n",
      "Epoch 298/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0077 - mse: 0.0170 - val_loss: 0.0103 - val_mse: 0.0243\n",
      "Epoch 299/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0077 - mse: 0.0170 - val_loss: 0.0103 - val_mse: 0.0242\n",
      "Epoch 300/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0077 - mse: 0.0170 - val_loss: 0.0103 - val_mse: 0.0242\n",
      "Epoch 301/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0077 - mse: 0.0170 - val_loss: 0.0103 - val_mse: 0.0242\n",
      "Epoch 302/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0077 - mse: 0.0170 - val_loss: 0.0103 - val_mse: 0.0242\n",
      "Epoch 303/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0077 - mse: 0.0170 - val_loss: 0.0103 - val_mse: 0.0242\n",
      "Epoch 304/2000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0077 - mse: 0.0170 - val_loss: 0.0103 - val_mse: 0.0242\n",
      "Epoch 305/2000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.0076 - mse: 0.0170 - val_loss: 0.0103 - val_mse: 0.0242\n",
      "Epoch 306/2000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0076 - mse: 0.0170 - val_loss: 0.0103 - val_mse: 0.0242\n",
      "Epoch 307/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0076 - mse: 0.0170 - val_loss: 0.0103 - val_mse: 0.0242\n",
      "Epoch 308/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0076 - mse: 0.0170 - val_loss: 0.0103 - val_mse: 0.0242\n",
      "Epoch 309/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0076 - mse: 0.0170 - val_loss: 0.0103 - val_mse: 0.0242\n",
      "Epoch 310/2000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0076 - mse: 0.0170 - val_loss: 0.0103 - val_mse: 0.0242\n",
      "Epoch 311/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0076 - mse: 0.0169 - val_loss: 0.0103 - val_mse: 0.0241\n",
      "Epoch 312/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0076 - mse: 0.0170 - val_loss: 0.0102 - val_mse: 0.0241\n",
      "Epoch 313/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0076 - mse: 0.0169 - val_loss: 0.0102 - val_mse: 0.0241\n",
      "Epoch 314/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0076 - mse: 0.0170 - val_loss: 0.0102 - val_mse: 0.0241\n",
      "Epoch 315/2000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0076 - mse: 0.0169 - val_loss: 0.0102 - val_mse: 0.0241\n",
      "Epoch 316/2000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0076 - mse: 0.0169 - val_loss: 0.0102 - val_mse: 0.0241\n",
      "Epoch 317/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0076 - mse: 0.0169 - val_loss: 0.0102 - val_mse: 0.0240\n",
      "Epoch 318/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0076 - mse: 0.0169 - val_loss: 0.0102 - val_mse: 0.0240\n",
      "Epoch 319/2000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0076 - mse: 0.0169 - val_loss: 0.0102 - val_mse: 0.0240\n",
      "Epoch 320/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0076 - mse: 0.0169 - val_loss: 0.0102 - val_mse: 0.0240\n",
      "Epoch 321/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0076 - mse: 0.0169 - val_loss: 0.0102 - val_mse: 0.0240\n",
      "Epoch 322/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0076 - mse: 0.0169 - val_loss: 0.0102 - val_mse: 0.0240\n",
      "Epoch 323/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0076 - mse: 0.0169 - val_loss: 0.0102 - val_mse: 0.0240\n",
      "Epoch 324/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0076 - mse: 0.0169 - val_loss: 0.0102 - val_mse: 0.0240\n",
      "Epoch 325/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0076 - mse: 0.0169 - val_loss: 0.0102 - val_mse: 0.0240\n",
      "Epoch 326/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0076 - mse: 0.0169 - val_loss: 0.0102 - val_mse: 0.0240\n",
      "Epoch 327/2000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0076 - mse: 0.0169 - val_loss: 0.0102 - val_mse: 0.0240\n",
      "Epoch 328/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0076 - mse: 0.0169 - val_loss: 0.0102 - val_mse: 0.0240\n",
      "Epoch 329/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0076 - mse: 0.0169 - val_loss: 0.0102 - val_mse: 0.0240\n",
      "Epoch 330/2000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0076 - mse: 0.0169 - val_loss: 0.0102 - val_mse: 0.0239\n",
      "Epoch 331/2000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.0076 - mse: 0.0169 - val_loss: 0.0102 - val_mse: 0.0239\n",
      "Epoch 332/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0076 - mse: 0.0169 - val_loss: 0.0102 - val_mse: 0.0239\n",
      "Epoch 333/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0076 - mse: 0.0169 - val_loss: 0.0102 - val_mse: 0.0239\n",
      "Epoch 334/2000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0076 - mse: 0.0168 - val_loss: 0.0102 - val_mse: 0.0239\n",
      "Epoch 335/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0076 - mse: 0.0168 - val_loss: 0.0101 - val_mse: 0.0239\n",
      "Epoch 336/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0076 - mse: 0.0169 - val_loss: 0.0101 - val_mse: 0.0239\n",
      "Epoch 337/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0076 - mse: 0.0168 - val_loss: 0.0101 - val_mse: 0.0239\n",
      "Epoch 338/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0076 - mse: 0.0168 - val_loss: 0.0101 - val_mse: 0.0239\n",
      "Epoch 339/2000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0076 - mse: 0.0168 - val_loss: 0.0101 - val_mse: 0.0238\n",
      "Epoch 340/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0076 - mse: 0.0168 - val_loss: 0.0101 - val_mse: 0.0238\n",
      "Epoch 341/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0076 - mse: 0.0168 - val_loss: 0.0101 - val_mse: 0.0238\n",
      "Epoch 342/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0076 - mse: 0.0168 - val_loss: 0.0101 - val_mse: 0.0238\n",
      "Epoch 343/2000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0076 - mse: 0.0168 - val_loss: 0.0101 - val_mse: 0.0238\n",
      "Epoch 344/2000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0076 - mse: 0.0168 - val_loss: 0.0101 - val_mse: 0.0238\n",
      "Epoch 345/2000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0076 - mse: 0.0168 - val_loss: 0.0101 - val_mse: 0.0238\n",
      "Epoch 346/2000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0076 - mse: 0.0168 - val_loss: 0.0101 - val_mse: 0.0238\n",
      "Epoch 347/2000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0076 - mse: 0.0168 - val_loss: 0.0101 - val_mse: 0.0237\n",
      "Epoch 348/2000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0076 - mse: 0.0168 - val_loss: 0.0101 - val_mse: 0.0237\n",
      "Epoch 349/2000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0076 - mse: 0.0168 - val_loss: 0.0101 - val_mse: 0.0237\n",
      "Epoch 350/2000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0076 - mse: 0.0168 - val_loss: 0.0101 - val_mse: 0.0237\n",
      "Epoch 351/2000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0076 - mse: 0.0168 - val_loss: 0.0101 - val_mse: 0.0237\n",
      "Epoch 352/2000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0076 - mse: 0.0168 - val_loss: 0.0101 - val_mse: 0.0237\n",
      "Epoch 353/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0076 - mse: 0.0168 - val_loss: 0.0101 - val_mse: 0.0237\n",
      "Epoch 354/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0075 - mse: 0.0168 - val_loss: 0.0101 - val_mse: 0.0237\n",
      "Epoch 355/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0076 - mse: 0.0168 - val_loss: 0.0101 - val_mse: 0.0237\n",
      "Epoch 356/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0075 - mse: 0.0168 - val_loss: 0.0101 - val_mse: 0.0237\n",
      "Epoch 357/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0075 - mse: 0.0167 - val_loss: 0.0100 - val_mse: 0.0237\n",
      "Epoch 358/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0075 - mse: 0.0167 - val_loss: 0.0100 - val_mse: 0.0236\n",
      "Epoch 359/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0075 - mse: 0.0167 - val_loss: 0.0100 - val_mse: 0.0236\n",
      "Epoch 360/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0075 - mse: 0.0167 - val_loss: 0.0100 - val_mse: 0.0236\n",
      "Epoch 361/2000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0075 - mse: 0.0167 - val_loss: 0.0100 - val_mse: 0.0236\n",
      "Epoch 362/2000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0075 - mse: 0.0167 - val_loss: 0.0100 - val_mse: 0.0236\n",
      "Epoch 363/2000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0075 - mse: 0.0167 - val_loss: 0.0100 - val_mse: 0.0236\n",
      "Epoch 364/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0075 - mse: 0.0167 - val_loss: 0.0100 - val_mse: 0.0236\n",
      "Epoch 365/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0075 - mse: 0.0167 - val_loss: 0.0100 - val_mse: 0.0235\n",
      "Epoch 366/2000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0075 - mse: 0.0167 - val_loss: 0.0100 - val_mse: 0.0235\n",
      "Epoch 367/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0075 - mse: 0.0167 - val_loss: 0.0100 - val_mse: 0.0235\n",
      "Epoch 368/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0075 - mse: 0.0167 - val_loss: 0.0100 - val_mse: 0.0235\n",
      "Epoch 369/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0075 - mse: 0.0167 - val_loss: 0.0100 - val_mse: 0.0235\n",
      "Epoch 370/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0075 - mse: 0.0167 - val_loss: 0.0100 - val_mse: 0.0235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 371/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0075 - mse: 0.0167 - val_loss: 0.0100 - val_mse: 0.0235\n",
      "Epoch 372/2000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0075 - mse: 0.0167 - val_loss: 0.0100 - val_mse: 0.0235\n",
      "Epoch 373/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0075 - mse: 0.0167 - val_loss: 0.0100 - val_mse: 0.0235\n",
      "Epoch 374/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0075 - mse: 0.0167 - val_loss: 0.0100 - val_mse: 0.0235\n",
      "Epoch 375/2000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0075 - mse: 0.0167 - val_loss: 0.0100 - val_mse: 0.0234\n",
      "Epoch 376/2000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0075 - mse: 0.0167 - val_loss: 0.0100 - val_mse: 0.0234\n",
      "Epoch 377/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0075 - mse: 0.0167 - val_loss: 0.0100 - val_mse: 0.0234\n",
      "Epoch 378/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0075 - mse: 0.0167 - val_loss: 0.0100 - val_mse: 0.0234\n",
      "Epoch 379/2000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0075 - mse: 0.0167 - val_loss: 0.0099 - val_mse: 0.0234\n",
      "Epoch 380/2000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0075 - mse: 0.0167 - val_loss: 0.0099 - val_mse: 0.0234\n",
      "Epoch 381/2000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0075 - mse: 0.0167 - val_loss: 0.0099 - val_mse: 0.0234\n",
      "Epoch 382/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0075 - mse: 0.0167 - val_loss: 0.0099 - val_mse: 0.0234\n",
      "Epoch 383/2000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0075 - mse: 0.0166 - val_loss: 0.0099 - val_mse: 0.0233\n",
      "Epoch 384/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0075 - mse: 0.0166 - val_loss: 0.0099 - val_mse: 0.0233\n",
      "Epoch 385/2000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0075 - mse: 0.0166 - val_loss: 0.0099 - val_mse: 0.0233\n",
      "Epoch 386/2000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0075 - mse: 0.0166 - val_loss: 0.0099 - val_mse: 0.0233\n",
      "Epoch 387/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0075 - mse: 0.0166 - val_loss: 0.0099 - val_mse: 0.0233\n",
      "Epoch 388/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0075 - mse: 0.0166 - val_loss: 0.0099 - val_mse: 0.0233\n",
      "Epoch 389/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0075 - mse: 0.0166 - val_loss: 0.0099 - val_mse: 0.0233\n",
      "Epoch 390/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0075 - mse: 0.0166 - val_loss: 0.0099 - val_mse: 0.0233\n",
      "Epoch 391/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0075 - mse: 0.0166 - val_loss: 0.0099 - val_mse: 0.0233\n",
      "Epoch 392/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0075 - mse: 0.0166 - val_loss: 0.0099 - val_mse: 0.0232\n",
      "Epoch 393/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0075 - mse: 0.0166 - val_loss: 0.0099 - val_mse: 0.0232\n",
      "Epoch 394/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0075 - mse: 0.0166 - val_loss: 0.0099 - val_mse: 0.0232\n",
      "Epoch 395/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0075 - mse: 0.0166 - val_loss: 0.0099 - val_mse: 0.0232\n",
      "Epoch 396/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0075 - mse: 0.0166 - val_loss: 0.0099 - val_mse: 0.0232\n",
      "Epoch 397/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0075 - mse: 0.0166 - val_loss: 0.0099 - val_mse: 0.0232\n",
      "Epoch 398/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0075 - mse: 0.0166 - val_loss: 0.0098 - val_mse: 0.0232\n",
      "Epoch 399/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0075 - mse: 0.0166 - val_loss: 0.0098 - val_mse: 0.0232\n",
      "Epoch 400/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0075 - mse: 0.0166 - val_loss: 0.0098 - val_mse: 0.0232\n",
      "Epoch 401/2000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0075 - mse: 0.0166 - val_loss: 0.0098 - val_mse: 0.0231\n",
      "Epoch 402/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0075 - mse: 0.0166 - val_loss: 0.0098 - val_mse: 0.0231\n",
      "Epoch 403/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0075 - mse: 0.0166 - val_loss: 0.0098 - val_mse: 0.0231\n",
      "Epoch 404/2000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0075 - mse: 0.0166 - val_loss: 0.0098 - val_mse: 0.0231\n",
      "Epoch 405/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0075 - mse: 0.0166 - val_loss: 0.0098 - val_mse: 0.0231\n",
      "Epoch 406/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0075 - mse: 0.0166 - val_loss: 0.0098 - val_mse: 0.0231\n",
      "Epoch 407/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0075 - mse: 0.0166 - val_loss: 0.0098 - val_mse: 0.0230\n",
      "Epoch 408/2000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0075 - mse: 0.0165 - val_loss: 0.0098 - val_mse: 0.0230\n",
      "Epoch 409/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0075 - mse: 0.0166 - val_loss: 0.0098 - val_mse: 0.0230\n",
      "Epoch 410/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0075 - mse: 0.0165 - val_loss: 0.0098 - val_mse: 0.0230\n",
      "Epoch 411/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0075 - mse: 0.0166 - val_loss: 0.0098 - val_mse: 0.0230\n",
      "Epoch 412/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0075 - mse: 0.0166 - val_loss: 0.0098 - val_mse: 0.0230\n",
      "Epoch 413/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0075 - mse: 0.0165 - val_loss: 0.0098 - val_mse: 0.0230\n",
      "Epoch 414/2000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0074 - mse: 0.0165 - val_loss: 0.0097 - val_mse: 0.0229\n",
      "Epoch 415/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0074 - mse: 0.0165 - val_loss: 0.0097 - val_mse: 0.0229\n",
      "Epoch 416/2000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0075 - mse: 0.0165 - val_loss: 0.0097 - val_mse: 0.0229\n",
      "Epoch 417/2000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0074 - mse: 0.0165 - val_loss: 0.0097 - val_mse: 0.0229\n",
      "Epoch 418/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0074 - mse: 0.0165 - val_loss: 0.0097 - val_mse: 0.0229\n",
      "Epoch 419/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0074 - mse: 0.0165 - val_loss: 0.0097 - val_mse: 0.0229\n",
      "Epoch 420/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0074 - mse: 0.0165 - val_loss: 0.0097 - val_mse: 0.0228\n",
      "Epoch 421/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0074 - mse: 0.0165 - val_loss: 0.0097 - val_mse: 0.0228\n",
      "Epoch 422/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0074 - mse: 0.0165 - val_loss: 0.0097 - val_mse: 0.0228\n",
      "Epoch 423/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0074 - mse: 0.0165 - val_loss: 0.0097 - val_mse: 0.0228\n",
      "Epoch 424/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0074 - mse: 0.0165 - val_loss: 0.0097 - val_mse: 0.0227\n",
      "Epoch 425/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0074 - mse: 0.0165 - val_loss: 0.0097 - val_mse: 0.0227\n",
      "Epoch 426/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0074 - mse: 0.0165 - val_loss: 0.0097 - val_mse: 0.0227\n",
      "Epoch 427/2000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0074 - mse: 0.0165 - val_loss: 0.0096 - val_mse: 0.0227\n",
      "Epoch 428/2000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0074 - mse: 0.0165 - val_loss: 0.0096 - val_mse: 0.0227\n",
      "Epoch 429/2000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0074 - mse: 0.0165 - val_loss: 0.0096 - val_mse: 0.0227\n",
      "Epoch 430/2000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0074 - mse: 0.0164 - val_loss: 0.0096 - val_mse: 0.0226\n",
      "Epoch 431/2000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0074 - mse: 0.0164 - val_loss: 0.0096 - val_mse: 0.0226\n",
      "Epoch 432/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0074 - mse: 0.0164 - val_loss: 0.0096 - val_mse: 0.0226\n",
      "Epoch 433/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0074 - mse: 0.0165 - val_loss: 0.0096 - val_mse: 0.0225\n",
      "Epoch 434/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0074 - mse: 0.0164 - val_loss: 0.0096 - val_mse: 0.0225\n",
      "Epoch 435/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0074 - mse: 0.0164 - val_loss: 0.0096 - val_mse: 0.0225\n",
      "Epoch 436/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0074 - mse: 0.0164 - val_loss: 0.0095 - val_mse: 0.0224\n",
      "Epoch 437/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0074 - mse: 0.0164 - val_loss: 0.0095 - val_mse: 0.0224\n",
      "Epoch 438/2000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0074 - mse: 0.0164 - val_loss: 0.0095 - val_mse: 0.0224\n",
      "Epoch 439/2000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0074 - mse: 0.0164 - val_loss: 0.0095 - val_mse: 0.0224\n",
      "Epoch 440/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0074 - mse: 0.0164 - val_loss: 0.0095 - val_mse: 0.0223\n",
      "Epoch 441/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0074 - mse: 0.0164 - val_loss: 0.0095 - val_mse: 0.0223\n",
      "Epoch 442/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0074 - mse: 0.0164 - val_loss: 0.0095 - val_mse: 0.0223\n",
      "Epoch 443/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0074 - mse: 0.0164 - val_loss: 0.0095 - val_mse: 0.0223\n",
      "Epoch 444/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0074 - mse: 0.0164 - val_loss: 0.0095 - val_mse: 0.0222\n",
      "Epoch 445/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0074 - mse: 0.0164 - val_loss: 0.0095 - val_mse: 0.0222\n",
      "Epoch 446/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0074 - mse: 0.0164 - val_loss: 0.0094 - val_mse: 0.0222\n",
      "Epoch 447/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0074 - mse: 0.0164 - val_loss: 0.0094 - val_mse: 0.0222\n",
      "Epoch 448/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0074 - mse: 0.0164 - val_loss: 0.0094 - val_mse: 0.0222\n",
      "Epoch 449/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0074 - mse: 0.0164 - val_loss: 0.0094 - val_mse: 0.0221\n",
      "Epoch 450/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0074 - mse: 0.0164 - val_loss: 0.0094 - val_mse: 0.0221\n",
      "Epoch 451/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0074 - mse: 0.0164 - val_loss: 0.0094 - val_mse: 0.0221\n",
      "Epoch 452/2000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0074 - mse: 0.0163 - val_loss: 0.0094 - val_mse: 0.0220\n",
      "Epoch 453/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0074 - mse: 0.0164 - val_loss: 0.0094 - val_mse: 0.0220\n",
      "Epoch 454/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0074 - mse: 0.0163 - val_loss: 0.0094 - val_mse: 0.0220\n",
      "Epoch 455/2000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0074 - mse: 0.0163 - val_loss: 0.0093 - val_mse: 0.0219\n",
      "Epoch 456/2000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0074 - mse: 0.0163 - val_loss: 0.0093 - val_mse: 0.0219\n",
      "Epoch 457/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0074 - mse: 0.0163 - val_loss: 0.0093 - val_mse: 0.0219\n",
      "Epoch 458/2000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0074 - mse: 0.0163 - val_loss: 0.0093 - val_mse: 0.0219\n",
      "Epoch 459/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0074 - mse: 0.0163 - val_loss: 0.0093 - val_mse: 0.0218\n",
      "Epoch 460/2000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0074 - mse: 0.0163 - val_loss: 0.0093 - val_mse: 0.0218\n",
      "Epoch 461/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0074 - mse: 0.0163 - val_loss: 0.0093 - val_mse: 0.0218\n",
      "Epoch 462/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0074 - mse: 0.0163 - val_loss: 0.0093 - val_mse: 0.0217\n",
      "Epoch 463/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0074 - mse: 0.0163 - val_loss: 0.0092 - val_mse: 0.0217\n",
      "Epoch 464/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0074 - mse: 0.0163 - val_loss: 0.0092 - val_mse: 0.0217\n",
      "Epoch 465/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0074 - mse: 0.0163 - val_loss: 0.0092 - val_mse: 0.0216\n",
      "Epoch 466/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0073 - mse: 0.0163 - val_loss: 0.0092 - val_mse: 0.0216\n",
      "Epoch 467/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0073 - mse: 0.0163 - val_loss: 0.0092 - val_mse: 0.0215\n",
      "Epoch 468/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0073 - mse: 0.0163 - val_loss: 0.0092 - val_mse: 0.0215\n",
      "Epoch 469/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0073 - mse: 0.0162 - val_loss: 0.0091 - val_mse: 0.0215\n",
      "Epoch 470/2000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0073 - mse: 0.0163 - val_loss: 0.0091 - val_mse: 0.0214\n",
      "Epoch 471/2000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0073 - mse: 0.0162 - val_loss: 0.0091 - val_mse: 0.0214\n",
      "Epoch 472/2000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0073 - mse: 0.0162 - val_loss: 0.0091 - val_mse: 0.0214\n",
      "Epoch 473/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0073 - mse: 0.0162 - val_loss: 0.0091 - val_mse: 0.0214\n",
      "Epoch 474/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0073 - mse: 0.0162 - val_loss: 0.0091 - val_mse: 0.0213\n",
      "Epoch 475/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0073 - mse: 0.0162 - val_loss: 0.0091 - val_mse: 0.0213\n",
      "Epoch 476/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0073 - mse: 0.0162 - val_loss: 0.0091 - val_mse: 0.0213\n",
      "Epoch 477/2000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0073 - mse: 0.0162 - val_loss: 0.0091 - val_mse: 0.0212\n",
      "Epoch 478/2000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0073 - mse: 0.0162 - val_loss: 0.0090 - val_mse: 0.0212\n",
      "Epoch 479/2000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0073 - mse: 0.0162 - val_loss: 0.0090 - val_mse: 0.0211\n",
      "Epoch 480/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0073 - mse: 0.0162 - val_loss: 0.0090 - val_mse: 0.0211\n",
      "Epoch 481/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0073 - mse: 0.0162 - val_loss: 0.0090 - val_mse: 0.0211\n",
      "Epoch 482/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0073 - mse: 0.0162 - val_loss: 0.0090 - val_mse: 0.0210\n",
      "Epoch 483/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0073 - mse: 0.0162 - val_loss: 0.0090 - val_mse: 0.0210\n",
      "Epoch 484/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0073 - mse: 0.0161 - val_loss: 0.0090 - val_mse: 0.0210\n",
      "Epoch 485/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0073 - mse: 0.0161 - val_loss: 0.0089 - val_mse: 0.0209\n",
      "Epoch 486/2000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0073 - mse: 0.0161 - val_loss: 0.0089 - val_mse: 0.0209\n",
      "Epoch 487/2000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0073 - mse: 0.0161 - val_loss: 0.0089 - val_mse: 0.0208\n",
      "Epoch 488/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0073 - mse: 0.0161 - val_loss: 0.0089 - val_mse: 0.0208\n",
      "Epoch 489/2000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.0073 - mse: 0.0161 - val_loss: 0.0089 - val_mse: 0.0208\n",
      "Epoch 490/2000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.0073 - mse: 0.0161 - val_loss: 0.0089 - val_mse: 0.0207\n",
      "Epoch 491/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0073 - mse: 0.0161 - val_loss: 0.0088 - val_mse: 0.0207\n",
      "Epoch 492/2000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0073 - mse: 0.0161 - val_loss: 0.0088 - val_mse: 0.0207\n",
      "Epoch 493/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0073 - mse: 0.0161 - val_loss: 0.0088 - val_mse: 0.0206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 494/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0073 - mse: 0.0161 - val_loss: 0.0088 - val_mse: 0.0206\n",
      "Epoch 495/2000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0073 - mse: 0.0161 - val_loss: 0.0088 - val_mse: 0.0205\n",
      "Epoch 496/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0073 - mse: 0.0161 - val_loss: 0.0088 - val_mse: 0.0205\n",
      "Epoch 497/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0073 - mse: 0.0161 - val_loss: 0.0088 - val_mse: 0.0205\n",
      "Epoch 498/2000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0073 - mse: 0.0161 - val_loss: 0.0087 - val_mse: 0.0204\n",
      "Epoch 499/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0072 - mse: 0.0160 - val_loss: 0.0087 - val_mse: 0.0204\n",
      "Epoch 500/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0073 - mse: 0.0161 - val_loss: 0.0087 - val_mse: 0.0203\n",
      "Epoch 501/2000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0073 - mse: 0.0160 - val_loss: 0.0087 - val_mse: 0.0203\n",
      "Epoch 502/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0073 - mse: 0.0161 - val_loss: 0.0087 - val_mse: 0.0203\n",
      "Epoch 503/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0072 - mse: 0.0160 - val_loss: 0.0086 - val_mse: 0.0202\n",
      "Epoch 504/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0072 - mse: 0.0160 - val_loss: 0.0086 - val_mse: 0.0202\n",
      "Epoch 505/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0072 - mse: 0.0160 - val_loss: 0.0086 - val_mse: 0.0201\n",
      "Epoch 506/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0072 - mse: 0.0160 - val_loss: 0.0086 - val_mse: 0.0201\n",
      "Epoch 507/2000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0072 - mse: 0.0160 - val_loss: 0.0086 - val_mse: 0.0201\n",
      "Epoch 508/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0072 - mse: 0.0160 - val_loss: 0.0086 - val_mse: 0.0200\n",
      "Epoch 509/2000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0072 - mse: 0.0160 - val_loss: 0.0086 - val_mse: 0.0200\n",
      "Epoch 510/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0072 - mse: 0.0160 - val_loss: 0.0085 - val_mse: 0.0200\n",
      "Epoch 511/2000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0072 - mse: 0.0160 - val_loss: 0.0085 - val_mse: 0.0199\n",
      "Epoch 512/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0072 - mse: 0.0160 - val_loss: 0.0085 - val_mse: 0.0199\n",
      "Epoch 513/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0072 - mse: 0.0160 - val_loss: 0.0085 - val_mse: 0.0198\n",
      "Epoch 514/2000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0072 - mse: 0.0160 - val_loss: 0.0085 - val_mse: 0.0198\n",
      "Epoch 515/2000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0072 - mse: 0.0160 - val_loss: 0.0085 - val_mse: 0.0198\n",
      "Epoch 516/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0072 - mse: 0.0160 - val_loss: 0.0085 - val_mse: 0.0197\n",
      "Epoch 517/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0072 - mse: 0.0160 - val_loss: 0.0084 - val_mse: 0.0197\n",
      "Epoch 518/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0072 - mse: 0.0159 - val_loss: 0.0084 - val_mse: 0.0196\n",
      "Epoch 519/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0072 - mse: 0.0159 - val_loss: 0.0084 - val_mse: 0.0196\n",
      "Epoch 520/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0072 - mse: 0.0160 - val_loss: 0.0084 - val_mse: 0.0196\n",
      "Epoch 521/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0072 - mse: 0.0159 - val_loss: 0.0084 - val_mse: 0.0195\n",
      "Epoch 522/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0072 - mse: 0.0159 - val_loss: 0.0084 - val_mse: 0.0195\n",
      "Epoch 523/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0072 - mse: 0.0159 - val_loss: 0.0084 - val_mse: 0.0195\n",
      "Epoch 524/2000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0072 - mse: 0.0159 - val_loss: 0.0083 - val_mse: 0.0194\n",
      "Epoch 525/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0072 - mse: 0.0159 - val_loss: 0.0083 - val_mse: 0.0194\n",
      "Epoch 526/2000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0072 - mse: 0.0159 - val_loss: 0.0083 - val_mse: 0.0194\n",
      "Epoch 527/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0072 - mse: 0.0159 - val_loss: 0.0083 - val_mse: 0.0193\n",
      "Epoch 528/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0072 - mse: 0.0159 - val_loss: 0.0083 - val_mse: 0.0193\n",
      "Epoch 529/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0072 - mse: 0.0159 - val_loss: 0.0083 - val_mse: 0.0193\n",
      "Epoch 530/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0072 - mse: 0.0159 - val_loss: 0.0083 - val_mse: 0.0193\n",
      "Epoch 531/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0072 - mse: 0.0159 - val_loss: 0.0083 - val_mse: 0.0192\n",
      "Epoch 532/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0072 - mse: 0.0159 - val_loss: 0.0082 - val_mse: 0.0192\n",
      "Epoch 533/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0072 - mse: 0.0159 - val_loss: 0.0082 - val_mse: 0.0191\n",
      "Epoch 534/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0072 - mse: 0.0159 - val_loss: 0.0082 - val_mse: 0.0191\n",
      "Epoch 535/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0072 - mse: 0.0159 - val_loss: 0.0082 - val_mse: 0.0191\n",
      "Epoch 536/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0072 - mse: 0.0159 - val_loss: 0.0082 - val_mse: 0.0191\n",
      "Epoch 537/2000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0072 - mse: 0.0159 - val_loss: 0.0082 - val_mse: 0.0190\n",
      "Epoch 538/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0072 - mse: 0.0159 - val_loss: 0.0082 - val_mse: 0.0190\n",
      "Epoch 539/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0072 - mse: 0.0158 - val_loss: 0.0082 - val_mse: 0.0190\n",
      "Epoch 540/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0072 - mse: 0.0159 - val_loss: 0.0081 - val_mse: 0.0189\n",
      "Epoch 541/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0072 - mse: 0.0158 - val_loss: 0.0081 - val_mse: 0.0189\n",
      "Epoch 542/2000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0072 - mse: 0.0158 - val_loss: 0.0081 - val_mse: 0.0189\n",
      "Epoch 543/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0072 - mse: 0.0158 - val_loss: 0.0081 - val_mse: 0.0189\n",
      "Epoch 544/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0071 - mse: 0.0158 - val_loss: 0.0081 - val_mse: 0.0188\n",
      "Epoch 545/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0071 - mse: 0.0158 - val_loss: 0.0081 - val_mse: 0.0188\n",
      "Epoch 546/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0072 - mse: 0.0158 - val_loss: 0.0081 - val_mse: 0.0188\n",
      "Epoch 547/2000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0072 - mse: 0.0158 - val_loss: 0.0081 - val_mse: 0.0188\n",
      "Epoch 548/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0072 - mse: 0.0158 - val_loss: 0.0081 - val_mse: 0.0187\n",
      "Epoch 549/2000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0071 - mse: 0.0158 - val_loss: 0.0081 - val_mse: 0.0187\n",
      "Epoch 550/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0071 - mse: 0.0158 - val_loss: 0.0080 - val_mse: 0.0187\n",
      "Epoch 551/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0071 - mse: 0.0158 - val_loss: 0.0080 - val_mse: 0.0187\n",
      "Epoch 552/2000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0071 - mse: 0.0158 - val_loss: 0.0080 - val_mse: 0.0186\n",
      "Epoch 553/2000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0071 - mse: 0.0158 - val_loss: 0.0080 - val_mse: 0.0186\n",
      "Epoch 554/2000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0071 - mse: 0.0158 - val_loss: 0.0080 - val_mse: 0.0186\n",
      "Epoch 555/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0071 - mse: 0.0158 - val_loss: 0.0080 - val_mse: 0.0186\n",
      "Epoch 556/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0071 - mse: 0.0158 - val_loss: 0.0080 - val_mse: 0.0185\n",
      "Epoch 557/2000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0071 - mse: 0.0158 - val_loss: 0.0080 - val_mse: 0.0185\n",
      "Epoch 558/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0071 - mse: 0.0158 - val_loss: 0.0080 - val_mse: 0.0185\n",
      "Epoch 559/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0071 - mse: 0.0158 - val_loss: 0.0080 - val_mse: 0.0185\n",
      "Epoch 560/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0071 - mse: 0.0157 - val_loss: 0.0080 - val_mse: 0.0185\n",
      "Epoch 561/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0071 - mse: 0.0158 - val_loss: 0.0079 - val_mse: 0.0184\n",
      "Epoch 562/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0071 - mse: 0.0157 - val_loss: 0.0079 - val_mse: 0.0184\n",
      "Epoch 563/2000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0071 - mse: 0.0157 - val_loss: 0.0079 - val_mse: 0.0184\n",
      "Epoch 564/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0071 - mse: 0.0157 - val_loss: 0.0079 - val_mse: 0.0184\n",
      "Epoch 565/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0071 - mse: 0.0157 - val_loss: 0.0079 - val_mse: 0.0183\n",
      "Epoch 566/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0071 - mse: 0.0157 - val_loss: 0.0079 - val_mse: 0.0183\n",
      "Epoch 567/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0071 - mse: 0.0157 - val_loss: 0.0079 - val_mse: 0.0183\n",
      "Epoch 568/2000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0071 - mse: 0.0157 - val_loss: 0.0079 - val_mse: 0.0183\n",
      "Epoch 569/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0071 - mse: 0.0157 - val_loss: 0.0079 - val_mse: 0.0183\n",
      "Epoch 570/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0071 - mse: 0.0157 - val_loss: 0.0079 - val_mse: 0.0183\n",
      "Epoch 571/2000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0071 - mse: 0.0157 - val_loss: 0.0079 - val_mse: 0.0182\n",
      "Epoch 572/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0071 - mse: 0.0157 - val_loss: 0.0079 - val_mse: 0.0182\n",
      "Epoch 573/2000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0071 - mse: 0.0157 - val_loss: 0.0079 - val_mse: 0.0182\n",
      "Epoch 574/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0071 - mse: 0.0157 - val_loss: 0.0079 - val_mse: 0.0182\n",
      "Epoch 575/2000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0071 - mse: 0.0157 - val_loss: 0.0078 - val_mse: 0.0182\n",
      "Epoch 576/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0071 - mse: 0.0157 - val_loss: 0.0078 - val_mse: 0.0181\n",
      "Epoch 577/2000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0071 - mse: 0.0157 - val_loss: 0.0078 - val_mse: 0.0181\n",
      "Epoch 578/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0071 - mse: 0.0157 - val_loss: 0.0078 - val_mse: 0.0181\n",
      "Epoch 579/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0071 - mse: 0.0157 - val_loss: 0.0078 - val_mse: 0.0181\n",
      "Epoch 580/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0071 - mse: 0.0157 - val_loss: 0.0078 - val_mse: 0.0181\n",
      "Epoch 581/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0071 - mse: 0.0157 - val_loss: 0.0078 - val_mse: 0.0181\n",
      "Epoch 582/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0071 - mse: 0.0157 - val_loss: 0.0078 - val_mse: 0.0181\n",
      "Epoch 583/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0071 - mse: 0.0157 - val_loss: 0.0078 - val_mse: 0.0180\n",
      "Epoch 584/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0071 - mse: 0.0157 - val_loss: 0.0078 - val_mse: 0.0180\n",
      "Epoch 585/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0071 - mse: 0.0156 - val_loss: 0.0078 - val_mse: 0.0180\n",
      "Epoch 586/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0071 - mse: 0.0156 - val_loss: 0.0078 - val_mse: 0.0180\n",
      "Epoch 587/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0071 - mse: 0.0157 - val_loss: 0.0078 - val_mse: 0.0180\n",
      "Epoch 588/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0071 - mse: 0.0157 - val_loss: 0.0078 - val_mse: 0.0180\n",
      "Epoch 589/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0071 - mse: 0.0156 - val_loss: 0.0078 - val_mse: 0.0180\n",
      "Epoch 590/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0071 - mse: 0.0156 - val_loss: 0.0078 - val_mse: 0.0179\n",
      "Epoch 591/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0071 - mse: 0.0156 - val_loss: 0.0078 - val_mse: 0.0179\n",
      "Epoch 592/2000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0071 - mse: 0.0156 - val_loss: 0.0077 - val_mse: 0.0179\n",
      "Epoch 593/2000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0071 - mse: 0.0156 - val_loss: 0.0077 - val_mse: 0.0179\n",
      "Epoch 594/2000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0071 - mse: 0.0156 - val_loss: 0.0077 - val_mse: 0.0179\n",
      "Epoch 595/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0071 - mse: 0.0156 - val_loss: 0.0077 - val_mse: 0.0179\n",
      "Epoch 596/2000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0071 - mse: 0.0156 - val_loss: 0.0077 - val_mse: 0.0179\n",
      "Epoch 597/2000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0071 - mse: 0.0156 - val_loss: 0.0077 - val_mse: 0.0179\n",
      "Epoch 598/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0071 - mse: 0.0156 - val_loss: 0.0077 - val_mse: 0.0178\n",
      "Epoch 599/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0071 - mse: 0.0156 - val_loss: 0.0077 - val_mse: 0.0178\n",
      "Epoch 600/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0071 - mse: 0.0156 - val_loss: 0.0077 - val_mse: 0.0178\n",
      "Epoch 601/2000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0071 - mse: 0.0156 - val_loss: 0.0077 - val_mse: 0.0178\n",
      "Epoch 602/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0071 - mse: 0.0156 - val_loss: 0.0077 - val_mse: 0.0178\n",
      "Epoch 603/2000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0071 - mse: 0.0156 - val_loss: 0.0077 - val_mse: 0.0178\n",
      "Epoch 604/2000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0070 - mse: 0.0156 - val_loss: 0.0077 - val_mse: 0.0178\n",
      "Epoch 605/2000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0071 - mse: 0.0156 - val_loss: 0.0077 - val_mse: 0.0178\n",
      "Epoch 606/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0070 - mse: 0.0156 - val_loss: 0.0077 - val_mse: 0.0178\n",
      "Epoch 607/2000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0070 - mse: 0.0156 - val_loss: 0.0077 - val_mse: 0.0178\n",
      "Epoch 608/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0070 - mse: 0.0156 - val_loss: 0.0077 - val_mse: 0.0178\n",
      "Epoch 609/2000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0070 - mse: 0.0155 - val_loss: 0.0077 - val_mse: 0.0178\n",
      "Epoch 610/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0070 - mse: 0.0155 - val_loss: 0.0077 - val_mse: 0.0177\n",
      "Epoch 611/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0070 - mse: 0.0156 - val_loss: 0.0077 - val_mse: 0.0177\n",
      "Epoch 612/2000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0070 - mse: 0.0156 - val_loss: 0.0077 - val_mse: 0.0177\n",
      "Epoch 613/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0070 - mse: 0.0156 - val_loss: 0.0077 - val_mse: 0.0177\n",
      "Epoch 614/2000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0070 - mse: 0.0156 - val_loss: 0.0077 - val_mse: 0.0177\n",
      "Epoch 615/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0070 - mse: 0.0156 - val_loss: 0.0077 - val_mse: 0.0177\n",
      "Epoch 616/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0070 - mse: 0.0156 - val_loss: 0.0077 - val_mse: 0.0177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 617/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0070 - mse: 0.0156 - val_loss: 0.0077 - val_mse: 0.0177\n",
      "Epoch 618/2000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0070 - mse: 0.0155 - val_loss: 0.0077 - val_mse: 0.0177\n",
      "Epoch 619/2000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0070 - mse: 0.0156 - val_loss: 0.0077 - val_mse: 0.0177\n",
      "Epoch 620/2000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0070 - mse: 0.0155 - val_loss: 0.0077 - val_mse: 0.0177\n",
      "Epoch 621/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0070 - mse: 0.0155 - val_loss: 0.0077 - val_mse: 0.0177\n",
      "Epoch 622/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0070 - mse: 0.0155 - val_loss: 0.0077 - val_mse: 0.0177\n",
      "Epoch 623/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0070 - mse: 0.0155 - val_loss: 0.0076 - val_mse: 0.0177\n",
      "Epoch 624/2000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0070 - mse: 0.0155 - val_loss: 0.0076 - val_mse: 0.0177\n",
      "Epoch 625/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0070 - mse: 0.0155 - val_loss: 0.0076 - val_mse: 0.0177\n",
      "Epoch 626/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0070 - mse: 0.0155 - val_loss: 0.0076 - val_mse: 0.0176\n",
      "Epoch 627/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0070 - mse: 0.0155 - val_loss: 0.0076 - val_mse: 0.0176\n",
      "Epoch 628/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0070 - mse: 0.0155 - val_loss: 0.0076 - val_mse: 0.0176\n",
      "Epoch 629/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0070 - mse: 0.0155 - val_loss: 0.0076 - val_mse: 0.0176\n",
      "Epoch 630/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0070 - mse: 0.0155 - val_loss: 0.0076 - val_mse: 0.0176\n",
      "Epoch 631/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0070 - mse: 0.0155 - val_loss: 0.0076 - val_mse: 0.0176\n",
      "Epoch 632/2000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0070 - mse: 0.0155 - val_loss: 0.0076 - val_mse: 0.0176\n",
      "Epoch 633/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0070 - mse: 0.0155 - val_loss: 0.0076 - val_mse: 0.0176\n",
      "Epoch 634/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0070 - mse: 0.0155 - val_loss: 0.0076 - val_mse: 0.0176\n",
      "Epoch 635/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0070 - mse: 0.0155 - val_loss: 0.0076 - val_mse: 0.0176\n",
      "Epoch 636/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0070 - mse: 0.0155 - val_loss: 0.0076 - val_mse: 0.0176\n",
      "Epoch 637/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0070 - mse: 0.0155 - val_loss: 0.0076 - val_mse: 0.0176\n",
      "Epoch 638/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0070 - mse: 0.0155 - val_loss: 0.0076 - val_mse: 0.0176\n",
      "Epoch 639/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0070 - mse: 0.0155 - val_loss: 0.0076 - val_mse: 0.0176\n",
      "Epoch 640/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0070 - mse: 0.0155 - val_loss: 0.0076 - val_mse: 0.0176\n",
      "Epoch 641/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0070 - mse: 0.0155 - val_loss: 0.0076 - val_mse: 0.0176\n",
      "Epoch 642/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0070 - mse: 0.0155 - val_loss: 0.0076 - val_mse: 0.0176\n",
      "Epoch 643/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0070 - mse: 0.0155 - val_loss: 0.0076 - val_mse: 0.0176\n",
      "Epoch 644/2000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0070 - mse: 0.0155 - val_loss: 0.0076 - val_mse: 0.0176\n",
      "Epoch 645/2000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0070 - mse: 0.0154 - val_loss: 0.0076 - val_mse: 0.0175\n",
      "Epoch 646/2000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0070 - mse: 0.0155 - val_loss: 0.0076 - val_mse: 0.0175\n",
      "Epoch 647/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0070 - mse: 0.0155 - val_loss: 0.0076 - val_mse: 0.0175\n",
      "Epoch 648/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0070 - mse: 0.0154 - val_loss: 0.0076 - val_mse: 0.0175\n",
      "Epoch 649/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0070 - mse: 0.0155 - val_loss: 0.0076 - val_mse: 0.0175\n",
      "Epoch 650/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0070 - mse: 0.0154 - val_loss: 0.0076 - val_mse: 0.0175\n",
      "Epoch 651/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0070 - mse: 0.0154 - val_loss: 0.0076 - val_mse: 0.0175\n",
      "Epoch 652/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0070 - mse: 0.0154 - val_loss: 0.0076 - val_mse: 0.0175\n",
      "Epoch 653/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0070 - mse: 0.0154 - val_loss: 0.0076 - val_mse: 0.0175\n",
      "Epoch 654/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0070 - mse: 0.0155 - val_loss: 0.0076 - val_mse: 0.0175\n",
      "Epoch 655/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0070 - mse: 0.0154 - val_loss: 0.0076 - val_mse: 0.0175\n",
      "Epoch 656/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0070 - mse: 0.0154 - val_loss: 0.0076 - val_mse: 0.0175\n",
      "Epoch 657/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0070 - mse: 0.0154 - val_loss: 0.0076 - val_mse: 0.0175\n",
      "Epoch 658/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0070 - mse: 0.0154 - val_loss: 0.0076 - val_mse: 0.0175\n",
      "Epoch 659/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0070 - mse: 0.0154 - val_loss: 0.0076 - val_mse: 0.0175\n",
      "Epoch 660/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0070 - mse: 0.0154 - val_loss: 0.0076 - val_mse: 0.0175\n",
      "Epoch 661/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0070 - mse: 0.0154 - val_loss: 0.0076 - val_mse: 0.0175\n",
      "Epoch 662/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0070 - mse: 0.0154 - val_loss: 0.0076 - val_mse: 0.0175\n",
      "Epoch 663/2000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0070 - mse: 0.0154 - val_loss: 0.0076 - val_mse: 0.0175\n",
      "Epoch 664/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0070 - mse: 0.0154 - val_loss: 0.0076 - val_mse: 0.0175\n",
      "Epoch 665/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0070 - mse: 0.0154 - val_loss: 0.0076 - val_mse: 0.0175\n",
      "Epoch 666/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0070 - mse: 0.0154 - val_loss: 0.0076 - val_mse: 0.0175\n",
      "Epoch 667/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0070 - mse: 0.0154 - val_loss: 0.0076 - val_mse: 0.0175\n",
      "Epoch 668/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0070 - mse: 0.0154 - val_loss: 0.0076 - val_mse: 0.0175\n",
      "Epoch 669/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0070 - mse: 0.0154 - val_loss: 0.0076 - val_mse: 0.0174\n",
      "Epoch 670/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0070 - mse: 0.0154 - val_loss: 0.0076 - val_mse: 0.0174\n",
      "Epoch 671/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0070 - mse: 0.0154 - val_loss: 0.0076 - val_mse: 0.0175\n",
      "Epoch 672/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0070 - mse: 0.0154 - val_loss: 0.0076 - val_mse: 0.0175\n",
      "Epoch 673/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0070 - mse: 0.0154 - val_loss: 0.0076 - val_mse: 0.0175\n",
      "Epoch 674/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0070 - mse: 0.0154 - val_loss: 0.0076 - val_mse: 0.0175\n",
      "Epoch 675/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0070 - mse: 0.0154 - val_loss: 0.0076 - val_mse: 0.0175\n",
      "Epoch 676/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0070 - mse: 0.0154 - val_loss: 0.0076 - val_mse: 0.0174\n",
      "Epoch 677/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0070 - mse: 0.0154 - val_loss: 0.0076 - val_mse: 0.0174\n",
      "Epoch 678/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0070 - mse: 0.0154 - val_loss: 0.0076 - val_mse: 0.0174\n",
      "Epoch 679/2000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0070 - mse: 0.0154 - val_loss: 0.0076 - val_mse: 0.0174\n",
      "Epoch 680/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0070 - mse: 0.0154 - val_loss: 0.0076 - val_mse: 0.0174\n",
      "Epoch 681/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0070 - mse: 0.0154 - val_loss: 0.0076 - val_mse: 0.0174\n",
      "Epoch 682/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0070 - mse: 0.0154 - val_loss: 0.0076 - val_mse: 0.0174\n",
      "Epoch 683/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0070 - mse: 0.0154 - val_loss: 0.0076 - val_mse: 0.0174\n",
      "Epoch 684/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0070 - mse: 0.0154 - val_loss: 0.0076 - val_mse: 0.0174\n",
      "Epoch 685/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0070 - mse: 0.0154 - val_loss: 0.0076 - val_mse: 0.0174\n",
      "Epoch 686/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0069 - mse: 0.0154 - val_loss: 0.0076 - val_mse: 0.0174\n",
      "Epoch 687/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0070 - mse: 0.0154 - val_loss: 0.0076 - val_mse: 0.0174\n",
      "Epoch 688/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0070 - mse: 0.0154 - val_loss: 0.0076 - val_mse: 0.0174\n",
      "Epoch 689/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0069 - mse: 0.0153 - val_loss: 0.0076 - val_mse: 0.0174\n",
      "Epoch 690/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0069 - mse: 0.0153 - val_loss: 0.0075 - val_mse: 0.0174\n",
      "Epoch 691/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0069 - mse: 0.0153 - val_loss: 0.0075 - val_mse: 0.0174\n",
      "Epoch 692/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0070 - mse: 0.0154 - val_loss: 0.0075 - val_mse: 0.0174\n",
      "Epoch 693/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0069 - mse: 0.0153 - val_loss: 0.0075 - val_mse: 0.0174\n",
      "Epoch 694/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0069 - mse: 0.0153 - val_loss: 0.0075 - val_mse: 0.0174\n",
      "Epoch 695/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0069 - mse: 0.0153 - val_loss: 0.0075 - val_mse: 0.0174\n",
      "Epoch 696/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0069 - mse: 0.0153 - val_loss: 0.0075 - val_mse: 0.0174\n",
      "Epoch 697/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0069 - mse: 0.0153 - val_loss: 0.0075 - val_mse: 0.0174\n",
      "Epoch 698/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0069 - mse: 0.0153 - val_loss: 0.0075 - val_mse: 0.0173\n",
      "Epoch 699/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0069 - mse: 0.0153 - val_loss: 0.0075 - val_mse: 0.0173\n",
      "Epoch 700/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0069 - mse: 0.0153 - val_loss: 0.0075 - val_mse: 0.0173\n",
      "Epoch 701/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0069 - mse: 0.0153 - val_loss: 0.0075 - val_mse: 0.0173\n",
      "Epoch 702/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0069 - mse: 0.0153 - val_loss: 0.0075 - val_mse: 0.0173\n",
      "Epoch 703/2000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0069 - mse: 0.0153 - val_loss: 0.0075 - val_mse: 0.0173\n",
      "Epoch 704/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0069 - mse: 0.0153 - val_loss: 0.0075 - val_mse: 0.0173\n",
      "Epoch 705/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0069 - mse: 0.0153 - val_loss: 0.0075 - val_mse: 0.0173\n",
      "Epoch 706/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0069 - mse: 0.0153 - val_loss: 0.0075 - val_mse: 0.0173\n",
      "Epoch 707/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0069 - mse: 0.0153 - val_loss: 0.0075 - val_mse: 0.0173\n",
      "Epoch 708/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0069 - mse: 0.0153 - val_loss: 0.0075 - val_mse: 0.0173\n",
      "Epoch 709/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0069 - mse: 0.0153 - val_loss: 0.0075 - val_mse: 0.0173\n",
      "Epoch 710/2000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0069 - mse: 0.0153 - val_loss: 0.0075 - val_mse: 0.0173\n",
      "Epoch 711/2000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0069 - mse: 0.0153 - val_loss: 0.0075 - val_mse: 0.0173\n",
      "Epoch 712/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0069 - mse: 0.0153 - val_loss: 0.0075 - val_mse: 0.0173\n",
      "Epoch 713/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0069 - mse: 0.0153 - val_loss: 0.0075 - val_mse: 0.0173\n",
      "Epoch 714/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0069 - mse: 0.0153 - val_loss: 0.0075 - val_mse: 0.0173\n",
      "Epoch 715/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0069 - mse: 0.0153 - val_loss: 0.0075 - val_mse: 0.0173\n",
      "Epoch 716/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0069 - mse: 0.0153 - val_loss: 0.0075 - val_mse: 0.0173\n",
      "Epoch 717/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0069 - mse: 0.0153 - val_loss: 0.0075 - val_mse: 0.0173\n",
      "Epoch 718/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0069 - mse: 0.0153 - val_loss: 0.0075 - val_mse: 0.0173\n",
      "Epoch 719/2000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0069 - mse: 0.0153 - val_loss: 0.0075 - val_mse: 0.0173\n",
      "Epoch 720/2000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0069 - mse: 0.0152 - val_loss: 0.0075 - val_mse: 0.0172\n",
      "Epoch 721/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0069 - mse: 0.0153 - val_loss: 0.0075 - val_mse: 0.0172\n",
      "Epoch 722/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0069 - mse: 0.0153 - val_loss: 0.0075 - val_mse: 0.0172\n",
      "Epoch 723/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0069 - mse: 0.0152 - val_loss: 0.0075 - val_mse: 0.0172\n",
      "Epoch 724/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0069 - mse: 0.0153 - val_loss: 0.0075 - val_mse: 0.0172\n",
      "Epoch 725/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0069 - mse: 0.0153 - val_loss: 0.0075 - val_mse: 0.0172\n",
      "Epoch 726/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0069 - mse: 0.0153 - val_loss: 0.0075 - val_mse: 0.0172\n",
      "Epoch 727/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0069 - mse: 0.0152 - val_loss: 0.0075 - val_mse: 0.0172\n",
      "Epoch 728/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0069 - mse: 0.0152 - val_loss: 0.0075 - val_mse: 0.0172\n",
      "Epoch 729/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0069 - mse: 0.0152 - val_loss: 0.0075 - val_mse: 0.0172\n",
      "Epoch 730/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0069 - mse: 0.0152 - val_loss: 0.0075 - val_mse: 0.0172\n",
      "Epoch 731/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0069 - mse: 0.0152 - val_loss: 0.0075 - val_mse: 0.0172\n",
      "Epoch 732/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0069 - mse: 0.0152 - val_loss: 0.0075 - val_mse: 0.0172\n",
      "Epoch 733/2000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0069 - mse: 0.0152 - val_loss: 0.0075 - val_mse: 0.0172\n",
      "Epoch 734/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0069 - mse: 0.0152 - val_loss: 0.0075 - val_mse: 0.0172\n",
      "Epoch 735/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0069 - mse: 0.0152 - val_loss: 0.0075 - val_mse: 0.0172\n",
      "Epoch 736/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0069 - mse: 0.0152 - val_loss: 0.0075 - val_mse: 0.0172\n",
      "Epoch 737/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0069 - mse: 0.0152 - val_loss: 0.0075 - val_mse: 0.0172\n",
      "Epoch 738/2000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0069 - mse: 0.0152 - val_loss: 0.0075 - val_mse: 0.0172\n",
      "Epoch 739/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0069 - mse: 0.0152 - val_loss: 0.0075 - val_mse: 0.0172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 740/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0069 - mse: 0.0152 - val_loss: 0.0075 - val_mse: 0.0172\n",
      "Epoch 741/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0069 - mse: 0.0152 - val_loss: 0.0075 - val_mse: 0.0172\n",
      "Epoch 742/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0069 - mse: 0.0152 - val_loss: 0.0075 - val_mse: 0.0172\n",
      "Epoch 743/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0069 - mse: 0.0152 - val_loss: 0.0075 - val_mse: 0.0171\n",
      "Epoch 744/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0069 - mse: 0.0152 - val_loss: 0.0074 - val_mse: 0.0171\n",
      "Epoch 745/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0069 - mse: 0.0152 - val_loss: 0.0075 - val_mse: 0.0171\n",
      "Epoch 746/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0069 - mse: 0.0152 - val_loss: 0.0075 - val_mse: 0.0171\n",
      "Epoch 747/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0069 - mse: 0.0152 - val_loss: 0.0075 - val_mse: 0.0172\n",
      "Epoch 748/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0069 - mse: 0.0152 - val_loss: 0.0075 - val_mse: 0.0172\n",
      "Epoch 749/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0069 - mse: 0.0152 - val_loss: 0.0075 - val_mse: 0.0172\n",
      "Epoch 750/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0069 - mse: 0.0152 - val_loss: 0.0075 - val_mse: 0.0172\n",
      "Epoch 751/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0069 - mse: 0.0152 - val_loss: 0.0075 - val_mse: 0.0172\n",
      "Epoch 752/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0069 - mse: 0.0152 - val_loss: 0.0075 - val_mse: 0.0172\n",
      "Epoch 753/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0069 - mse: 0.0151 - val_loss: 0.0075 - val_mse: 0.0172\n",
      "Epoch 754/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0069 - mse: 0.0152 - val_loss: 0.0075 - val_mse: 0.0172\n",
      "Epoch 755/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0069 - mse: 0.0151 - val_loss: 0.0075 - val_mse: 0.0172\n",
      "Epoch 756/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0069 - mse: 0.0151 - val_loss: 0.0075 - val_mse: 0.0171\n",
      "Epoch 757/2000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0069 - mse: 0.0151 - val_loss: 0.0074 - val_mse: 0.0171\n",
      "Epoch 758/2000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.0069 - mse: 0.0151 - val_loss: 0.0074 - val_mse: 0.0171\n",
      "Epoch 759/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0069 - mse: 0.0151 - val_loss: 0.0074 - val_mse: 0.0171\n",
      "Epoch 760/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0068 - mse: 0.0151 - val_loss: 0.0074 - val_mse: 0.0171\n",
      "Epoch 761/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0068 - mse: 0.0151 - val_loss: 0.0074 - val_mse: 0.0171\n",
      "Epoch 762/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0068 - mse: 0.0151 - val_loss: 0.0074 - val_mse: 0.0171\n",
      "Epoch 763/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0068 - mse: 0.0151 - val_loss: 0.0074 - val_mse: 0.0171\n",
      "Epoch 764/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0069 - mse: 0.0151 - val_loss: 0.0074 - val_mse: 0.0171\n",
      "Epoch 765/2000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0068 - mse: 0.0151 - val_loss: 0.0074 - val_mse: 0.0171\n",
      "Epoch 766/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0068 - mse: 0.0151 - val_loss: 0.0074 - val_mse: 0.0171\n",
      "Epoch 767/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0068 - mse: 0.0151 - val_loss: 0.0074 - val_mse: 0.0171\n",
      "Epoch 768/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0068 - mse: 0.0151 - val_loss: 0.0074 - val_mse: 0.0171\n",
      "Epoch 769/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0068 - mse: 0.0151 - val_loss: 0.0074 - val_mse: 0.0171\n",
      "Epoch 770/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0068 - mse: 0.0151 - val_loss: 0.0074 - val_mse: 0.0171\n",
      "Epoch 771/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0068 - mse: 0.0151 - val_loss: 0.0074 - val_mse: 0.0171\n",
      "Epoch 772/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0068 - mse: 0.0151 - val_loss: 0.0074 - val_mse: 0.0171\n",
      "Epoch 773/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0068 - mse: 0.0151 - val_loss: 0.0074 - val_mse: 0.0171\n",
      "Epoch 774/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0068 - mse: 0.0151 - val_loss: 0.0074 - val_mse: 0.0170\n",
      "Epoch 775/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0068 - mse: 0.0151 - val_loss: 0.0074 - val_mse: 0.0170\n",
      "Epoch 776/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0068 - mse: 0.0151 - val_loss: 0.0074 - val_mse: 0.0170\n",
      "Epoch 777/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0068 - mse: 0.0151 - val_loss: 0.0074 - val_mse: 0.0170\n",
      "Epoch 778/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0068 - mse: 0.0151 - val_loss: 0.0074 - val_mse: 0.0170\n",
      "Epoch 779/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0068 - mse: 0.0151 - val_loss: 0.0074 - val_mse: 0.0170\n",
      "Epoch 780/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0068 - mse: 0.0151 - val_loss: 0.0074 - val_mse: 0.0170\n",
      "Epoch 781/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0068 - mse: 0.0151 - val_loss: 0.0074 - val_mse: 0.0170\n",
      "Epoch 782/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0068 - mse: 0.0151 - val_loss: 0.0074 - val_mse: 0.0170\n",
      "Epoch 783/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0068 - mse: 0.0151 - val_loss: 0.0074 - val_mse: 0.0170\n",
      "Epoch 784/2000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.0068 - mse: 0.0151 - val_loss: 0.0074 - val_mse: 0.0170\n",
      "Epoch 785/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0074 - val_mse: 0.0170\n",
      "Epoch 786/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0068 - mse: 0.0151 - val_loss: 0.0074 - val_mse: 0.0170\n",
      "Epoch 787/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0068 - mse: 0.0151 - val_loss: 0.0074 - val_mse: 0.0170\n",
      "Epoch 788/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0068 - mse: 0.0151 - val_loss: 0.0074 - val_mse: 0.0170\n",
      "Epoch 789/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0068 - mse: 0.0151 - val_loss: 0.0074 - val_mse: 0.0170\n",
      "Epoch 790/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0068 - mse: 0.0151 - val_loss: 0.0074 - val_mse: 0.0170\n",
      "Epoch 791/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0068 - mse: 0.0151 - val_loss: 0.0074 - val_mse: 0.0170\n",
      "Epoch 792/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0074 - val_mse: 0.0170\n",
      "Epoch 793/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0074 - val_mse: 0.0170\n",
      "Epoch 794/2000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0074 - val_mse: 0.0169\n",
      "Epoch 795/2000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0068 - mse: 0.0151 - val_loss: 0.0074 - val_mse: 0.0169\n",
      "Epoch 796/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0074 - val_mse: 0.0169\n",
      "Epoch 797/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0074 - val_mse: 0.0169\n",
      "Epoch 798/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0068 - mse: 0.0151 - val_loss: 0.0074 - val_mse: 0.0169\n",
      "Epoch 799/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0074 - val_mse: 0.0169\n",
      "Epoch 800/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0074 - val_mse: 0.0169\n",
      "Epoch 801/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0074 - val_mse: 0.0169\n",
      "Epoch 802/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0074 - val_mse: 0.0169\n",
      "Epoch 803/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0074 - val_mse: 0.0169\n",
      "Epoch 804/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0074 - val_mse: 0.0169\n",
      "Epoch 805/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0074 - val_mse: 0.0169\n",
      "Epoch 806/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0068 - mse: 0.0151 - val_loss: 0.0074 - val_mse: 0.0169\n",
      "Epoch 807/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0074 - val_mse: 0.0169\n",
      "Epoch 808/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0074 - val_mse: 0.0169\n",
      "Epoch 809/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0074 - val_mse: 0.0169\n",
      "Epoch 810/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0074 - val_mse: 0.0169\n",
      "Epoch 811/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0068 - mse: 0.0151 - val_loss: 0.0074 - val_mse: 0.0169\n",
      "Epoch 812/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0074 - val_mse: 0.0169\n",
      "Epoch 813/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0074 - val_mse: 0.0169\n",
      "Epoch 814/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0074 - val_mse: 0.0169\n",
      "Epoch 815/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0074 - val_mse: 0.0169\n",
      "Epoch 816/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0074 - val_mse: 0.0169\n",
      "Epoch 817/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0074 - val_mse: 0.0169\n",
      "Epoch 818/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0074 - val_mse: 0.0169\n",
      "Epoch 819/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0074 - val_mse: 0.0169\n",
      "Epoch 820/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0074 - val_mse: 0.0169\n",
      "Epoch 821/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0074 - val_mse: 0.0169\n",
      "Epoch 822/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0073 - val_mse: 0.0169\n",
      "Epoch 823/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0073 - val_mse: 0.0168\n",
      "Epoch 824/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0073 - val_mse: 0.0168\n",
      "Epoch 825/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0073 - val_mse: 0.0168\n",
      "Epoch 826/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0073 - val_mse: 0.0168\n",
      "Epoch 827/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0073 - val_mse: 0.0168\n",
      "Epoch 828/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0073 - val_mse: 0.0168\n",
      "Epoch 829/2000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0073 - val_mse: 0.0168\n",
      "Epoch 830/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0073 - val_mse: 0.0168\n",
      "Epoch 831/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0073 - val_mse: 0.0168\n",
      "Epoch 832/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0073 - val_mse: 0.0168\n",
      "Epoch 833/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0073 - val_mse: 0.0168\n",
      "Epoch 834/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0073 - val_mse: 0.0168\n",
      "Epoch 835/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0073 - val_mse: 0.0168\n",
      "Epoch 836/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0073 - val_mse: 0.0168\n",
      "Epoch 837/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0073 - val_mse: 0.0168\n",
      "Epoch 838/2000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0073 - val_mse: 0.0168\n",
      "Epoch 839/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0073 - val_mse: 0.0168\n",
      "Epoch 840/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0073 - val_mse: 0.0168\n",
      "Epoch 841/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0073 - val_mse: 0.0168\n",
      "Epoch 842/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0073 - val_mse: 0.0168\n",
      "Epoch 843/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0073 - val_mse: 0.0168\n",
      "Epoch 844/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0073 - val_mse: 0.0168\n",
      "Epoch 845/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0073 - val_mse: 0.0168\n",
      "Epoch 846/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0073 - val_mse: 0.0168\n",
      "Epoch 847/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0073 - val_mse: 0.0168\n",
      "Epoch 848/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0073 - val_mse: 0.0168\n",
      "Epoch 849/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0073 - val_mse: 0.0168\n",
      "Epoch 850/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0073 - val_mse: 0.0168\n",
      "Epoch 851/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0073 - val_mse: 0.0168\n",
      "Epoch 852/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0073 - val_mse: 0.0168\n",
      "Epoch 853/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0073 - val_mse: 0.0168\n",
      "Epoch 854/2000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0168\n",
      "Epoch 855/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 856/2000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 857/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 858/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 859/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 860/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 861/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 862/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0073 - val_mse: 0.0167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 863/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 864/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 865/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 866/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 867/2000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 868/2000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 869/2000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 870/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 871/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 872/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 873/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 874/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 875/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 876/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 877/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 878/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 879/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 880/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 881/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 882/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0068 - mse: 0.0150 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 883/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 884/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 885/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 886/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 887/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 888/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 889/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 890/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 891/2000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 892/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 893/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 894/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 895/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 896/2000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 897/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 898/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 899/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 900/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0168\n",
      "Epoch 901/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 902/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 903/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 904/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 905/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 906/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 907/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0067 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 908/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 909/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 910/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 911/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 912/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 913/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 914/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 915/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0067 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 916/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 917/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 918/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0067 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 919/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0067 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 920/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 921/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0067 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 922/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0067 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 923/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0067 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 924/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0067 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 925/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0067 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 926/2000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 927/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 928/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0067 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 929/2000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0067 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 930/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0067 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 931/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0068 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 932/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0067 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 933/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0067 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 934/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0067 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 935/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0067 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 936/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0067 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 937/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0067 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 938/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0067 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 939/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0067 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 940/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 941/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0067 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 942/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0067 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 943/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0067 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 944/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0067 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 945/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0067 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 946/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0067 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 947/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0067 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 948/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0067 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 949/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 950/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0067 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 951/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0067 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 952/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0067 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 953/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0067 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 954/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0067 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 955/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0067 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 956/2000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0067 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 957/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 958/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0067 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 959/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0067 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 960/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0067 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 961/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0067 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 962/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 963/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0067 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 964/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0067 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 965/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 966/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 967/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 968/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0067 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 969/2000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 970/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 971/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 972/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 973/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 974/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 975/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 976/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 977/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 978/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 979/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 980/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 981/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 982/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 983/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 984/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 985/2000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 986/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 987/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 988/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 989/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 990/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 991/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 992/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 993/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 994/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 995/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 996/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0067 - mse: 0.0149 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 997/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 998/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 999/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1000/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1001/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1002/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1003/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1004/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1005/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1006/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1007/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1008/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1009/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1010/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1011/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1012/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1013/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1014/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1015/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1016/2000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1017/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1018/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1019/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1020/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1021/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1022/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1023/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1024/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1025/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1026/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1027/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1028/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1029/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1030/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1031/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1032/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1033/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1034/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1035/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1036/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1037/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1038/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1039/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1040/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1041/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1042/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1043/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1044/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1045/2000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1046/2000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1047/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1048/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1049/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1050/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1051/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1052/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1053/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1054/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1055/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1056/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1057/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1058/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1059/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1060/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1061/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1062/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1063/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1064/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1065/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1066/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1067/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1068/2000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1069/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1070/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1071/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1072/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1073/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1074/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1075/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1076/2000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1077/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1078/2000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1079/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1080/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1081/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1082/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1083/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1084/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1085/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1086/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1087/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1088/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1089/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1090/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1091/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1092/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1093/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1094/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1095/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1096/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1097/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1098/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1099/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1100/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1101/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1102/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0067 - mse: 0.0148 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1103/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1104/2000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1105/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1106/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1107/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1108/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1109/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1110/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1111/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1112/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1113/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1114/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1115/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1116/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1117/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1118/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1119/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1120/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1121/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1122/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1123/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1124/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1125/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1126/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1127/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0165\n",
      "Epoch 1128/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0165\n",
      "Epoch 1129/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1130/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1131/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1132/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1133/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1134/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1135/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1136/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1137/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1138/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1139/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1140/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1141/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1142/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1143/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1144/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1145/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1146/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1147/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1148/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1149/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1150/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1151/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1152/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1153/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1154/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1155/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1156/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1157/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1158/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1159/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1160/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1161/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1162/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0165\n",
      "Epoch 1163/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0165\n",
      "Epoch 1164/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0165\n",
      "Epoch 1165/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1166/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1167/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1168/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0066 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1169/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1170/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1171/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1172/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0066 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1173/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1174/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1175/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1176/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0066 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1177/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1178/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0165\n",
      "Epoch 1179/2000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0165\n",
      "Epoch 1180/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0165\n",
      "Epoch 1181/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0165\n",
      "Epoch 1182/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1183/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1184/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1185/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0066 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1186/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1187/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0066 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1188/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0066 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1189/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0066 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0165\n",
      "Epoch 1190/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0165\n",
      "Epoch 1191/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0165\n",
      "Epoch 1192/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0066 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0165\n",
      "Epoch 1193/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0072 - val_mse: 0.0165\n",
      "Epoch 1194/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0165\n",
      "Epoch 1195/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0066 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1196/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0066 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1197/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1198/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1199/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1200/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1201/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0066 - mse: 0.0147 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1202/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1203/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0066 - mse: 0.0147 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1204/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0066 - mse: 0.0147 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1205/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1206/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0067 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1207/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0072 - val_mse: 0.0165\n",
      "Epoch 1208/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0072 - val_mse: 0.0165\n",
      "Epoch 1209/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0072 - val_mse: 0.0165\n",
      "Epoch 1210/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0072 - val_mse: 0.0165\n",
      "Epoch 1211/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0066 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0165\n",
      "Epoch 1212/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0072 - val_mse: 0.0165\n",
      "Epoch 1213/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0072 - val_mse: 0.0165\n",
      "Epoch 1214/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1215/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1216/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0066 - mse: 0.0147 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1217/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1218/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1219/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1220/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0066 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1221/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1222/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0072 - val_mse: 0.0165\n",
      "Epoch 1223/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0072 - val_mse: 0.0165\n",
      "Epoch 1224/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0066 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0165\n",
      "Epoch 1225/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0066 - mse: 0.0147 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1226/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1227/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0066 - mse: 0.0147 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1228/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1229/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1230/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1231/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1232/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1233/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1234/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1235/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1236/2000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1237/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0072 - val_mse: 0.0165\n",
      "Epoch 1238/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0072 - val_mse: 0.0165\n",
      "Epoch 1239/2000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0072 - val_mse: 0.0165\n",
      "Epoch 1240/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0072 - val_mse: 0.0165\n",
      "Epoch 1241/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0072 - val_mse: 0.0165\n",
      "Epoch 1242/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0072 - val_mse: 0.0165\n",
      "Epoch 1243/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0072 - val_mse: 0.0165\n",
      "Epoch 1244/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1245/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1246/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1247/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1248/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1249/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1250/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1251/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1252/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1253/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1254/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1255/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1256/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1257/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1258/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1259/2000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1260/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1261/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1262/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1263/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1264/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1265/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1266/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1267/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1268/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1269/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0072 - val_mse: 0.0165\n",
      "Epoch 1270/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0072 - val_mse: 0.0165\n",
      "Epoch 1271/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0072 - val_mse: 0.0165\n",
      "Epoch 1272/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1273/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1274/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1275/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1276/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1277/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1278/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1279/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1280/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1281/2000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1282/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1283/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1284/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1285/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1286/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1287/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1288/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1289/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1290/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1291/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1292/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1293/2000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1294/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1295/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1296/2000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1297/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1298/2000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1299/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1300/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1301/2000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1302/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1303/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1304/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1305/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1306/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1307/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1308/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1309/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1310/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1311/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1312/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1313/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1314/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1315/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0072 - val_mse: 0.0166\n",
      "Epoch 1316/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1317/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1318/2000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1319/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1320/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1321/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1322/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1323/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1324/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1325/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1326/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1327/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1328/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1329/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1330/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1331/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1332/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1333/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1334/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1335/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1336/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1337/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1338/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1339/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1340/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1341/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0066 - mse: 0.0146 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1342/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1343/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1344/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1345/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1346/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1347/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1348/2000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1349/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1350/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1351/2000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1352/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1353/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1354/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1355/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1356/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1357/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1358/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1359/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1360/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1361/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0168\n",
      "Epoch 1362/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0168\n",
      "Epoch 1363/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0168\n",
      "Epoch 1364/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0168\n",
      "Epoch 1365/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0168\n",
      "Epoch 1366/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0168\n",
      "Epoch 1367/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0168\n",
      "Epoch 1368/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1369/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1370/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1371/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1372/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1373/2000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1374/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1375/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1376/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1377/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1378/2000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1379/2000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1380/2000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1381/2000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1382/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1383/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1384/2000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1385/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1386/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0168\n",
      "Epoch 1387/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0168\n",
      "Epoch 1388/2000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1389/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1390/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1391/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1392/2000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1393/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1394/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0166\n",
      "Epoch 1395/2000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1396/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1397/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1398/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1399/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1400/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1401/2000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1402/2000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1403/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1404/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1405/2000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1406/2000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1407/2000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 1408/2000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0066 - mse: 0.0145 - val_loss: 0.0073 - val_mse: 0.0167\n",
      "Epoch 01408: early stopping\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "history = model.fit(x_train_scaled, x_train_scaled, epochs=EPOCHS, batch_size=batch_size, shuffle=True, verbose=1,\n",
    "                    validation_split=0.2, callbacks=[checkpointer, earlystopping], workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8645c4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_threshold(model, x_train_scaled):\n",
    "    reconstructions = model.predict(x_train_scaled)\n",
    "    # provides losses of individual instances\n",
    "    reconstruction_errors = tf.keras.losses.msle(reconstructions, x_train_scaled)\n",
    "    # threshold for anomaly scores\n",
    "    threshold = np.mean(reconstruction_errors.numpy()) + np.std(reconstruction_errors.numpy())\n",
    "    return threshold\n",
    "\n",
    "def get_predictions(model, x_val_scaled, threshold):\n",
    "    predictions = model.predict(x_val_scaled)\n",
    "    # provides losses of individual instances\n",
    "    errors = tf.keras.losses.msle(predictions, x_val_scaled)\n",
    "    # 1 = anomaly, 0 = normal\n",
    "    anomaly_mask = pd.Series(errors) > threshold\n",
    "    preds = anomaly_mask.map(lambda x: 1.0 if x == True else 0.0)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5809c544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.0099258268951801\n"
     ]
    }
   ],
   "source": [
    "threshold = find_threshold(model, x_train_scaled)\n",
    "print(f\"Threshold: {threshold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "42556154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2825873093949828"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = get_predictions(model, x_val_scaled, threshold)\n",
    "accuracy_score(predictions, val_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9ab15855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2213304661090842"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(predictions, val_Y, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e0a5b5",
   "metadata": {},
   "source": [
    "## 10. new AutoEncoder로 오류 분포 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "fe7c8a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reconstruction_error</th>\n",
       "      <th>true_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28462.000000</td>\n",
       "      <td>28462.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.320094</td>\n",
       "      <td>0.001054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.013033</td>\n",
       "      <td>0.032449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.004501</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.019437</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.166903</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>248.509770</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reconstruction_error    true_class\n",
       "count          28462.000000  28462.000000\n",
       "mean               0.320094      0.001054\n",
       "std                3.013033      0.032449\n",
       "min                0.000834      0.000000\n",
       "25%                0.004501      0.000000\n",
       "50%                0.019437      0.000000\n",
       "75%                0.166903      0.000000\n",
       "max              248.509770      1.000000"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_val = new_autoencoder.predict(val_X)\n",
    "mse = np.mean(np.power(val_X - pred_val, 2), axis=1)\n",
    "error_df = pd.DataFrame({'reconstruction_error' : mse, 'true_class' : val_Y})\n",
    "error_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6faafba5",
   "metadata": {},
   "source": [
    "### 1) 정상 데이터의 재구성 오류 분포 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "327382e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "normal_error_df = error_df[(error_df['true_class'] == 0)]\n",
    "_ = ax.hist(normal_error_df.reconstruction_error.values, bins=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87d6a1f",
   "metadata": {},
   "source": [
    "### 2) 이상 데이터의 재구성 오류 분포 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c5181cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "fraud_error_df = error_df[error_df['true_class'] == 1]\n",
    "_ = ax.hist(fraud_error_df.reconstruction_error.values, bins=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ae3468",
   "metadata": {},
   "source": [
    "### 3) 정밀도 vs 재현율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d186c8fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision, recall, th = precision_recall_curve(error_df.true_class, error_df.reconstruction_error)\n",
    "plt.plot(recall, precision, 'b', label='Precision-Recall curve')\n",
    "plt.title('Recall vs Precision')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716adb34",
   "metadata": {},
   "source": [
    "### 4) 임계값에 따른 정밀도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "86ff7b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(th, precision[1:], 'b', label='Threshold-Precision curve')\n",
    "plt.title('Precision for different threshold values')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Precision')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed75ea6",
   "metadata": {},
   "source": [
    "### 5) 임계값에 따른 재현율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4f79a6a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(th, recall[1:], 'b', label='Threshold-Recall curve')\n",
    "plt.title('Recall for different threshold values')\n",
    "plt.xlabel('Reconstruction error')\n",
    "plt.ylabel('Recall')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f235b8d",
   "metadata": {},
   "source": [
    "## 11. 최적의 임계값 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "7e542ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af8b06a1ddb34403a9369278736f1bf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28451 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_score = 0\n",
    "best_th = 0\n",
    "\n",
    "for i in tqdm(th):\n",
    "    pred_class = np.where(mse > i, 1, 0)\n",
    "    score = f1_score(val_Y, pred_class, average='macro')\n",
    "    \n",
    "    if max_score < score:\n",
    "        max_score = score\n",
    "        best_th = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "1300b167",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best f1-score : 0.7597890072792488\n",
      "Best threshold : 30.002564009499945\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best f1-score : {max_score}\")\n",
    "print(f\"Best threshold : {best_th}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ce8107",
   "metadata": {},
   "source": [
    "- 더 해볼 것 \n",
    "    - 정상 데이터로만 학습시키는 모델의 accuracy 및 loss 값 개선할 것"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
